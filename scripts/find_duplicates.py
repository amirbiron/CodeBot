#!/usr/bin/env python3
"""
×¡×§×¨×™×¤×˜ ×œ××™×ª×•×¨ ×›×¤×™×œ×•×™×•×ª ×§×•×“ ×‘×¨×™×¤×•.

ğŸ”’ ×¡×§×¨×™×¤×˜ ×œ×§×¨×™××” ×‘×œ×‘×“ - ×œ× ××‘×¦×¢ ×©×•× ×¢×¨×™×›×” ××• ××—×™×§×” ×©×œ ×§×•×“!

×©×™×¤×•×¨×™× ×œ×¢×•××ª ×”×’×¨×¡×” ×”××§×•×¨×™×ª:
- ×¡×™× ×•×Ÿ ×ª×™×§×™×•×ª ××“×•×™×§ ×™×•×ª×¨ ×¢× Path.parts
- ×ª××™×›×” ×‘×¤×•× ×§×¦×™×•×ª ××¡×™× ×›×¨×•× ×™×•×ª (AsyncFunctionDef)
- × ×¨××•×œ AST ××ª×§×“×: ×”×—×œ×¤×ª ××–×”×™× ×•×”×¡×¨×ª docstrings
- ×˜×™×¤×•×œ ×‘×˜×•×— ×‘-lineno/end_lineno
- SHA256 ×‘××§×•× MD5

×©×™××•×©:
    python scripts/find_duplicates.py
    python scripts/find_duplicates.py --min-lines 6
    python scripts/find_duplicates.py --output json
"""

from __future__ import annotations

import argparse
import ast
import copy
import hashlib
import json
import sys
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any

# ============================================================================
# ×”×’×“×¨×•×ª
# ============================================================================

PROJECT_ROOT = Path(__file__).parent.parent  # ×ª×™×§×™×™×ª ×”×¤×¨×•×™×§×˜

# ×ª×™×§×™×•×ª ×œ×¡×¨×™×§×” (×¨×§ ×ª×™×§×™×•×ª ×©×‘×××ª ××›×™×œ×•×ª ×§×•×“ ×©×œ ×”×¤×¨×•×™×§×˜)
DIRS_TO_INCLUDE = {
    "services",
    "handlers",
    "webapp",
    "database",
    "src",
    "chatops",
    "monitoring",
    "reminders",
    "i18n",
    "tools",
}

# ×ª×™×§×™×•×ª ×œ×”×ª×¢×œ××•×ª ××•×—×œ×˜×ª
DIRS_TO_EXCLUDE = {
    "tests",
    "node_modules",
    "__pycache__",
    ".git",
    "venv",
    ".venv",
    "docs",
}

# ××™× ×™××•× ×©×•×¨×•×ª ×œ×¤×•× ×§×¦×™×” (×¤×—×•×ª ××–×” = × ×ª×¢×œ×)
DEFAULT_MIN_LINES = 4


# ============================================================================
# ××‘× ×™ × ×ª×•× ×™×
# ============================================================================


@dataclass
class FunctionLocation:
    """××™×§×•× ×©×œ ×¤×•× ×§×¦×™×” ×‘×§×•×“."""

    file: str
    name: str
    start_line: int
    end_line: int
    is_async: bool = False

    @property
    def lines_range(self) -> str:
        return f"{self.start_line}-{self.end_line}"

    @property
    def line_count(self) -> int:
        return self.end_line - self.start_line + 1


@dataclass
class DuplicateGroup:
    """×§×‘×•×¦×ª ×¤×•× ×§×¦×™×•×ª ×›×¤×•×œ×•×ª."""

    hash_prefix: str
    locations: list[FunctionLocation] = field(default_factory=list)

    @property
    def count(self) -> int:
        return len(self.locations)


# ============================================================================
# × ×¨××•×œ AST ××ª×§×“×
# ============================================================================


class ASTNormalizer(ast.NodeTransformer):
    """
    ×× ×¨××œ ×¢×¥ AST ×›×“×™ ×œ×”×©×•×•×ª ××‘× ×™× ×œ×•×’×™×™×.

    ××” ×©×”×•× ×¢×•×©×”:
    - ××—×œ×™×£ ××ª ×›×œ ×©××•×ª ×”××©×ª× ×™× ×œ-_v0, _v1, _v2...
    - ××¡×™×¨ docstrings
    - ××¡×™×¨ ××™×“×¢ ××™×§×•× (lineno, col_offset ×•×›×•')
    """

    def __init__(self) -> None:
        self.var_counter = 0
        self.var_map: dict[str, str] = {}

    def _get_normalized_name(self, original: str) -> str:
        """××—×–×™×¨ ×©× ×× ×•×¨××œ ×œ××©×ª× ×”."""
        if original not in self.var_map:
            self.var_map[original] = f"_v{self.var_counter}"
            self.var_counter += 1
        return self.var_map[original]

    def visit_Name(self, node: ast.Name) -> ast.Name:
        """××—×œ×™×£ ×©××•×ª ××©×ª× ×™× ×œ×©××•×ª ×’× ×¨×™×™×."""
        node.id = self._get_normalized_name(node.id)
        self.generic_visit(node)
        return node

    def visit_arg(self, node: ast.arg) -> ast.arg:
        """××—×œ×™×£ ×©××•×ª ×¤×¨××˜×¨×™×."""
        node.arg = self._get_normalized_name(node.arg)
        self.generic_visit(node)
        return node

    def visit_FunctionDef(self, node: ast.FunctionDef) -> ast.FunctionDef:
        """××˜×¤×œ ×‘×¤×•× ×§×¦×™×” - ××¡×™×¨ docstring ×•×× ×¨××œ ×©×."""
        node.name = "_func"
        node.body = self._remove_docstring(node.body)
        self.generic_visit(node)
        return node

    def visit_AsyncFunctionDef(
        self, node: ast.AsyncFunctionDef
    ) -> ast.AsyncFunctionDef:
        """××˜×¤×œ ×‘×¤×•× ×§×¦×™×” ××¡×™× ×›×¨×•× ×™×ª - ××¡×™×¨ docstring ×•×× ×¨××œ ×©×."""
        node.name = "_func"
        node.body = self._remove_docstring(node.body)
        self.generic_visit(node)
        return node

    def _remove_docstring(self, body: list[ast.stmt]) -> list[ast.stmt]:
        """××¡×™×¨ docstring ××’×•×£ ×”×¤×•× ×§×¦×™×”."""
        if not body:
            return body

        first_stmt = body[0]
        if isinstance(first_stmt, ast.Expr) and isinstance(
            first_stmt.value, ast.Constant
        ):
            if isinstance(first_stmt.value.value, str):
                return body[1:]
        return body


def normalize_ast_node(node: ast.AST) -> str:
    """
    ×× ×¨××œ ×¦×•××ª AST ×•××—×–×™×¨ ××—×¨×•×–×ª ×œ×”×©×•×•××”.

    ××—×–×™×¨ ××ª ×”×™×™×¦×•×’ ×”×× ×•×¨××œ ×©×œ ×”×¤×•× ×§×¦×™×” - ×œ×œ× ×©××•×ª ××©×ª× ×™×,
    ×œ×œ× docstrings, ×¨×§ ×”××‘× ×” ×”×œ×•×’×™.
    """
    # ×™×•×¦×¨×™× ×¢×•×ª×§ ×¢××•×§ ×›×“×™ ×œ× ×œ×©× ×•×ª ××ª ×”××§×•×¨
    node_copy = copy.deepcopy(node)

    # ×× ×¨××œ×™× ××ª ×”×¢×¥
    normalizer = ASTNormalizer()
    normalized = normalizer.visit(node_copy)

    # ×××™×¨×™× ×œ-dump ×œ×œ× ××™×“×¢ ××™×§×•×
    return ast.dump(normalized, include_attributes=False)


def get_function_hash(normalized_code: str) -> str:
    """××—×©×‘ hash ×©×œ ×”×§×•×“ ×”×× ×•×¨××œ ×¢× SHA256."""
    return hashlib.sha256(normalized_code.encode("utf-8")).hexdigest()


# ============================================================================
# ×¡×¨×™×§×ª ×”×¤×¨×•×™×§×˜
# ============================================================================


def should_scan_file(filepath: Path) -> bool:
    """×‘×•×“×§ ×× ×”×§×•×‘×¥ ×¦×¨×™×š ×œ×”×™×¡×¨×§."""
    if not filepath.suffix == ".py":
        return False

    # ×‘×•×“×§×™× ×©×”×§×•×‘×¥ × ××¦× ×‘××—×ª ×”×ª×™×§×™×•×ª ×”×¨×¦×•×™×•×ª
    parts = set(filepath.parts)

    # ×× ×™×© ×ª×™×§×™×™×” ×©×¦×¨×™×š ×œ×”×ª×¢×œ× ××× ×” - ×“×™×œ×•×’
    if parts & DIRS_TO_EXCLUDE:
        return False

    # ×‘×•×“×§×™× ×× ×”×§×•×‘×¥ × ××¦× ×‘××—×ª ×”×ª×™×§×™×•×ª ×©×× ×—× ×• ×¨×•×¦×™×
    return bool(parts & DIRS_TO_INCLUDE)


def get_line_info(node: ast.AST) -> tuple[int, int]:
    """
    ××—×–×™×¨ ××™×“×¢ ×©×•×¨×•×ª ×‘×˜×•×— ×¢×‘×•×¨ ×¦×•××ª AST.

    ××˜×¤×œ ×‘××§×¨×™× ×©×‘×”× lineno ××• end_lineno ×œ× ×§×™×™××™×.
    """
    start = getattr(node, "lineno", 0)
    end = getattr(node, "end_lineno", start)
    return start, end


def extract_functions(
    filepath: Path, min_lines: int
) -> list[tuple[ast.AST, FunctionLocation]]:
    """××—×œ×¥ ××ª ×›×œ ×”×¤×•× ×§×¦×™×•×ª ××§×•×‘×¥."""
    functions: list[tuple[ast.AST, FunctionLocation]] = []

    try:
        content = filepath.read_text(encoding="utf-8")
        tree = ast.parse(content)
    except (SyntaxError, UnicodeDecodeError) as e:
        print(f"âš ï¸  ×“×™×œ×’×ª×™ ×¢×œ {filepath}: {e}")
        return functions

    for node in ast.walk(tree):
        is_async = isinstance(node, ast.AsyncFunctionDef)
        is_sync = isinstance(node, ast.FunctionDef)

        if not (is_async or is_sync):
            continue

        start_line, end_line = get_line_info(node)

        # ×‘×“×™×§×ª ××™× ×™××•× ×©×•×¨×•×ª
        line_count = end_line - start_line + 1
        if line_count < min_lines:
            continue

        location = FunctionLocation(
            file=str(filepath.relative_to(PROJECT_ROOT)),
            name=node.name,  # type: ignore
            start_line=start_line,
            end_line=end_line,
            is_async=is_async,
        )

        functions.append((node, location))

    return functions


def scan_project(min_lines: int = DEFAULT_MIN_LINES) -> dict[str, list[FunctionLocation]]:
    """
    ×¡×•×¨×§ ××ª ×”×¤×¨×•×™×§×˜ ×•××—×–×™×¨ ××¤×” ×©×œ hash ×œ×¨×©×™××ª ××™×§×•××™×.

    âš ï¸ ×¤×•× ×§×¦×™×” ×œ×§×¨×™××” ×‘×œ×‘×“ - ×œ× ××©× ×” ×©×•× ×§×•×‘×¥!
    """
    duplicates: dict[str, list[FunctionLocation]] = {}

    print(f"ğŸš€ ××ª×—×™×œ ×¡×¨×™×§×” ×‘×ª×™×§×™×•×ª: {', '.join(sorted(DIRS_TO_INCLUDE))}...")
    print(f"   ××ª×¢×œ× ××¤×•× ×§×¦×™×•×ª ×§×¦×¨×•×ª ×-{min_lines} ×©×•×¨×•×ª")
    print()

    files_scanned = 0
    functions_found = 0

    for py_file in PROJECT_ROOT.rglob("*.py"):
        if not should_scan_file(py_file):
            continue

        files_scanned += 1
        functions = extract_functions(py_file, min_lines)

        for node, location in functions:
            functions_found += 1

            # × ×¨××•×œ ×•-hash
            normalized = normalize_ast_node(node)
            func_hash = get_function_hash(normalized)

            if func_hash not in duplicates:
                duplicates[func_hash] = []
            duplicates[func_hash].append(location)

    print(f"ğŸ“ × ×¡×¨×§×• {files_scanned} ×§×‘×¦×™×")
    print(f"ğŸ” × ××¦××• {functions_found} ×¤×•× ×§×¦×™×•×ª")

    return duplicates


# ============================================================================
# ×”×¦×’×ª ×ª×•×¦××•×ª
# ============================================================================


def print_report(duplicates: dict[str, list[FunctionLocation]]) -> int:
    """××“×¤×™×¡ ×“×•×— ×›×¤×™×œ×•×™×•×ª. ××—×–×™×¨ ××ª ××¡×¤×¨ ×”×›×¤×™×œ×•×™×•×ª ×©× ××¦××•."""
    print("\n" + "=" * 60)
    print("ğŸ“Š ×ª×•×¦××•×ª ×”×¡×¨×™×§×”")
    print("=" * 60)

    found = 0
    total_duplicate_instances = 0

    # ××™×•×Ÿ ×œ×¤×™ ××¡×¤×¨ ×”×›×¤×™×œ×•×™×•×ª (×”×›×™ ×”×¨×‘×” ×§×•×“×)
    sorted_items = sorted(
        ((h, locs) for h, locs in duplicates.items() if len(locs) > 1),
        key=lambda x: len(x[1]),
        reverse=True,
    )

    for func_hash, locations in sorted_items:
        found += 1
        total_duplicate_instances += len(locations)

        # ×‘×“×™×§×” ×× ×™×© ×¤×•× ×§×¦×™×•×ª async ×‘×§×‘×•×¦×”
        has_async = any(loc.is_async for loc in locations)
        async_marker = " ğŸ”„" if has_async else ""

        print(f"\nğŸ”´ ×›×¤×™×œ×•×ª #{found} (Hash: {func_hash[:8]}...){async_marker}")
        print(f"   × ××¦××• {len(locations)} ××•×¤×¢×™×:")

        for loc in locations:
            async_tag = "[async] " if loc.is_async else ""
            print(
                f"   â€¢ {loc.file}: {async_tag}{loc.name}() "
                f"(×©×•×¨×•×ª {loc.lines_range}, {loc.line_count} ×©×•×¨×•×ª)"
            )

    print("\n" + "=" * 60)

    if found == 0:
        print("âœ… ×”×§×•×“ × ×§×™! ×œ× × ××¦××• ×›×¤×™×œ×•×™×•×ª.")
    else:
        print(f"âš ï¸  ×¡×”\"×› × ××¦××• {found} ×§×‘×•×¦×•×ª ×©×œ ×§×•×“ ××©×•×›×¤×œ")
        print(f"   ({total_duplicate_instances} ××•×¤×¢×™× ×›×¤×•×œ×™×)")

    print("=" * 60)

    return found


def output_json(duplicates: dict[str, list[FunctionLocation]]) -> None:
    """××“×¤×™×¡ ××ª ×”×ª×•×¦××•×ª ×‘×¤×•×¨××˜ JSON."""
    result: dict[str, Any] = {
        "summary": {
            "duplicate_groups": 0,
            "total_duplicates": 0,
        },
        "duplicates": [],
    }

    for func_hash, locations in duplicates.items():
        if len(locations) <= 1:
            continue

        result["summary"]["duplicate_groups"] += 1
        result["summary"]["total_duplicates"] += len(locations)

        group = {
            "hash": func_hash[:16],
            "count": len(locations),
            "locations": [
                {
                    "file": loc.file,
                    "function": loc.name,
                    "start_line": loc.start_line,
                    "end_line": loc.end_line,
                    "is_async": loc.is_async,
                }
                for loc in locations
            ],
        }
        result["duplicates"].append(group)

    # ××™×•×Ÿ ×œ×¤×™ ××¡×¤×¨ ×›×¤×™×œ×•×™×•×ª
    result["duplicates"].sort(key=lambda x: x["count"], reverse=True)

    print(json.dumps(result, ensure_ascii=False, indent=2))


# ============================================================================
# × ×§×•×“×ª ×›× ×™×¡×”
# ============================================================================


def main() -> int:
    """× ×§×•×“×ª ×›× ×™×¡×” ×¨××©×™×ª."""
    parser = argparse.ArgumentParser(
        description="×¡×§×¨×™×¤×˜ ×œ××™×ª×•×¨ ×›×¤×™×œ×•×™×•×ª ×§×•×“ (×§×¨×™××” ×‘×œ×‘×“)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
×“×•×’×××•×ª ×©×™××•×©:
  python scripts/find_duplicates.py                    # ×¡×¨×™×§×” ×¨×’×™×œ×”
  python scripts/find_duplicates.py --min-lines 6     # ×¨×§ ×¤×•× ×§×¦×™×•×ª ××¨×•×›×•×ª ×™×•×ª×¨
  python scripts/find_duplicates.py --output json     # ×¤×œ×˜ JSON
        """,
    )

    parser.add_argument(
        "--min-lines",
        type=int,
        default=DEFAULT_MIN_LINES,
        help=f"××™× ×™××•× ×©×•×¨×•×ª ×œ×¤×•× ×§×¦×™×” (×‘×¨×™×¨×ª ××—×“×œ: {DEFAULT_MIN_LINES})",
    )

    parser.add_argument(
        "--output",
        choices=["text", "json"],
        default="text",
        help="×¤×•×¨××˜ ×”×¤×œ×˜ (×‘×¨×™×¨×ª ××—×“×œ: text)",
    )

    args = parser.parse_args()

    # ×¡×¨×™×§×”
    duplicates = scan_project(min_lines=args.min_lines)

    # ×”×¦×’×ª ×ª×•×¦××•×ª
    if args.output == "json":
        output_json(duplicates)
        return 0
    else:
        found = print_report(duplicates)
        return 1 if found > 0 else 0


if __name__ == "__main__":
    sys.exit(main())
