# 专 砖 注专转 Caching 转拽转 注 TTL 

转专: 2025-10-22  
住 注: 砖驻专 爪注 砖注转 砖 WebApp 注 注专转 caching  转转

##  住拽专 转

注专转 caching 转拽转 注 TTL  驻砖专转  砖驻专 驻 专 转  转 砖 驻拽爪, 拽 注住 注 MongoDB 住驻拽 转 砖转砖 拽 专 转专. 专 转拽 注 专转转 驻专拽转 砖 砖转 caching 砖转.

### 转专转 专:
- **驻转转  转 -70-90%** 注专 驻注转 专转
- **拽转 注住 注 MongoDB -50-80%** 
- **砖驻专 转 砖转砖** 注 注 专 砖 驻
- **住 砖 砖专转** 转 scale

---

##  住专转 TTL 

### 1. 拽注转 TTL 驻 住 转

```python
class DynamicTTL:
    """拽  TTL  驻 住 转 拽拽住"""
    
    # TTL 住住 驻 住 转 (砖转)
    BASE_TTL = {
        'user_stats': 300,        # 5 拽转 - 住住拽转 砖转砖
        'file_content': 3600,     # 砖注 - 转 拽爪 ( 砖转 专)
        'file_list': 60,          # 拽 - 专砖转 拽爪
        'markdown_render': 1800,  # 30 拽转 - 专专 Markdown
        'search_results': 180,    # 3 拽转 - 转爪转 驻砖
        'public_stats': 600,      # 10 拽转 - 住住拽转 爪专转
        'bookmarks': 120,         # 2 拽转 - 住转
        'tags': 300,              # 5 拽转 - 转转
        'settings': 60,           # 拽 - 专转 砖转砖
    }
    
    @classmethod
    def calculate_ttl(cls, content_type: str, context: Dict[str, Any]) -> int:
        """砖 TTL  驻 拽拽住"""
        base_ttl = cls.BASE_TTL.get(content_type, 300)
        
        # 转转 驻 拽拽住
        if context.get('is_favorite'):
            # 拽爪 注驻 - cache 专 转专
            base_ttl = int(base_ttl * 1.5)
            
        if context.get('last_modified_hours_ago', 24) < 1:
            # 转 砖注 专 - cache 拽爪专 转专
            base_ttl = int(base_ttl * 0.5)
            
        if context.get('access_frequency', 'low') == 'high':
            # 转 驻驻专 - cache 专 转专
            base_ttl = int(base_ttl * 2)
            
        if context.get('user_tier') == 'premium':
            # 砖转砖 驻专 - cache 拽爪专 转专 注 专
            base_ttl = int(base_ttl * 0.7)
            
        # 转  拽住
        return max(30, min(base_ttl, 7200))  #  30 砖转 -2 砖注转
```

### 2. TTL 转 砖注转 驻注转

```python
from datetime import datetime

class ActivityBasedTTL:
    """转转 TTL 驻 砖注转 驻注转"""
    
    @staticmethod
    def get_activity_multiplier() -> float:
        """专 拽 TTL 驻 砖注 """
        hour = datetime.now().hour
        
        # 砖注转 砖 (9:00-18:00) - TTL 拽爪专 转专
        if 9 <= hour < 18:
            return 0.7
        
        # 砖注转 注专 (18:00-23:00) - TTL   
        elif 18 <= hour < 23:
            return 1.0
            
        # 砖注转  (23:00-9:00) - TTL 专 转专
        else:
            return 1.5
    
    @classmethod
    def adjust_ttl(cls, base_ttl: int) -> int:
        """转转 TTL 驻 砖注转 """
        multiplier = cls.get_activity_multiplier()
        return int(base_ttl * multiplier)
```

---

##  注 拽 拽

### 1. 砖专 CacheManager 拽

```python
# 专转 cache_manager.py 拽
from typing import Callable, Optional

class EnhancedCacheManager(CacheManager):
    """ Cache 砖专 注 TTL """
    
    def __init__(self):
        super().__init__()
        self.ttl_calculator = DynamicTTL()
        self.activity_adjuster = ActivityBasedTTL()
    
    def set_dynamic(self, key: str, value: Any, content_type: str, 
                    context: Optional[Dict] = None) -> bool:
        """砖专 -cache 注 TTL """
        if context is None:
            context = {}
            
        # 砖 TTL 住住
        base_ttl = self.ttl_calculator.calculate_ttl(content_type, context)
        
        # 转 驻 砖注转 驻注转
        adjusted_ttl = self.activity_adjuster.adjust_ttl(base_ttl)
        
        #  专
        if cache_op_duration_seconds:
            logger.debug(f"Setting cache key {key} with TTL {adjusted_ttl}s "
                        f"(type: {content_type})")
        
        return self.set(key, value, adjusted_ttl)
    
    def get_with_refresh(self, key: str, refresh_func: Callable,
                         content_type: str, context: Optional[Dict] = None) -> Any:
        """拽专 -cache 注 专注   爪专"""
        cached_value = self.get(key)
        
        if cached_value is None:
            #  -cache - 砖 sh专
            fresh_value = refresh_func()
            if fresh_value is not None:
                self.set_dynamic(key, fresh_value, content_type, context)
            return fresh_value
            
        return cached_value
```

### 2. 拽专专 砖砖  -Flask

> **砖:** 拽专专 驻 -Flask Response objects 爪专  - 砖专 专拽 转 -JSON data  转 -Response object 注爪

```python
from functools import wraps
from flask import request, g, jsonify

def dynamic_cache(content_type: str, key_prefix: Optional[str] = None):
    """拽专专 -caching  砖 endpoints"""
    def decorator(f):
        @wraps(f)
        def wrapper(*args, **kwargs):
            # 转 驻转 cache
            if key_prefix:
                cache_key = f"{key_prefix}:"
            else:
                cache_key = f"{f.__name__}:"
            
            # 住驻转 驻专专 驻转
            cache_key += f"{g.get('user_id', 'anonymous')}:"
            cache_key += f"{request.path}:{request.query_string.decode()}"
            
            # 拽拽住 砖 TTL
            context = {
                'user_id': g.get('user_id'),
                'user_tier': g.get('user_tier', 'regular'),
                'endpoint': f.__name__
            }
            
            # 住 拽专 -cache
            cache_manager = get_cache_manager()
            cached = cache_manager.get(cache_key)
            
            if cached is not None:
                # 专拽转 hit
                if cache_hits_total:
                    cache_hits_total.labels(backend='redis').inc()
                #   dict - 专 -jsonify, 专转 专  砖
                if isinstance(cached, dict):
                    return jsonify(cached)
                return cached
            
            # 砖 转爪
            result = f(*args, **kwargs)
            
            # 拽  转爪  Response object
            if hasattr(result, 'get_json'):
                #   Response object, 砖专 专拽 转 -JSON data
                try:
                    cache_data = result.get_json()
                    if cache_data is not None:
                        cache_manager.set_dynamic(cache_key, cache_data, content_type, context)
                except:
                    #   爪 抓 JSON,  砖专 -cache
                    pass
            elif isinstance(result, (dict, list, str, int, float, bool)):
                # 专拽  转爪 serializable, 砖专 -cache
                cache_manager.set_dynamic(cache_key, result, content_type, context)
            
            # 专拽转 miss
            if cache_misses_total:
                cache_misses_total.labels(backend='redis').inc()
                
            return result
        return wrapper
    return decorator
```

---

##  转 注 -WebApp

### 1. Cache 专砖转 拽爪

```python
# webapp/app.py - 砖驻专 endpoint 拽

@app.route('/api/files')
@requires_auth
@dynamic_cache(content_type='file_list')
def get_files():
    """API 拽转 专砖转 拽爪 注 cache """
    user_id = session.get('user_id')
    
    # 驻专专 -query string
    page = request.args.get('page', 1, type=int)
    per_page = request.args.get('per_page', 20, type=int)
    sort_by = request.args.get('sort_by', 'created_at')
    language = request.args.get('language')
    
    # 拽拽住 住祝 -TTL
    context = {
        'has_filters': bool(language or request.args.get('tags')),
        'page_number': page
    }
    
    # 专转 cache_key 
    cache_key = f"files:{user_id}:{page}:{per_page}:{sort_by}:{language}"
    
    def fetch_files():
        """驻拽爪 砖驻转 拽爪 -DB"""
        query = {'user_id': user_id}
        if language:
            query['language'] = language
            
        files = db.code_snippets.find(query)\
                                 .sort(sort_by, DESCENDING)\
                                 .skip((page - 1) * per_page)\
                                 .limit(per_page)
        return list(files)
    
    # 砖砖 -cache 注 专注 
    files = cache_manager.get_with_refresh(
        cache_key, fetch_files, 'file_list', context
    )
    
    return jsonify(files)
```

### 2. Cache 专专 Markdown

```python
# webapp/app.py - cache 专专 Markdown

class MarkdownCache:
    """拽 注转 -cache 砖 专专 Markdown"""
    
    @staticmethod
    def get_render_cache_key(file_id: str, version: Optional[int] = None) -> str:
        """转 驻转 cache 专专"""
        key = f"md_render:{file_id}"
        if version:
            key += f":v{version}"
        return key
    
    @staticmethod
    def render_with_cache(file_id: str, markdown_content: str,
                          last_modified: datetime) -> str:
        """专专 Markdown 注 cache """
        cache_key = MarkdownCache.get_render_cache_key(file_id)
        
        # 拽拽住 拽注转 TTL
        hours_since_modified = (datetime.now() - last_modified).total_seconds() / 3600
        context = {
            'last_modified_hours_ago': hours_since_modified,
            'content_length': len(markdown_content)
        }
        
        def render_markdown():
            """专专 驻注"""
            #  砖转砖 -markdown processor 拽
            rendered = markdown_to_html(markdown_content)
            return {
                'html': rendered,
                'rendered_at': datetime.now().isoformat(),
                'etag': hashlib.md5(rendered.encode()).hexdigest()
            }
        
        return cache_manager.get_with_refresh(
            cache_key, render_markdown, 'markdown_render', context
        )

@app.route('/md/<file_id>')
def view_markdown(file_id):
    """爪转 拽抓 Markdown 注 cache"""
    file_doc = db.code_snippets.find_one({'_id': ObjectId(file_id)})
    if not file_doc:
        abort(404)
    
    # 专专 注 cache
    rendered = MarkdownCache.render_with_cache(
        file_id, 
        file_doc['content'],
        file_doc.get('updated_at', file_doc['created_at'])
    )
    
    # 拽转 ETag
    if request.headers.get('If-None-Match') == rendered['etag']:
        return '', 304
    
    response = make_response(rendered['html'])
    response.headers['ETag'] = rendered['etag']
    response.headers['Cache-Control'] = 'private, must-revalidate'
    
    return response
```

### 3. Cache 住住拽转

```python
# webapp/app.py - cache 住住拽转 注 TTL 专

class StatsCache:
    """ cache 住住拽转"""
    
    @staticmethod
    def get_user_stats_cached(user_id: str) -> Dict:
        """住住拽转 砖转砖 注 cache"""
        cache_key = f"stats:user:{user_id}"
        
        def calculate_stats():
            """砖 住住拽转 -DB"""
            pipeline = [
                {'$match': {'user_id': user_id}},
                {'$group': {
                    '_id': None,
                    'total_files': {'$sum': 1},
                    'total_size': {'$sum': '$size'},
                    'languages': {'$addToSet': '$language'},
                    'last_upload': {'$max': '$created_at'}
                }},
                {'$project': {
                    '_id': 0,
                    'total_files': 1,
                    'total_size': 1,
                    'unique_languages': {'$size': '$languages'},
                    'last_upload': 1
                }}
            ]
            
            result = list(db.code_snippets.aggregate(pipeline))
            if result:
                stats = result[0]
                stats['calculated_at'] = datetime.now().isoformat()
                return stats
            return {'total_files': 0, 'total_size': 0}
        
        # 拽拽住 -TTL - 砖转砖 驻注 拽 注 转驻 转专
        last_activity = get_user_last_activity(user_id)
        context = {
            'access_frequency': 'high' if last_activity < 3600 else 'low'
        }
        
        return cache_manager.get_with_refresh(
            cache_key, calculate_stats, 'user_stats', context
        )

@app.route('/api/stats')
@requires_auth
def get_stats():
    """API 住住拽转 注 cache """
    user_id = session.get('user_id')
    stats = StatsCache.get_user_stats_cached(user_id)
    return jsonify(stats)
```

---

##  Cache Warming 注 专砖

### 1. 注转 cache 专砖 注转 驻注

```python
# webapp/cache_warmup.py

class CacheWarmer:
    """注转 cache 专砖 砖驻专 爪注"""
    
    def __init__(self, cache_manager, db):
        self.cache = cache_manager
        self.db = db
        
    def warm_popular_content(self):
        """注转 转 驻驻专 -cache"""
        # 拽爪 驻驻专 ( 专 爪驻转)
        popular_files = self.db.code_snippets.find(
            {'views_count': {'$gt': 10}}
        ).sort('views_count', -1).limit(100)
        
        for file_doc in popular_files:
            # cache 砖 转 拽抓
            cache_key = f"file_content:{file_doc['_id']}"
            self.cache.set_dynamic(
                cache_key, 
                file_doc,
                'file_content',
                {'access_frequency': 'high'}
            )
            
            #   Markdown,  专专
            if file_doc.get('language') == 'markdown':
                rendered = markdown_to_html(file_doc['content'])
                render_key = f"md_render:{file_doc['_id']}"
                self.cache.set_dynamic(
                    render_key,
                    rendered,
                    'markdown_render',
                    {'access_frequency': 'high'}
                )
    
    def warm_user_data(self, user_id: str):
        """注转 转 砖转砖 -cache"""
        # 专砖转 拽爪 专
        recent_files = list(
            self.db.code_snippets.find({'user_id': user_id})
                                 .sort('created_at', -1)
                                 .limit(20)
        )
        
        cache_key = f"files:{user_id}:1:20:created_at:"
        self.cache.set_dynamic(
            cache_key,
            recent_files,
            'file_list'
        )
        
        # 住住拽转 砖转砖
        stats = calculate_user_stats(user_id)
        stats_key = f"stats:user:{user_id}"
        self.cache.set_dynamic(
            stats_key,
            stats,
            'user_stats'
        )

# 驻注 注转 转 驻拽爪
@app.before_first_request
def warm_cache():
    """注转 cache 注转 驻注"""
    if not app.config.get('SKIP_CACHE_WARMUP'):
        warmer = CacheWarmer(cache_manager, db)
        warmer.warm_popular_content()
```

### 2. 专注 cache 专拽注

```python
# webapp/cache_refresh.py
import threading
import schedule
import time  # 砖! 专砖 注专 time.sleep() 转 专注

class CacheRefresher:
    """专注 cache  专拽注"""
    
    def __init__(self, cache_manager, db):
        self.cache = cache_manager
        self.db = db
        self.running = False
        self.thread = None
        
    def refresh_stats(self):
        """专注 住住拽转 -cache"""
        # 住住拽转 爪专转
        public_stats = calculate_public_stats()
        self.cache.set_dynamic(
            'stats:public',
            public_stats,
            'public_stats'
        )
        
        # 住住拽转 砖转砖 驻注
        active_users = get_recently_active_users(hours=1)
        for user_id in active_users:
            stats = calculate_user_stats(user_id)
            self.cache.set_dynamic(
                f'stats:user:{user_id}',
                stats,
                'user_stats',
                {'access_frequency': 'high'}
            )
    
    def clean_stale_cache(self):
        """拽 cache 砖"""
        # 砖砖 驻拽爪 拽转
        deleted = self.cache.clear_stale(
            max_scan=5000,
            ttl_seconds_threshold=30
        )
        logger.info(f"Cleaned {deleted} stale cache entries")
    
    def start(self):
        """驻注转 专注 """
        schedule.every(5).minutes.do(self.refresh_stats)
        schedule.every(30).minutes.do(self.clean_stale_cache)
        
        def run_schedule():
            while self.running:
                schedule.run_pending()
                time.sleep(60)
        
        self.running = True
        self.thread = threading.Thread(target=run_schedule, daemon=True)
        self.thread.start()
    
    def stop(self):
        """注爪专转 专注"""
        self.running = False
        if self.thread:
            self.thread.join(timeout=5)

# 驻注 驻拽爪
cache_refresher = CacheRefresher(cache_manager, db)
cache_refresher.start()
```

---

##  Cache Invalidation 注拽转 转

### 转专 专
砖专 转 转注 -DB  -cache 注 拽 注专 砖,  砖砖  住驻专 instances 砖 砖专转 - 爪专转 注转 注拽转.  驻转专转 拽驻:

### 1. Invalidation Strategies - 住专转  Cache

```python
# webapp/cache_invalidation.py

from enum import Enum
from typing import Set, List, Optional
import redis.client

class InvalidationStrategy(Enum):
    """住专转 砖转  cache"""
    IMMEDIATE = "immediate"        #  
    LAZY = "lazy"                  #  注爪 (拽专 )
    TTL_BASED = "ttl_based"        # 住住 TTL 
    EVENT_DRIVEN = "event_driven"  # 住住 专注

class SmartCacheInvalidator:
    """注专转   cache 注转 注 转"""
    
    def __init__(self, cache_manager, db):
        self.cache = cache_manager
        self.db = db
        self.redis_client = cache_manager.redis_client
        
    def invalidate_on_update(self, collection: str, doc_id: str, 
                            update_data: Dict, user_id: str):
        """ cache  注转 注 住"""
        
        # 1.  cache 砖 住 注爪
        self._invalidate_document_cache(collection, doc_id)
        
        # 2.  专砖转 砖转 转 住
        self._invalidate_list_caches(collection, user_id)
        
        # 3.  住住拽转  爪专
        if self._should_invalidate_stats(update_data):
            self._invalidate_stats_cache(user_id)
        
        # 4. 驻专住 专注 住专  instances
        self._publish_invalidation_event(collection, doc_id, user_id)
    
    def _invalidate_document_cache(self, collection: str, doc_id: str):
        """ cache 砖 住 """
        patterns = [
            f"file_content:{doc_id}*",
            f"md_render:{doc_id}*",
            f"{collection}:{doc_id}*"
        ]
        
        for pattern in patterns:
            self._delete_by_pattern(pattern)
    
    def _invalidate_list_caches(self, collection: str, user_id: str):
        """ cache 砖 专砖转"""
        patterns = [
            f"files:{user_id}:*",      #  专砖转 拽爪
            f"search:{user_id}:*",      # 转爪转 驻砖
            f"bookmarks:{user_id}",     # 住转
        ]
        
        for pattern in patterns:
            self._delete_by_pattern(pattern)
    
    def _should_invalidate_stats(self, update_data: Dict) -> bool:
        """拽  爪专 注 住住拽转"""
        stats_affecting_fields = {
            'size', 'language', 'tags', 'is_deleted', 'created_at'
        }
        return bool(stats_affecting_fields.intersection(update_data.keys()))
    
    def _invalidate_stats_cache(self, user_id: str):
        """ cache 砖 住住拽转"""
        patterns = [
            f"stats:user:{user_id}",
            f"stats:public",
            f"activity:{user_id}:*"
        ]
        
        for pattern in patterns:
            self._delete_by_pattern(pattern)
    
    def _delete_by_pattern(self, pattern: str):
        """拽转 驻转转 驻 pattern"""
        try:
            if '*' in pattern:
                # 住专拽 拽 砖 驻转转
                for key in self.redis_client.scan_iter(match=pattern, count=100):
                    self.redis_client.delete(key)
            else:
                # 拽 砖专
                self.redis_client.delete(pattern)
        except Exception as e:
            logger.error(f"Failed to delete cache pattern {pattern}: {e}")
    
    def _publish_invalidation_event(self, collection: str, doc_id: str, user_id: str):
        """驻专住 专注 住专  instances"""
        event = {
            'type': 'cache_invalidation',
            'collection': collection,
            'doc_id': doc_id,
            'user_id': user_id,
            'timestamp': time.time()
        }
        
        try:
            # 驻专住 -Redis Pub/Sub
            self.redis_client.publish('cache_invalidation', json.dumps(event))
        except Exception as e:
            logger.error(f"Failed to publish invalidation event: {e}")

# 砖砖 注转 注
@app.route('/api/files/<file_id>', methods=['PUT'])
@requires_auth
def update_file(file_id):
    """注 拽抓 注  cache """
    user_id = session.get('user_id')
    update_data = request.json
    
    # 注 -DB
    result = db.code_snippets.update_one(
        {'_id': ObjectId(file_id), 'user_id': user_id},
        {'$set': update_data}
    )
    
    if result.modified_count:
        #  cache 
        invalidator = SmartCacheInvalidator(cache_manager, db)
        invalidator.invalidate_on_update(
            'code_snippets', file_id, update_data, user_id
        )
        
        return jsonify({'success': True})
    
    return jsonify({'success': False}), 404
```

### 2. Cache Versioning - 专住转 Cache

```python
# webapp/cache_versioning.py

class VersionedCache:
    """注专转 cache 注 转 专住转"""
    
    def __init__(self, cache_manager):
        self.cache = cache_manager
        self.version_key = "cache_versions"
        
    def get_version(self, entity_type: str) -> int:
        """拽转 专住 转 砖 entity"""
        versions = self.cache.get(self.version_key) or {}
        return versions.get(entity_type, 1)
    
    def increment_version(self, entity_type: str):
        """注转 专住 - 专  cache """
        versions = self.cache.get(self.version_key) or {}
        versions[entity_type] = versions.get(entity_type, 1) + 1
        self.cache.set(self.version_key, versions, expire_seconds=86400)
        
        # 驻专住 砖 专住
        self._publish_version_change(entity_type, versions[entity_type])
    
    def get_with_version(self, key: str, entity_type: str) -> Any:
        """拽专 -cache 注 拽转 专住"""
        version = self.get_version(entity_type)
        versioned_key = f"{key}:v{version}"
        return self.cache.get(versioned_key)
    
    def set_with_version(self, key: str, value: Any, entity_type: str,
                         expire_seconds: int = 300):
        """砖专 -cache 注 专住"""
        version = self.get_version(entity_type)
        versioned_key = f"{key}:v{version}"
        return self.cache.set(versioned_key, value, expire_seconds)
    
    def _publish_version_change(self, entity_type: str, new_version: int):
        """驻专住 砖 专住  -instances"""
        event = {
            'type': 'version_change',
            'entity_type': entity_type,
            'version': new_version,
            'timestamp': time.time()
        }
        self.cache.redis_client.publish('cache_versions', json.dumps(event))

# 砖砖 注 专住转
versioned_cache = VersionedCache(cache_manager)

@app.route('/api/files')
@requires_auth
def get_files_versioned():
    """拽转 拽爪 注 cache 住住 专住转"""
    user_id = session.get('user_id')
    cache_key = f"files:{user_id}"
    
    # 住 拽专 注 专住
    files = versioned_cache.get_with_version(cache_key, 'files')
    
    if files is None:
        # 砖驻 -DB
        files = list(db.code_snippets.find({'user_id': user_id}))
        
        # 砖专 注 专住
        versioned_cache.set_with_version(
            cache_key, files, 'files', expire_seconds=300
        )
    
    return jsonify(files)

#  注  注转 专住
@app.route('/api/files', methods=['POST'])
@requires_auth
def create_file():
    """爪专转 拽抓 砖"""
    # ... 爪专转 拽抓 ...
    
    # 注转 专住 -  转  -cache 砖 拽爪
    versioned_cache.increment_version('files')
    
    return jsonify({'success': True})
```

### 3. 住专  Instances 专

```python
# webapp/cache_sync.py

import threading
from redis.client import PubSub

class CacheSynchronizer:
    """住专 cache  instances 专 砖 砖专转"""
    
    def __init__(self, cache_manager, instance_id: Optional[str] = None):
        self.cache = cache_manager
        self.instance_id = instance_id or self._generate_instance_id()
        self.pubsub = None
        self.sync_thread = None
        self.running = False
        
    def _generate_instance_id(self) -> str:
        """爪专转 ID  -instance"""
        import socket
        hostname = socket.gethostname()
        pid = os.getpid()
        return f"{hostname}:{pid}"
    
    def start_sync(self):
        """驻注转  住专"""
        if not self.cache.redis_client:
            logger.warning("Redis not available, skipping cache sync")
            return
        
        self.pubsub = self.cache.redis_client.pubsub()
        self.pubsub.subscribe(
            'cache_invalidation',
            'cache_versions', 
            'cache_updates'
        )
        
        self.running = True
        self.sync_thread = threading.Thread(
            target=self._sync_worker,
            daemon=True
        )
        self.sync_thread.start()
        
        logger.info(f"Cache sync started for instance {self.instance_id}")
    
    def _sync_worker(self):
        """Worker thread 驻 专注 住专"""
        while self.running:
            try:
                message = self.pubsub.get_message(timeout=1)
                if message and message['type'] == 'message':
                    self._handle_sync_message(message)
            except Exception as e:
                logger.error(f"Sync worker error: {e}")
                time.sleep(5)
    
    def _handle_sync_message(self, message):
        """驻 注转 住专"""
        try:
            data = json.loads(message['data'])
            channel = message['channel'].decode()
            
            #  注 注转 -instance 
            if data.get('instance_id') == self.instance_id:
                return
            
            if channel == 'cache_invalidation':
                self._handle_invalidation(data)
            elif channel == 'cache_versions':
                self._handle_version_change(data)
            elif channel == 'cache_updates':
                self._handle_cache_update(data)
                
        except Exception as e:
            logger.error(f"Failed to handle sync message: {e}")
    
    def _handle_invalidation(self, data: Dict):
        """驻 专注  cache"""
        patterns = []
        
        if data.get('doc_id'):
            patterns.append(f"*:{data['doc_id']}*")
        if data.get('user_id'):
            patterns.append(f"*:{data['user_id']}:*")
        if data.get('collection'):
            patterns.append(f"{data['collection']}:*")
        
        for pattern in patterns:
            self._local_invalidate(pattern)
    
    def _handle_version_change(self, data: Dict):
        """驻 砖 专住"""
        #  拽 砖 cache 注 专住 砖
        entity_type = data.get('entity_type')
        if entity_type:
            old_version = data.get('version', 1) - 1
            pattern = f"*:v{old_version}"
            self._local_invalidate(pattern)
    
    def _handle_cache_update(self, data: Dict):
        """驻 注 cache 砖专"""
        key = data.get('key')
        value = data.get('value')
        ttl = data.get('ttl', 300)
        
        if key and value:
            # 注 cache 拽
            self.cache.set(key, value, ttl)
    
    def _local_invalidate(self, pattern: str):
        """ cache 拽"""
        try:
            if '*' in pattern:
                for key in self.cache.redis_client.scan_iter(match=pattern):
                    self.cache.redis_client.delete(key)
            else:
                self.cache.redis_client.delete(pattern)
        except Exception as e:
            logger.error(f"Local invalidation failed: {e}")
    
    def publish_update(self, key: str, value: Any, ttl: int = 300):
        """驻专住 注 cache  -instances"""
        event = {
            'instance_id': self.instance_id,
            'key': key,
            'value': value,
            'ttl': ttl,
            'timestamp': time.time()
        }
        
        try:
            self.cache.redis_client.publish('cache_updates', json.dumps(event))
        except Exception as e:
            logger.error(f"Failed to publish cache update: {e}")
    
    def stop_sync(self):
        """注爪专转 住专"""
        self.running = False
        if self.pubsub:
            self.pubsub.unsubscribe()
            self.pubsub.close()
        if self.sync_thread:
            self.sync_thread.join(timeout=5)

# 驻注 驻拽爪
cache_sync = CacheSynchronizer(cache_manager)
cache_sync.start_sync()

# Cleanup 注转 
import atexit
atexit.register(cache_sync.stop_sync)
```

### 4. Write-Through Cache Pattern

```python
# webapp/write_through_cache.py

class WriteThroughCache:
    """Pattern 砖 Write-Through - 转 住转 -DB -cache"""
    
    def __init__(self, cache_manager, db):
        self.cache = cache_manager
        self.db = db
        self.sync = CacheSynchronizer(cache_manager)
    
    def write(self, collection: str, doc_id: str, data: Dict,
              user_id: str) -> bool:
        """转 住转 -DB -cache"""
        
        # 1. 转 -DB
        result = self.db[collection].update_one(
            {'_id': ObjectId(doc_id)},
            {'$set': data}
        )
        
        if not result.modified_count:
            return False
        
        # 2. 注 cache 
        doc = self.db[collection].find_one({'_id': ObjectId(doc_id)})
        if doc:
            # 注 cache 砖 住
            cache_key = f"{collection}:{doc_id}"
            self.cache.set_dynamic(cache_key, doc, collection)
            
            # 3. 驻专住 住专
            self.sync.publish_update(cache_key, doc)
            
            # 4.  caches 转
            self._invalidate_dependent_caches(collection, doc_id, user_id)
        
        return True
    
    def _invalidate_dependent_caches(self, collection: str, doc_id: str, 
                                    user_id: str):
        """ caches 转"""
        # 专砖转
        self.cache.delete_pattern(f"files:{user_id}:*")
        # 住住拽转
        self.cache.delete(f"stats:user:{user_id}")
        # 驻砖
        self.cache.delete_pattern(f"search:{user_id}:*")

# 砖砖
write_through = WriteThroughCache(cache_manager, db)

@app.route('/api/files/<file_id>', methods=['PATCH'])
@requires_auth
def patch_file(file_id):
    """注 拽 注 Write-Through"""
    user_id = session.get('user_id')
    updates = request.json
    
    success = write_through.write(
        'code_snippets',
        file_id,
        updates,
        user_id
    )
    
    return jsonify({'success': success})
```

### 5. Event-Driven Invalidation 注 Decorators

```python
# webapp/cache_decorators.py

def invalidates_cache(*cache_patterns):
    """拽专专  cache """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # 专爪转 驻拽爪
            result = func(*args, **kwargs)
            
            #  cache 驻 patterns
            if result:  # 专拽  驻注 爪
                for pattern in cache_patterns:
                    # 驻转 placeholders
                    actual_pattern = pattern
                    if '{user_id}' in pattern:
                        actual_pattern = pattern.replace(
                            '{user_id}', 
                            str(g.get('user_id', '*'))
                        )
                    if '{file_id}' in pattern and 'file_id' in kwargs:
                        actual_pattern = pattern.replace(
                            '{file_id}',
                            str(kwargs.get('file_id', '*'))
                        )
                    
                    cache_manager.delete_pattern(actual_pattern)
            
            return result
        return wrapper
    return decorator

# 砖砖 注 拽专专
@app.route('/api/files/<file_id>', methods=['DELETE'])
@requires_auth
@invalidates_cache(
    'files:{user_id}:*',
    'file_content:{file_id}',
    'stats:user:{user_id}'
)
def delete_file(file_id):
    """拽转 拽抓 注  cache """
    user_id = g.user_id
    
    result = db.code_snippets.delete_one({
        '_id': ObjectId(file_id),
        'user_id': user_id
    })
    
    return result.deleted_count > 0
```

### 6. Lazy Invalidation 注 Tagged Cache

```python
# webapp/tagged_cache.py

class TaggedCache:
    """注专转 cache 注 tags  拽爪转"""
    
    def __init__(self, cache_manager):
        self.cache = cache_manager
        self.tag_prefix = "tag:"
        
    def set_with_tags(self, key: str, value: Any, tags: List[str],
                      expire_seconds: int = 300):
        """砖专 -cache 注 tags"""
        # 砖专转 注专
        self.cache.set(key, value, expire_seconds)
        
        # 砖专转 tags
        for tag in tags:
            tag_key = f"{self.tag_prefix}{tag}"
            tagged_keys = self.cache.get(tag_key) or set()
            tagged_keys.add(key)
            self.cache.set(tag_key, list(tagged_keys), expire_seconds=3600)
    
    def invalidate_by_tag(self, tag: str):
        """  -cache entries 注 tag 住"""
        tag_key = f"{self.tag_prefix}{tag}"
        tagged_keys = self.cache.get(tag_key) or []
        
        for key in tagged_keys:
            self.cache.delete(key)
        
        # 拽转 -tag 注爪
        self.cache.delete(tag_key)
    
    def get_with_lazy_invalidation(self, key: str, 
                                   validation_func: Callable) -> Any:
        """拽专 注 拽转 转拽转 (lazy invalidation)"""
        cached_value = self.cache.get(key)
        
        if cached_value is not None:
            # 拽  注专 注 转拽祝
            if validation_func(cached_value):
                return cached_value
            else:
                # 注专  转拽祝 - 拽
                self.cache.delete(key)
        
        return None

# 砖砖
tagged_cache = TaggedCache(cache_manager)

# 砖专 注 tags
tagged_cache.set_with_tags(
    f"file:{file_id}",
    file_data,
    tags=[f"user:{user_id}", "files", f"language:{language}"],
    expire_seconds=600
)

#   拽爪 砖 砖转砖
tagged_cache.invalidate_by_tag(f"user:{user_id}")

# 拽专 注 validation
def validate_file(cached_file):
    """拽  拽抓 注 转拽祝"""
    # 拽转 timestamp
    if cached_file.get('cached_at', 0) < time.time() - 300:
        return False
    # 拽 住驻转  DB  爪专
    return True

file = tagged_cache.get_with_lazy_invalidation(
    f"file:{file_id}",
    validate_file
)
```

### 7. Distributed Lock 注拽转 注

```python
# webapp/distributed_lock.py

import uuid

class DistributedLock:
    """注 专转 注转 race conditions"""
    
    def __init__(self, redis_client, default_timeout=10):
        self.redis = redis_client
        self.default_timeout = default_timeout
    
    def acquire(self, lock_name: str, timeout: Optional[int] = None) -> str:
        """住 拽转 注"""
        timeout = timeout or self.default_timeout
        identifier = str(uuid.uuid4())
        lock_key = f"lock:{lock_name}"
        
        # 住 拽转 注
        acquired = self.redis.set(
            lock_key,
            identifier,
            nx=True,  # 专拽   拽
            ex=timeout
        )
        
        return identifier if acquired else None
    
    def release(self, lock_name: str, identifier: str) -> bool:
        """砖专专 注"""
        lock_key = f"lock:{lock_name}"
        
        # Lua script 砖专专 
        lua_script = """
        if redis.call("get", KEYS[1]) == ARGV[1] then
            return redis.call("del", KEYS[1])
        else
            return 0
        end
        """
        
        try:
            result = self.redis.eval(lua_script, 1, lock_key, identifier)
            return bool(result)
        except Exception as e:
            logger.error(f"Failed to release lock: {e}")
            return False

# 砖砖 注
lock = DistributedLock(cache_manager.redis_client)

@app.route('/api/files/<file_id>/process', methods=['POST'])
@requires_auth
def process_file(file_id):
    """注 拽抓 注 注 注转 注 拽"""
    lock_id = lock.acquire(f"process:{file_id}", timeout=30)
    
    if not lock_id:
        return jsonify({'error': 'File is being processed'}), 423
    
    try:
        # 注 拽抓
        result = process_file_content(file_id)
        
        # 注 cache 爪专 
        cache_manager.set(f"processed:{file_id}", result)
        
        return jsonify(result)
    finally:
        # 砖专专 注
        lock.release(f"process:{file_id}", lock_id)
```

---

##  专 专拽转

### 1. 专拽转 爪注

```python
# webapp/cache_metrics.py
from typing import Dict, Any

class CacheMetrics:
    """专 爪注 cache"""
    
    def __init__(self, cache_manager=None):
        self.hit_rate_window = []  #  砖 100 驻注转 专转
        self.response_times = []
        self.cache_manager = cache_manager
        
    def record_hit(self):
        """专砖 cache hit"""
        self.hit_rate_window.append(1)
        if len(self.hit_rate_window) > 100:
            self.hit_rate_window.pop(0)
    
    def record_miss(self):
        """专砖 cache miss"""
        self.hit_rate_window.append(0)
        if len(self.hit_rate_window) > 100:
            self.hit_rate_window.pop(0)
    
    def get_hit_rate(self) -> float:
        """砖 hit rate"""
        if not self.hit_rate_window:
            return 0.0
        return sum(self.hit_rate_window) / len(self.hit_rate_window)
    
    def get_metrics_summary(self) -> Dict:
        """住 专拽转"""
        cache_size = 'N/A'
        if self.cache_manager:
            try:
                info = self.cache_manager.get_info()
                cache_size = info.get('used_memory_human', 'N/A') if info else 'N/A'
            except:
                pass
        
        return {
            'hit_rate': self.get_hit_rate(),
            'total_hits': cache_hits_total._value.get() if cache_hits_total else 0,
            'total_misses': cache_misses_total._value.get() if cache_misses_total else 0,
            'avg_response_time': sum(self.response_times[-100:]) / len(self.response_times[-100:]) if self.response_times else 0,
            'cache_size': cache_size
        }

# 转 -endpoint 专
cache_metrics_collector = CacheMetrics(cache_manager)

@app.route('/api/cache/metrics')
@requires_admin
def cache_metrics():
    """API 专拽转 cache"""
    metrics = cache_metrics_collector.get_metrics_summary()
    return jsonify(metrics)
```

### 2. Dashboard 专 Cache

```html
<!-- webapp/templates/cache_dashboard.html -->
<!DOCTYPE html>
<html dir="rtl" lang="he">
<head>
    <title>专 Cache</title>
    <style>
        .metric-card {
            background: #f5f5f5;
            border-radius: 8px;
            padding: 20px;
            margin: 10px;
            display: inline-block;
            min-width: 200px;
        }
        .metric-value {
            font-size: 2em;
            font-weight: bold;
            color: #2196F3;
        }
        .metric-label {
            color: #666;
            margin-top: 5px;
        }
        .hit-rate-good { color: #4CAF50; }
        .hit-rate-medium { color: #FF9800; }
        .hit-rate-bad { color: #F44336; }
    </style>
</head>
<body>
    <h1> 拽专转 Cache</h1>
    
    <div id="metrics">
        <div class="metric-card">
            <div class="metric-value" id="hit-rate">--</div>
            <div class="metric-label">Hit Rate</div>
        </div>
        
        <div class="metric-card">
            <div class="metric-value" id="total-hits">--</div>
            <div class="metric-label">Total Hits</div>
        </div>
        
        <div class="metric-card">
            <div class="metric-value" id="total-misses">--</div>
            <div class="metric-label">Total Misses</div>
        </div>
        
        <div class="metric-card">
            <div class="metric-value" id="avg-response">--</div>
            <div class="metric-label">Avg Response (ms)</div>
        </div>
    </div>
    
    <canvas id="hitRateChart" width="400" height="200"></canvas>
    
    <script>
        // 注 专拽转  5 砖转
        function updateMetrics() {
            fetch('/api/cache/metrics')
                .then(r => r.json())
                .then(data => {
                    // 注 注专
                    document.getElementById('hit-rate').textContent = 
                        (data.hit_rate * 100).toFixed(1) + '%';
                    document.getElementById('total-hits').textContent = 
                        data.total_hits.toLocaleString();
                    document.getElementById('total-misses').textContent = 
                        data.total_misses.toLocaleString();
                    document.getElementById('avg-response').textContent = 
                        data.avg_response_time.toFixed(2);
                    
                    // 爪注转 hit rate
                    const hitRateEl = document.getElementById('hit-rate');
                    hitRateEl.className = 'metric-value';
                    if (data.hit_rate > 0.8) {
                        hitRateEl.classList.add('hit-rate-good');
                    } else if (data.hit_rate > 0.5) {
                        hitRateEl.classList.add('hit-rate-medium');
                    } else {
                        hitRateEl.classList.add('hit-rate-bad');
                    }
                });
        }
        
        updateMetrics();
        setInterval(updateMetrics, 5000);
    </script>
</body>
</html>
```

---

## 锔 专转 驻转专 注转 驻爪转

### 1. 注转 Serialization 注 Flask Response Objects

**注:** Flask endpoints 专 注转 `Response` objects (-`jsonify()`) 砖 转 -serialization 砖专 -JSON.

**驻转专 专:**
```python
# 拽专专 dynamic_cache - 拽  砖 住 转爪
if hasattr(result, 'get_json'):
    #   Response object, 抓 专拽 转 -data
    cache_data = result.get_json()
    if cache_data:
        cache_manager.set_dynamic(cache_key, cache_data, content_type, context)
elif isinstance(result, (dict, list, str, int, float, bool)):
    # 专拽 驻住 serializable
    cache_manager.set_dynamic(cache_key, result, content_type, context)
```

**爪:** 转 专 dict 驻拽爪 转 拽专专 专 -jsonify 注转 爪专.

### 2. Import Dependencies 住专

**注转 驻爪转:**
- 住专 `import time` -`CacheRefresher`
- 住专 `cache_manager` instance -`CacheMetrics`

**驻转专:** 转 拽 转  -imports 转转  :
```python
# 专砖转 imports  注专转 cache
import json
import time
import threading
import hashlib
import random
from typing import Dict, Any, List, Optional, Callable
from functools import wraps
from flask import request, g, jsonify, make_response
import redis
import schedule
```

### 3. Circular Dependencies

**注:** imports   

**驻转专:** 砖转砖 -lazy imports  dependency injection:
```python
# 拽 import 砖专
from cache_manager import cache_manager  # 注 爪专 circular

# 砖转砖 -injection
class CacheMetrics:
    def __init__(self, cache_manager=None):
        self.cache_manager = cache_manager or get_cache_manager()
```

##  Best Practices 爪转

### 1.  爪注 拽注转 TTL

| 住 转 | TTL 抓 | 注专转 |
|---------|-----------|--------|
| 转 住 (拽爪) | 30-60 拽转 | 专   注专 专 |
| 专砖转 转 | 1-5 拽转 | 拽爪专 砖注转 砖 |
| 住住拽转 | 5-10 拽转 | 专 住住拽转 住专转 |
| 专专 Markdown | 15-30 拽转 | 转  专转 |
| 转爪转 驻砖 | 2-5 拽转 | 转 转专转 注 |
| 专转 砖转砖 | 30-60 砖转 | cache 拽爪专 砖  |

### 2. 驻转转 Cache 注

```python
def build_cache_key(*parts) -> str:
    """转 驻转 cache 注 """
    # 住 拽 专拽
    clean_parts = [str(p) for p in parts if p]
    
    # 驻转 转 注转
    key = ':'.join(clean_parts)
    key = key.replace(' ', '_').replace('/', '-')
    
    # 转 专
    if len(key) > 200:
        # 砖砖 -hash 拽爪专
        key_hash = hashlib.md5(key.encode()).hexdigest()[:8]
        key = f"{key[:150]}:{key_hash}"
    
    return key
```

### 3. Cache Invalidation 

```python
class CacheInvalidator:
    """  cache """
    
    @staticmethod
    def invalidate_file_caches(file_id: str, user_id: str):
        """  -caches 拽砖专 拽抓"""
        patterns = [
            f"file_content:{file_id}*",
            f"md_render:{file_id}*",
            f"files:{user_id}:*",  # 专砖转 拽爪 砖 砖转砖
            f"stats:user:{user_id}"  # 住住拽转 砖转砖
        ]
        
        for pattern in patterns:
            cache_manager.delete_pattern(pattern)
    
    @staticmethod
    def invalidate_user_caches(user_id: str):
        """  -caches 砖 砖转砖"""
        cache_manager.delete_pattern(f"*:{user_id}:*")
```

### 4. 驻 转拽转 Redis

```python
class ResilientCache:
    """Cache 注 转拽转"""
    
    def __init__(self, cache_manager, fallback_ttl=60):
        self.cache = cache_manager
        self.fallback_ttl = fallback_ttl
        self.local_cache = {}  # cache 拽 -fallback
        
    def get_with_fallback(self, key: str, compute_func: Callable) -> Any:
        """拽专 注 fallback 拽专 砖 转拽"""
        try:
            # 住 拽专 -Redis
            value = self.cache.get(key)
            if value is not None:
                return value
        except Exception as e:
            logger.warning(f"Redis error: {e}, using fallback")
            # 住 cache 拽
            if key in self.local_cache:
                cached_at, value = self.local_cache[key]
                if time.time() - cached_at < self.fallback_ttl:
                    return value
        
        # 砖 注专
        value = compute_func()
        
        # 砖专 -Redis  驻砖专
        try:
            self.cache.set(key, value, self.fallback_ttl)
        except Exception:
            # 砖专 -cache 拽 -fallback
            self.local_cache[key] = (time.time(), value)
            # 拽 cache 拽 砖
            self._cleanup_local_cache()
        
        return value
    
    def _cleanup_local_cache(self):
        """拽 cache 拽 砖"""
        if len(self.local_cache) > 100:
            # 拽转 20% 砖 转专
            sorted_items = sorted(self.local_cache.items(), 
                                key=lambda x: x[1][0])
            for key, _ in sorted_items[:20]:
                del self.local_cache[key]
```

---

##  转 注 专

### 砖 1: 转砖转转 住住转 (砖注 1)
- [ ] 注转 `DynamicTTL` -`ActivityBasedTTL`
- [ ] 砖专 `CacheManager` 注 TTL 
- [ ] 住驻转 拽专专 `@dynamic_cache`
- [ ] 专转 专拽转 住住转

### 砖 2: 注 -endpoints 拽专 (砖注 2)
- [ ] Cache 专砖转 拽爪 (`/api/files`)
- [ ] Cache 住住拽转 (`/api/stats`)
- [ ] Cache 专专 Markdown
- [ ] 拽转 爪注 专砖转

### 砖 3: 驻爪 -warming (砖注 3)
- [ ] 注转 cache warming
- [ ] 专注  专拽注
- [ ] Cache invalidation 
- [ ] Dashboard 专

### 砖 4: 爪 砖驻专 (砖注 4)
- [ ]  TTL 驻 转 砖砖 转
- [ ] 住驻转 fallback mechanisms
- [ ] 驻爪 砖 驻转转 cache
- [ ] 转注 -best practices

---

##  转 爪

### KPIs 专:
1. **Hit Rate** - 注: 注 80% 专 
2. ** 转 爪注** - 注: 驻转 砖 70%
3. **注住 注 MongoDB** - 注: 驻转 砖 60%
4. **专 Redis** - 注: 驻转 -500MB
5. **砖注转 专爪 砖转砖** -  专 驻拽

### 专 :
- Dashboard  转 注 专拽转
- 转专转 注 hit rate 
-  砖注 注 专
- 转 patterns 砖 cache misses

---

##  驻 驻转专 注转 驻爪转

### 1. 注转 Thundering Herd
砖-cache 驻 驻专 驻驻专, 住驻专 专 砖 拽砖转 拽转 注转 转 -DB:

```python
def prevent_thundering_herd(key: str, compute_func: Callable, ttl: int = 300):
    """注转 thundering herd 注 jitter -probabilistic expiration"""
    
    # 住驻转 jitter -TTL
    jittered_ttl = ttl + random.randint(-ttl//10, ttl//10)
    
    # Probabilistic early expiration
    cached = cache_manager.get(key)
    if cached:
        # 砖 住转专转 专注 拽
        age = time.time() - cached.get('cached_at', 0)
        refresh_probability = age / ttl
        
        if random.random() < refresh_probability * 0.1:  # 10% 住 拽住
            # 专注 拽 专拽注
            threading.Thread(
                target=lambda: cache_manager.set(key, compute_func(), jittered_ttl),
                daemon=True
            ).start()
    
    return cached or compute_func()
```

### 2.  专
```python
# 住驻转  驻专
import structlog
logger = structlog.get_logger()

def debug_cache_operation(operation: str, key: str, hit: bool, latency: float):
    logger.info(
        "cache_operation",
        operation=operation,
        key=key,
        hit=hit,
        latency_ms=latency * 1000,
        instance_id=INSTANCE_ID
    )
```

### 3. 拽转 专爪
```python
# tests/test_cache_consistency.py
def test_multi_instance_consistency():
    """拽转 注拽转  instances"""
    # 住爪 砖 2 instances
    instance1 = CompleteCacheSolution(app1, db, cache1)
    instance2 = CompleteCacheSolution(app2, db, cache2)
    
    # 注 -instance1
    instance1.invalidator.invalidate_on_update('files', 'file123', {}, 'user1')
    
    # 转 住专
    time.sleep(0.1)
    
    #  砖-instance2 拽 转 注
    assert instance2.cache.get('files:file123') is None
```

##  住

注专转 caching 转拽转 注 TTL  注拽转   instances   砖专 注 转专 砖驻专 爪注 转. 

**驻转专转 专 注转 砖注转:**

1. **Cache Invalidation 注转 注:**
   - Immediate invalidation 注 patterns
   - Write-through caching
   - Event-driven invalidation
   - Tagged cache  拽爪转

2. **注拽转  Instances:**
   - Redis Pub/Sub 住专
   - Versioned cache
   - Distributed locks
   - Shared cache configuration

**转专转 :**
- 砖驻专 专  转
- 注拽转 转 
- 注转 race conditions
- 住专   砖专转

**爪转 砖:**
1. 转 注 invalidation 驻砖 住祝 专转 专
2. 注 monitoring 拽祝  注转 注拽转
3. 拽 转 驻转专 爪 注住 
4. 砖拽 Redis Cluster 转 

爪 注! 