name: "âš¡ Performance Tests"

on:
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review, converted_to_draft]
  schedule:
    - cron: '0 4 * * *'
  workflow_dispatch:

jobs:
  performance-test:
    name: "ðŸš€ Load Testing"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: "ðŸ”¥ Run Load Tests"
        run: |
          echo "ðŸ”¥ Running performance tests..."
          # Place your load-testing tool invocation here (e.g., k6, locust)
          # k6 run performance/load-test.js

  python-performance:
    name: "ðŸ PyTest Performance"
    runs-on: ubuntu-latest
    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
          cache-dependency-path: |
            requirements/*.txt

      - name: ðŸ“¦ Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements/development.txt
          pip freeze | sort > constraints.txt
          pip install -r requirements/development.txt -c constraints.txt
          pip check || true

      # ×‘×¨×™×¨×ª ×ž×—×“×œ: ×œ×”×¨×™×¥ ×”×›×œ (×›×•×œ×œ heavy)
      - name: Run ALL performance tests (default)
        if: github.event_name != 'pull_request' || !(github.event.pull_request.draft && contains(join(github.event.pull_request.labels.*.name, ','), 'perf-light'))
        run: |
          echo "Running all performance tests (if any)..."
          pytest -v -o addopts="" -m performance || echo "No performance tests found or none collected."
      - name: Collect test durations (default)
        if: always() && (github.event_name != 'pull_request' || !(github.event.pull_request.draft && contains(join(github.event.pull_request.labels.*.name, ','), 'perf-light')))
        run: |
          echo "Collecting durations for all performance tests..."
          pytest -o addopts="" -m performance --durations=0 --json-report --json-report-file=durations.json || true
          cat durations.json | jq '.summary.durations' > durations-summary.json || echo '{}' > durations-summary.json

      # ×›××©×¨ ×”â€‘PR ×”×•× draft ×•×ž×ª×•×™×’ perf-light: ×œ×”×¨×™×¥ ×¨×§ ×§×œ×™×
      - name: Run LIGHT performance tests (draft + perf-light)
        if: github.event_name == 'pull_request' && github.event.pull_request.draft && contains(join(github.event.pull_request.labels.*.name, ','), 'perf-light')
        env:
          ONLY_LIGHT_PERF: '1'
        run: |
          echo "Running light performance tests (if any)..."
          pytest -v -o addopts="" -m performance || echo "No performance tests found or none collected."
      - name: Collect test durations (light)
        if: always() && (github.event_name == 'pull_request' && github.event.pull_request.draft && contains(join(github.event.pull_request.labels.*.name, ','), 'perf-light'))
        env:
          ONLY_LIGHT_PERF: '1'
        run: |
          echo "Collecting durations for light performance tests..."
          pytest -o addopts="" -m performance --durations=0 --json-report --json-report-file=durations.json || true
          cat durations.json | jq '.summary.durations' > durations-summary.json || echo '{}' > durations-summary.json

      - name: Upload durations artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: perf-durations-${{ github.run_id }}
          path: |
            durations.json
            durations-summary.json
          if-no-files-found: warn