name: "⚡ Performance Tests"

on:
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review, converted_to_draft]
  schedule:
    - cron: '0 4 * * *'
  workflow_dispatch:

jobs:
  performance-test:
    name: "🚀 Load Testing"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: "🔥 Run Load Tests"
        run: |
          echo "🔥 Running performance tests..."
          # Place your load-testing tool invocation here (e.g., k6, locust)
          # k6 run performance/load-test.js

  python-performance:
    name: "🐍 PyTest Performance"
    runs-on: ubuntu-latest
    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4

      - name: 🐍 Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
          cache-dependency-path: |
            requirements/*.txt

      - name: 📦 Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements/development.txt
          pip freeze | sort > constraints.txt
          pip install -r requirements/development.txt -c constraints.txt
          pip check || true

      # ברירת מחדל: להריץ הכל (כולל heavy)
      - name: Run ALL performance tests (default)
        if: github.event_name != 'pull_request' || !(github.event.pull_request.draft && contains(join(github.event.pull_request.labels.*.name, ','), 'perf-light'))
        run: |
          echo "Running all performance tests (if any)..."
          pytest -v -o addopts="" -m performance --perf-heavy-percentile=90 || echo "No performance tests found or none collected."
      - name: Collect test durations (default)
        if: always() && (github.event_name != 'pull_request' || !(github.event.pull_request.draft && contains(join(github.event.pull_request.labels.*.name, ','), 'perf-light')))
        run: |
          echo "Collecting durations for all performance tests..."
          pytest -o addopts="" -m performance --durations=0 --json-report --json-report-file=durations.json || true
          cat durations.json | jq '.summary.durations' > durations-summary.json || echo '{}' > durations-summary.json

      # כאשר ה‑PR הוא draft ומתויג perf-light: להריץ רק קלים
      - name: Run LIGHT performance tests (draft + perf-light)
        if: github.event_name == 'pull_request' && github.event.pull_request.draft && contains(join(github.event.pull_request.labels.*.name, ','), 'perf-light')
        env:
          ONLY_LIGHT_PERF: '1'
        run: |
          echo "Running light performance tests (if any)..."
          pytest -v -o addopts="" -m performance --perf-heavy-percentile=90 || echo "No performance tests found or none collected."
      - name: Collect test durations (light)
        if: always() && (github.event_name == 'pull_request' && github.event.pull_request.draft && contains(join(github.event.pull_request.labels.*.name, ','), 'perf-light'))
        env:
          ONLY_LIGHT_PERF: '1'
        run: |
          echo "Collecting durations for light performance tests..."
          pytest -o addopts="" -m performance --durations=0 --json-report --json-report-file=durations.json || true
          cat durations.json | jq '.summary.durations' > durations-summary.json || echo '{}' > durations-summary.json

      - name: Upload durations artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: perf-durations-${{ github.run_id }}
          path: |
            durations.json
            durations-summary.json
          if-no-files-found: warn

      - name: Comment PR with performance report
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const runUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
            let top = '';
            let threshold = null;
            try {
              const raw = fs.readFileSync('durations.json', 'utf8');
              const data = JSON.parse(raw);
              const durations = (data.summary && data.summary.durations) || [];
              // Load last threshold from log if present
              try {
                const log = fs.readFileSync(process.env.GITHUB_STEP_SUMMARY || '', 'utf8');
                const m = /Heavy threshold auto-calculated: ([0-9.]+)s \(P(\d+)\)/.exec(log);
                if (m) threshold = parseFloat(m[1]);
              } catch(e) {}
              // durations entries are like: { "test": "nodeid", "seconds": 0.123 }
              durations.sort((a,b) => (b.seconds||0) - (a.seconds||0));
              const topN = durations.slice(0, 10).map((d, i) => ` ${i+1}. ${d.test} — ${d.seconds?.toFixed(3)}s`).join('\n');
              if (topN) {
                // add warning icon for entries exceeding threshold
                const lines = durations.slice(0,10).map((d,i)=>{
                  const warn = (threshold && d.seconds && d.seconds >= threshold) ? ' ⚠️' : '';
                  return ` ${i+1}. ${d.test} — ${d.seconds?.toFixed(3)}s${warn}`;
                }).join('\n');
                top = `\n\n### Top slow tests\n\n${lines}`;
              }
            } catch (e) {
              // ignore missing/invalid file
            }

            const body = `## ⏱️ Performance report\n\n- Run: ${runUrl}\n- Artifact: perf-durations-${context.runId}${top}`;
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            const existing = comments.find(c => c.user.type === 'Bot' && c.body && c.body.includes('Performance report'));
            if (existing) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existing.id,
                body,
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body,
              });
            }