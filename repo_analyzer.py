"""
×× ×ª×— ×¨×™×¤×•×–×™×˜×•×¨×™ GitHub - ×× ×ª×— ××‘× ×” ×•××¦×™×¢ ×©×™×¤×•×¨×™×
"""

import os
import re
import json
import logging
import asyncio
import aiohttp
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta
from urllib.parse import urlparse
import base64

logger = logging.getLogger(__name__)

# ×”×’×“×¨×•×ª ×•×§×‘×•×¢×™×
MAX_FILE_SIZE = 100 * 1024  # 100KB
MAX_FILES = 50
GITHUB_API_BASE = "https://api.github.com"
FILE_EXTENSIONS = {
    'python': ['.py', '.pyw'],
    'javascript': ['.js', '.jsx', '.mjs'],
    'typescript': ['.ts', '.tsx'],
    'java': ['.java'],
    'csharp': ['.cs'],
    'cpp': ['.cpp', '.cc', '.cxx', '.hpp', '.h'],
    'go': ['.go'],
    'rust': ['.rs'],
    'ruby': ['.rb'],
    'php': ['.php'],
    'swift': ['.swift'],
    'kotlin': ['.kt', '.kts'],
    'scala': ['.scala'],
    'r': ['.r', '.R'],
    'dart': ['.dart'],
    'lua': ['.lua'],
    'perl': ['.pl', '.pm'],
    'shell': ['.sh', '.bash', '.zsh'],
    'sql': ['.sql'],
    'html': ['.html', '.htm'],
    'css': ['.css', '.scss', '.sass', '.less'],
    'yaml': ['.yaml', '.yml'],
    'json': ['.json'],
    'xml': ['.xml'],
    'markdown': ['.md', '.markdown']
}

DEPENDENCY_FILES = [
    'requirements.txt', 'setup.py', 'pyproject.toml', 'Pipfile',  # Python
    'package.json', 'package-lock.json', 'yarn.lock',  # JavaScript/Node
    'pom.xml', 'build.gradle', 'build.gradle.kts',  # Java
    'Cargo.toml',  # Rust
    'go.mod', 'go.sum',  # Go
    'composer.json',  # PHP
    'Gemfile', 'Gemfile.lock',  # Ruby
    '.csproj', 'packages.config',  # C#
    'pubspec.yaml',  # Dart/Flutter
]

IMPORTANT_FILES = ['README.md', 'LICENSE', '.gitignore', 'CONTRIBUTING.md', 'CODE_OF_CONDUCT.md']


class RepoAnalyzer:
    """××—×œ×§×” ×œ× ×™×ª×•×— ×¨×™×¤×•×–×™×˜×•×¨×™ GitHub"""
    
    def __init__(self, github_token: Optional[str] = None):
        self.github_token = github_token or os.getenv('GITHUB_TOKEN')
        self.headers = {
            'Accept': 'application/vnd.github.v3+json',
            'User-Agent': 'CodeKeeperBot-RepoAnalyzer'
        }
        if self.github_token:
            self.headers['Authorization'] = f'token {self.github_token}'
    
    def set_token(self, token: str):
        """×¢×“×›×•×Ÿ ×”×˜×•×§×Ÿ ×‘×–××Ÿ ×¨×™×¦×”"""
        self.github_token = token
        if token:
            self.headers['Authorization'] = f'token {token}'
        elif 'Authorization' in self.headers:
            del self.headers['Authorization']
    
    async def fetch_and_analyze_repo(self, url: str) -> Dict[str, Any]:
        """
        ×©×•×œ×£ ×•×× ×ª×— ×¨×™×¤×•×–×™×˜×•×¨×™ GitHub
        
        Args:
            url: URL ×©×œ ×”×¨×™×¤×•×–×™×˜×•×¨×™
            
        Returns:
            Dictionary ×¢× ×ª×•×¦××•×ª ×”× ×™×ª×•×—
        """
        try:
            # ×¤×¨×¡×•×¨ URL
            owner, repo = self._parse_github_url(url)
            if not owner or not repo:
                return {'error': 'URL ×œ× ×ª×§×™×Ÿ. ×“×•×’××”: https://github.com/owner/repo'}
            
            async with aiohttp.ClientSession() as session:
                # ×©×œ×‘ 1: ×§×‘×œ×ª ××™×“×¢ ×‘×¡×™×¡×™ ×¢×œ ×”×¨×™×¤×•
                repo_info = await self._fetch_repo_info(session, owner, repo)
                if 'error' in repo_info:
                    return repo_info
                
                # ×©×œ×‘ 2: ×§×‘×œ×ª ××‘× ×” ×”×¨×™×¤×• (×¢×•××§ 1)
                tree = await self._fetch_repo_tree(session, owner, repo)
                if 'error' in tree:
                    return tree
                
                # ×©×œ×‘ 3: ×”×•×¨×“×ª ×§×‘×¦×™× ×¨×œ×•×•× ×˜×™×™×
                files_content = await self._fetch_relevant_files(session, owner, repo, tree)
                
                # ×©×œ×‘ 4: × ×™×ª×•×— ×”×××¦××™×
                analysis = self._analyze_repo_data(repo_info, tree, files_content)
                
                return {
                    'success': True,
                    'repo_url': url,
                    'owner': owner,
                    'repo_name': repo,
                    'repo_info': repo_info,
                    'analysis': analysis,
                    'files_content': files_content  # ×œ××§×¨×” ×©× ×¨×¦×” ×œ× ×ª×— ×™×•×ª×¨ ×œ×¢×•××§
                }
                
        except Exception as e:
            logger.error(f"Error analyzing repo {url}: {e}")
            return {'error': f'×©×’×™××” ×‘× ×™×ª×•×— ×”×¨×™×¤×•: {str(e)}'}
    
    def _parse_github_url(self, url: str) -> Tuple[Optional[str], Optional[str]]:
        """×¤×¨×¡×•×¨ URL ×©×œ GitHub ×œ×§×‘×œ×ª owner ×•-repo"""
        patterns = [
            r'github\.com/([^/]+)/([^/\?#]+)',
            r'github\.com:([^/]+)/([^/\?#]+)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                owner, repo = match.groups()
                # ×”×¡×¨×ª .git ×× ×§×™×™×
                repo = repo.replace('.git', '')
                return owner, repo
        
        return None, None
    
    async def _fetch_repo_info(self, session: aiohttp.ClientSession, owner: str, repo: str) -> Dict:
        """×©×œ×™×¤×ª ××™×“×¢ ×‘×¡×™×¡×™ ×¢×œ ×”×¨×™×¤×•"""
        url = f"{GITHUB_API_BASE}/repos/{owner}/{repo}"
        
        try:
            async with session.get(url, headers=self.headers) as response:
                if response.status == 404:
                    return {'error': '×¨×™×¤×•×–×™×˜×•×¨×™ ×œ× × ××¦× ××• ×¤×¨×˜×™'}
                elif response.status == 403:
                    return {'error': '×—×¨×™×’×ª ××’×‘×œ×ª API ×©×œ GitHub'}
                elif response.status != 200:
                    return {'error': f'×©×’×™××” ×‘×§×‘×œ×ª ××™×“×¢: {response.status}'}
                
                return await response.json()
        except Exception as e:
            return {'error': f'×©×’×™××” ×‘×—×™×‘×•×¨ ×œ-GitHub: {str(e)}'}
    
    async def _fetch_repo_tree(self, session: aiohttp.ClientSession, owner: str, repo: str) -> Dict:
        """×©×œ×™×¤×ª ××‘× ×” ×”×¨×™×¤×• (×¢×•××§ 1)"""
        url = f"{GITHUB_API_BASE}/repos/{owner}/{repo}/contents"
        
        try:
            async with session.get(url, headers=self.headers) as response:
                if response.status != 200:
                    return {'error': f'×©×’×™××” ×‘×§×‘×œ×ª ××‘× ×” ×”×¨×™×¤×•: {response.status}'}
                
                return {'items': await response.json()}
        except Exception as e:
            return {'error': f'×©×’×™××” ×‘×§×‘×œ×ª ××‘× ×”: {str(e)}'}
    
    async def _fetch_relevant_files(self, session: aiohttp.ClientSession, owner: str, repo: str, tree: Dict) -> Dict[str, Any]:
        """×”×•×¨×“×ª ×§×‘×¦×™× ×¨×œ×•×•× ×˜×™×™×"""
        files_content = {}
        files_downloaded = 0
        
        if 'error' in tree:
            return files_content
        
        # ×¨×©×™××ª ×§×‘×¦×™× ×œ×”×•×¨×“×”
        files_to_download = []
        
        for item in tree.get('items', []):
            if files_downloaded >= MAX_FILES:
                break
                
            if item['type'] != 'file':
                continue
                
            file_name = item['name']
            file_size = item.get('size', 0)
            
            # ×“×œ×’ ×¢×œ ×§×‘×¦×™× ×’×“×•×œ×™× ××“×™
            if file_size > MAX_FILE_SIZE:
                continue
            
            # ×‘×“×•×§ ×× ×–×” ×§×•×‘×¥ ×¨×œ×•×•× ×˜×™
            is_relevant = False
            
            # ×§×‘×¦×™× ×—×©×•×‘×™×
            if file_name in IMPORTANT_FILES or file_name in DEPENDENCY_FILES:
                is_relevant = True
            
            # ×§×‘×¦×™ ×§×•×“
            if not is_relevant:
                for lang, extensions in FILE_EXTENSIONS.items():
                    if any(file_name.endswith(ext) for ext in extensions):
                        is_relevant = True
                        break
            
            if is_relevant:
                files_to_download.append(item)
        
        # ×”×•×¨×“×ª ×”×§×‘×¦×™× ×‘××§×‘×™×œ
        tasks = []
        for file_item in files_to_download[:MAX_FILES]:
            task = self._fetch_file_content(session, file_item['download_url'], file_item['name'])
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for i, result in enumerate(results):
            if not isinstance(result, Exception) and result:
                file_name = files_to_download[i]['name']
                files_content[file_name] = result
        
        return files_content
    
    async def _fetch_file_content(self, session: aiohttp.ClientSession, url: str, file_name: str) -> Optional[Dict]:
        """×”×•×¨×“×ª ×ª×•×›×Ÿ ×§×•×‘×¥ ×‘×•×“×“"""
        try:
            async with session.get(url) as response:
                if response.status == 200:
                    content = await response.text()
                    lines = content.split('\n')
                    return {
                        'content': content[:5000] if len(content) > 5000 else content,  # ×”×’×‘×œ×” ×œ-5000 ×ª×•×•×™×
                        'lines_count': len(lines),
                        'size': len(content),
                        'truncated': len(content) > 5000
                    }
        except Exception as e:
            logger.error(f"Error fetching file {file_name}: {e}")
            return None
    
    def _analyze_repo_data(self, repo_info: Dict, tree: Dict, files_content: Dict) -> Dict:
        """× ×™×ª×•×— ×”× ×ª×•× ×™× ×©× ××¡×¤×•"""
        analysis = {
            'has_readme': False,
            'has_license': False,
            'has_gitignore': False,
            'has_contributing': False,
            'has_code_of_conduct': False,
            'has_tests': False,
            'has_ci_cd': False,
            'languages': {},
            'dependency_files': [],
            'large_files': [],
            'long_functions': [],
            'total_files': 0,
            'total_directories': 0,
            'structure': [],
            'dependencies': {},
            'suggestions_data': {}  # × ×ª×•× ×™× × ×•×¡×¤×™× ×œ×¦×•×¨×š ×”×¦×¢×•×ª
        }
        
        # × ×™×ª×•×— ××™×“×¢ ×‘×¡×™×¡×™ ××”×¨×™×¤×•
        if repo_info and 'error' not in repo_info:
            analysis['stars'] = repo_info.get('stargazers_count', 0)
            analysis['forks'] = repo_info.get('forks_count', 0)
            analysis['open_issues'] = repo_info.get('open_issues_count', 0)
            analysis['created_at'] = repo_info.get('created_at')
            analysis['updated_at'] = repo_info.get('updated_at')
            analysis['default_branch'] = repo_info.get('default_branch', 'main')
            analysis['description'] = repo_info.get('description', '')
            analysis['topics'] = repo_info.get('topics', [])
        
        # × ×™×ª×•×— ××‘× ×” ×”×¨×™×¤×•
        if tree and 'items' in tree:
            for item in tree['items']:
                if item['type'] == 'file':
                    analysis['total_files'] += 1
                    file_name = item['name']
                    
                    # ×‘×“×™×§×ª ×§×‘×¦×™× ×—×©×•×‘×™×
                    if file_name.upper() == 'README.MD' or file_name == 'README':
                        analysis['has_readme'] = True
                    elif file_name.upper() == 'LICENSE' or file_name.upper().startswith('LICENSE.'):
                        analysis['has_license'] = True
                    elif file_name == '.gitignore':
                        analysis['has_gitignore'] = True
                    elif file_name.upper() == 'CONTRIBUTING.MD':
                        analysis['has_contributing'] = True
                    elif file_name.upper() == 'CODE_OF_CONDUCT.MD':
                        analysis['has_code_of_conduct'] = True
                    
                    # ×‘×“×™×§×ª CI/CD
                    if file_name in ['.travis.yml', '.circleci', 'Jenkinsfile', 'azure-pipelines.yml']:
                        analysis['has_ci_cd'] = True
                    
                    # ×¡×¤×™×¨×ª ×©×¤×•×ª
                    for lang, extensions in FILE_EXTENSIONS.items():
                        if any(file_name.endswith(ext) for ext in extensions):
                            analysis['languages'][lang] = analysis['languages'].get(lang, 0) + 1
                    
                    # ×–×™×”×•×™ ×§×‘×¦×™ ×ª×œ×•×™×•×ª
                    if file_name in DEPENDENCY_FILES:
                        analysis['dependency_files'].append(file_name)
                    
                    # ×–×™×”×•×™ ×§×‘×¦×™× ×’×“×•×œ×™×
                    file_size = item.get('size', 0)
                    if file_size > 50000:  # ×§×‘×¦×™× ××¢×œ 50KB
                        analysis['large_files'].append({
                            'name': file_name,
                            'size': file_size,
                            'size_kb': round(file_size / 1024, 2)
                        })
                
                elif item['type'] == 'dir':
                    analysis['total_directories'] += 1
                    dir_name = item['name']
                    
                    # ×‘×“×™×§×ª ×ª×™×§×™×•×ª ××™×•×—×“×•×ª
                    if dir_name in ['test', 'tests', 'spec', 'specs', '__tests__']:
                        analysis['has_tests'] = True
                    elif dir_name == '.github':
                        analysis['has_ci_cd'] = True  # GitHub Actions
                    
                    analysis['structure'].append({'type': 'dir', 'name': dir_name})
        
        # × ×™×ª×•×— ×ª×•×›×Ÿ ×”×§×‘×¦×™×
        for file_name, content_data in files_content.items():
            if content_data and 'content' in content_data:
                content = content_data.get('content', '')
                lines_count = content_data.get('lines_count', 0)
                
                # ×–×™×”×•×™ ×¤×•× ×§×¦×™×•×ª ××¨×•×›×•×ª (×¤×©×•×˜ - ×¡×¤×™×¨×ª ×©×•×¨×•×ª ×‘×™×Ÿ def/function)
                if file_name.endswith('.py'):
                    functions = re.findall(r'def\s+(\w+)\s*\([^)]*\):', content)
                    if lines_count > 500:
                        analysis['long_functions'].append({
                            'file': file_name,
                            'lines': lines_count,
                            'functions_found': len(functions)
                        })
                
                # × ×™×ª×•×— ×§×‘×¦×™ ×ª×œ×•×™×•×ª
                if file_name == 'requirements.txt':
                    deps = self._parse_requirements(content)
                    analysis['dependencies']['python'] = deps
                elif file_name == 'package.json':
                    deps = self._parse_package_json(content)
                    analysis['dependencies']['npm'] = deps
        
        return analysis
    
    def _parse_requirements(self, content: str) -> List[Dict]:
        """×¤×¨×¡×•×¨ requirements.txt"""
        dependencies = []
        for line in content.split('\n'):
            line = line.strip()
            if line and not line.startswith('#'):
                # ×¤×¨×¡×•×¨ ×‘×¡×™×¡×™ ×©×œ ×ª×œ×•×ª
                match = re.match(r'^([a-zA-Z0-9\-_]+)([><=~!]+.*)?', line)
                if match:
                    name = match.group(1)
                    version = match.group(2) or ''
                    dependencies.append({
                        'name': name,
                        'version': version.strip() if version else 'any'
                    })
        return dependencies
    
    def _parse_package_json(self, content: str) -> List[Dict]:
        """×¤×¨×¡×•×¨ package.json"""
        dependencies = []
        try:
            data = json.loads(content)
            for dep_type in ['dependencies', 'devDependencies']:
                if dep_type in data:
                    for name, version in data[dep_type].items():
                        dependencies.append({
                            'name': name,
                            'version': version,
                            'dev': dep_type == 'devDependencies'
                        })
        except json.JSONDecodeError:
            pass
        return dependencies
    
    def generate_improvement_suggestions(self, analysis_data: Dict) -> List[Dict]:
        """
        ×™×¦×™×¨×ª ×”×¦×¢×•×ª ×œ×©×™×¤×•×¨ ×¢×œ ×‘×¡×™×¡ ×”× ×™×ª×•×—
        
        Args:
            analysis_data: ×ª×•×¦××•×ª ×”× ×™×ª×•×— ×-fetch_and_analyze_repo
            
        Returns:
            ×¨×©×™××ª ×”×¦×¢×•×ª ×œ×©×™×¤×•×¨
        """
        suggestions = []
        
        if 'error' in analysis_data:
            return suggestions
        
        analysis = analysis_data.get('analysis', {})
        
        # ×‘×“×™×§×ª ×§×‘×¦×™× ×—×¡×¨×™× ×—×©×•×‘×™×
        if not analysis.get('has_license'):
            suggestions.append({
                'id': 'add_license',
                'title': 'ğŸ”’ ×”×•×¡×£ ×§×•×‘×¥ LICENSE',
                'why': '×¤×¨×•×™×§×˜ ×œ×œ× ×¨×™×©×™×•×Ÿ = ×›×œ ×”×–×›×•×™×•×ª ×©××•×¨×•×ª. ×–×” ××•× ×¢ ×××—×¨×™× ×œ×”×©×ª××© ×‘×§×•×“',
                'how': '×”×•×¡×£ ×§×•×‘×¥ LICENSE ×¢× ×¨×™×©×™×•×Ÿ ××ª××™× (MIT/Apache 2.0/GPL)',
                'impact': 'high',
                'effort': 'low',
                'category': 'legal'
            })
        
        if not analysis.get('has_readme'):
            suggestions.append({
                'id': 'add_readme',
                'title': 'ğŸ“ ×”×•×¡×£ ×§×•×‘×¥ README.md',
                'why': 'README ×”×•× ×”×¤× ×™× ×©×œ ×”×¤×¨×•×™×§×˜ - ×‘×œ×¢×“×™×• ××£ ××—×“ ×œ× ×™×‘×™×Ÿ ××” ×”×¤×¨×•×™×§×˜ ×¢×•×©×”',
                'how': '×¦×•×¨ README.md ×¢×: ×ª×™××•×¨, ×”×ª×§× ×”, ×©×™××•×©, ×ª×¨×•××”',
                'impact': 'high',
                'effort': 'medium',
                'category': 'documentation'
            })
        elif analysis.get('has_readme'):
            # ×‘×“×•×§ ×× README ×§×¦×¨ ××“×™
            readme_content = analysis_data.get('files_content', {}).get('README.md', {})
            if readme_content and readme_content.get('lines_count', 0) < 10:
                suggestions.append({
                    'id': 'improve_readme',
                    'title': 'ğŸ“ ×©×¤×¨ ××ª ×”-README',
                    'why': 'README ×§×¦×¨ ××“×™ - ×—×¡×¨ ××™×“×¢ ×—×©×•×‘ ×œ××©×ª××©×™×',
                    'how': '×”×•×¡×£: ×“×•×’×××•×ª ×§×•×“, ×ª××•× ×•×ª, badges, ×¨×©×™××ª features',
                    'impact': 'medium',
                    'effort': 'medium',
                    'category': 'documentation'
                })
        
        if not analysis.get('has_gitignore'):
            suggestions.append({
                'id': 'add_gitignore',
                'title': 'ğŸ”§ ×”×•×¡×£ ×§×•×‘×¥ .gitignore',
                'why': '××•× ×¢ ×”×¢×œ××ª ×§×‘×¦×™× ×œ× ×¨×¦×•×™×™× ×œ-Git (node_modules, __pycache__, .env)',
                'how': '×¦×•×¨ .gitignore ××ª××™× ×œ×©×¤×”. ×”×©×ª××© ×‘-gitignore.io',
                'impact': 'medium',
                'effort': 'low',
                'category': 'configuration'
            })
        
        # ×‘×“×™×§×ª ×ª×œ×•×™×•×ª
        if 'python' in analysis.get('dependencies', {}):
            deps = analysis['dependencies']['python']
            unpinned = [d for d in deps if d.get('version') == 'any' or not d.get('version')]
            if unpinned:
                suggestions.append({
                    'id': 'pin_dependencies',
                    'title': 'ğŸ“¦ × ×¢×œ ×’×¨×¡××•×ª ×ª×œ×•×™×•×ª Python',
                    'why': f'×™×© {len(unpinned)} ×ª×œ×•×™×•×ª ×œ×œ× ×’×¨×¡×” ××•×’×“×¨×ª - ×¢×œ×•×œ ×œ×’×¨×•× ×œ×‘×¢×™×•×ª ×ª××™××•×ª',
                    'how': '×”×•×¡×£ ×’×¨×¡××•×ª ××“×•×™×§×•×ª ××• ×˜×•×•×—×™× ×‘-requirements.txt',
                    'impact': 'medium',
                    'effort': 'low',
                    'category': 'dependencies'
                })
        
        if 'npm' in analysis.get('dependencies', {}):
            deps = analysis['dependencies']['npm']
            if deps and not any('package-lock.json' in f for f in analysis.get('dependency_files', [])):
                suggestions.append({
                    'id': 'add_lockfile',
                    'title': 'ğŸ“¦ ×”×•×¡×£ package-lock.json',
                    'why': '×—×¡×¨ ×§×•×‘×¥ × ×¢×™×œ×ª ×’×¨×¡××•×ª - ×¢×œ×•×œ ×œ×’×¨×•× ×œ×‘×¢×™×•×ª ×‘×”×ª×§× ×”',
                    'how': '×”×¨×¥ npm install ×œ×”×¤×§×ª package-lock.json',
                    'impact': 'medium',
                    'effort': 'low',
                    'category': 'dependencies'
                })
        
        # ×‘×“×™×§×ª CI/CD
        if not analysis.get('has_ci_cd'):
            suggestions.append({
                'id': 'add_ci_cd',
                'title': 'ğŸ”„ ×”×•×¡×£ GitHub Actions CI/CD',
                'why': '××•×˜×•××¦×™×” ×©×œ ×‘×“×™×§×•×ª ×•-deployment ×—×•×¡×›×ª ×–××Ÿ ×•××•× ×¢×ª ×‘××’×™×',
                'how': '×¦×•×¨ .github/workflows ×¢× ×‘×“×™×§×•×ª ××•×˜×•××˜×™×•×ª',
                'impact': 'high',
                'effort': 'medium',
                'category': 'automation'
            })
        
        # ×‘×“×™×§×ª ×‘×“×™×§×•×ª
        if not analysis.get('has_tests'):
            suggestions.append({
                'id': 'add_tests',
                'title': 'ğŸ§ª ×”×•×¡×£ ×‘×“×™×§×•×ª ×œ×¤×¨×•×™×§×˜',
                'why': '×‘×“×™×§×•×ª ××‘×˜×™×—×•×ª ×©×”×§×•×“ ×¢×•×‘×“ ×•××•× ×¢×•×ª ×¨×’×¨×¡×™×•×ª',
                'how': '×¦×•×¨ ×ª×™×§×™×™×ª tests ×¢× ×‘×“×™×§×•×ª ×™×—×™×“×” ×‘×¡×™×¡×™×•×ª',
                'impact': 'high',
                'effort': 'high',
                'category': 'quality'
            })
        
        # ×‘×“×™×§×ª ×§×‘×¦×™× ×’×“×•×œ×™×
        large_files = analysis.get('large_files', [])
        if large_files:
            largest = max(large_files, key=lambda x: x['size'])
            suggestions.append({
                'id': 'split_large_files',
                'title': f'âš¡ ×¤×¦×œ ×§×‘×¦×™× ×’×“×•×œ×™×',
                'why': f'×™×© {len(large_files)} ×§×‘×¦×™× ×’×“×•×œ×™× (×”×’×“×•×œ: {largest["name"]} - {largest["size_kb"]}KB)',
                'how': '×¤×¦×œ ×œ×¤×•× ×§×¦×™×•×ª/××•×“×•×œ×™× ×§×˜× ×™× ×™×•×ª×¨ ×œ×©×™×¤×•×¨ ×ª×—×–×•×§×”',
                'impact': 'medium',
                'effort': 'medium',
                'category': 'refactoring'
            })
        
        # ×‘×“×™×§×ª ×¤×•× ×§×¦×™×•×ª ××¨×•×›×•×ª
        long_functions = analysis.get('long_functions', [])
        if long_functions:
            suggestions.append({
                'id': 'refactor_long_functions',
                'title': 'ğŸ”¨ ×¤×¨×§ ×¤×•× ×§×¦×™×•×ª ××¨×•×›×•×ª',
                'why': f'×™×© {len(long_functions)} ×§×‘×¦×™× ×¢× ×™×•×ª×¨ ×-500 ×©×•×¨×•×ª',
                'how': '×¤×¨×§ ×œ×¤×•× ×§×¦×™×•×ª ×§×˜× ×•×ª ×™×•×ª×¨ (××§×¡×™××•× 50 ×©×•×¨×•×ª)',
                'impact': 'medium',
                'effort': 'high',
                'category': 'refactoring'
            })
        
        # ×‘×“×™×§×ª ×ª×™×¢×•×“ ×ª×¨×•××”
        if not analysis.get('has_contributing'):
            suggestions.append({
                'id': 'add_contributing',
                'title': 'ğŸ¤ ×”×•×¡×£ CONTRIBUTING.md',
                'why': '××¡×‘×™×¨ ××™×š ×œ×ª×¨×•× ×œ×¤×¨×•×™×§×˜ - ××¢×•×“×“ ×§×”×™×œ×”',
                'how': '×¦×•×¨ CONTRIBUTING.md ×¢× ×”× ×—×™×•×ª ×œ×ª×•×¨××™×',
                'impact': 'low',
                'effort': 'low',
                'category': 'community'
            })
        
        # ×‘×“×™×§×ª ×§×•×“ ×”×ª× ×”×’×•×ª
        if not analysis.get('has_code_of_conduct'):
            suggestions.append({
                'id': 'add_code_of_conduct',
                'title': 'ğŸ‘¥ ×”×•×¡×£ CODE_OF_CONDUCT.md',
                'why': '××’×“×™×¨ ×›×œ×œ×™ ×”×ª× ×”×’×•×ª ×‘×§×”×™×œ×” - ×™×•×¦×¨ ×¡×‘×™×‘×” ×‘×˜×•×—×”',
                'how': '×”×©×ª××© ×‘×ª×‘× ×™×ª ×-GitHub ××• Contributor Covenant',
                'impact': 'low',
                'effort': 'low',
                'category': 'community'
            })
        
        # ×‘×“×™×§×ª ×¢×“×›× ×™×•×ª (×× ×™×© ×ª××¨×™×š ×¢×“×›×•×Ÿ ××—×¨×•×Ÿ)
        if analysis.get('updated_at'):
            try:
                last_update = datetime.fromisoformat(analysis['updated_at'].replace('Z', '+00:00'))
                days_since_update = (datetime.now(last_update.tzinfo) - last_update).days
                if days_since_update > 365:
                    suggestions.append({
                        'id': 'update_project',
                        'title': 'â¬†ï¸ ×¢×“×›×Ÿ ××ª ×”×¤×¨×•×™×§×˜',
                        'why': f'×”×¤×¨×•×™×§×˜ ×œ× ×¢×•×“×›×Ÿ {days_since_update} ×™××™× - ×¢×œ×•×œ ×œ×”×›×™×œ ×ª×œ×•×™×•×ª ××™×•×©× ×•×ª',
                        'how': '×¢×“×›×Ÿ ×ª×œ×•×™×•×ª, ×ª×§×Ÿ ×‘××’×™×, ×”×•×¡×£ features ×—×“×©×™×',
                        'impact': 'high',
                        'effort': 'medium',
                        'category': 'maintenance'
                    })
            except:
                pass
        
        # ×‘×“×™×§×ª ×ª×™××•×¨
        if not analysis.get('description'):
            suggestions.append({
                'id': 'add_description',
                'title': 'ğŸ“‹ ×”×•×¡×£ ×ª×™××•×¨ ×œ×¨×™×¤×•×–×™×˜×•×¨×™',
                'why': '×ª×™××•×¨ ×§×¦×¨ ×¢×•×–×¨ ×œ×”×‘×™×Ÿ ×‘××”×™×¨×•×ª ××” ×”×¤×¨×•×™×§×˜ ×¢×•×©×”',
                'how': '×”×•×¡×£ ×ª×™××•×¨ ×‘×”×’×“×¨×•×ª ×”×¨×™×¤×• ×‘-GitHub',
                'impact': 'low',
                'effort': 'low',
                'category': 'metadata'
            })
        
        # ×‘×“×™×§×ª topics/tags
        if not analysis.get('topics'):
            suggestions.append({
                'id': 'add_topics',
                'title': 'ğŸ·ï¸ ×”×•×¡×£ ×ª×’×™×•×ª (topics)',
                'why': '×ª×’×™×•×ª ×¢×•×–×¨×•×ª ×œ×× ×©×™× ×œ××¦×•× ××ª ×”×¤×¨×•×™×§×˜',
                'how': '×”×•×¡×£ topics ×¨×œ×•×•× ×˜×™×™× ×‘×”×’×“×¨×•×ª ×”×¨×™×¤×•',
                'impact': 'low',
                'effort': 'low',
                'category': 'metadata'
            })
        
        # ××™×•×Ÿ ×œ×¤×™ ×—×©×™×‘×•×ª (impact) ×•××××¥ (effort)
        priority_order = {
            ('high', 'low'): 1,
            ('high', 'medium'): 2,
            ('medium', 'low'): 3,
            ('high', 'high'): 4,
            ('medium', 'medium'): 5,
            ('low', 'low'): 6,
            ('medium', 'high'): 7,
            ('low', 'medium'): 8,
            ('low', 'high'): 9
        }
        
        suggestions.sort(key=lambda x: priority_order.get((x['impact'], x['effort']), 10))
        
        return suggestions


# ×™×¦×™×¨×ª instance ×’×œ×•×‘×œ×™
repo_analyzer = RepoAnalyzer()


async def fetch_and_analyze_repo(url: str) -> Dict[str, Any]:
    """×¤×•× ×§×¦×™×” ×¢×•×˜×¤×ª ×œ×©×™××•×© ×‘×‘×•×˜"""
    return await repo_analyzer.fetch_and_analyze_repo(url)


def generate_improvement_suggestions(analysis_data: Dict) -> List[Dict]:
    """×¤×•× ×§×¦×™×” ×¢×•×˜×¤×ª ×œ×©×™××•×© ×‘×‘×•×˜"""
    return repo_analyzer.generate_improvement_suggestions(analysis_data)