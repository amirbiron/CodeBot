#!/usr/bin/env python3
"""
×‘×•×˜ ×©×•××¨ ×§×‘×¦×™ ×§×•×“ - Code Keeper Bot
× ×§×•×“×ª ×”×›× ×™×¡×” ×”×¨××©×™×ª ×œ×‘×•×˜
"""

from __future__ import annotations

# ×”×’×“×¨×•×ª ××ª×§×“××•×ª
import os
import functools
import inspect
import logging
import asyncio
import warnings
import json
import random
import threading
from pathlib import Path
from typing import Any, Optional, TypedDict
try:
    from typing import NotRequired  # type: ignore[attr-defined]
except ImportError:  # pragma: no cover
    try:
        from typing_extensions import NotRequired  # type: ignore[assignment]
    except Exception:  # pragma: no cover
        class _NotRequiredShim:
            def __class_getitem__(cls, item):
                return item
        NotRequired = _NotRequiredShim  # type: ignore[misc,assignment]
from datetime import datetime

# ×”×¤×—×ª×ª ×¨×¢×© ×‘×œ×•×’×™×: DeprecationWarnings ×¡×¤×¨×™×™×ª×™×™× (×œ××©×œ httplib2/pyparsing)
# ×œ× ××©×¤×™×¢ ×¢×œ ×”×ª× ×”×’×•×ª ×¨×™×¦×”, ×¨×§ ×¢×œ ×¤×œ×˜ ××–×”×¨×•×ª.
warnings.filterwarnings("ignore", category=DeprecationWarning, module=r"httplib2\.auth")

import signal
import socket
import sys
import time
from urllib.parse import urlparse
try:
    import pymongo
    _HAS_PYMONGO = True
except Exception:
    pymongo = None  # fallback ×œ×œ× type: ignore
    _HAS_PYMONGO = False
from datetime import datetime, timezone, timedelta
import atexit
try:
    import pymongo.errors
    from pymongo.errors import DuplicateKeyError
except Exception:
    class _DummyErr(Exception):
        pass
    class _DummyErrors:
        InvalidOperation = _DummyErr
        OperationFailure = _DummyErr
    DuplicateKeyError = _DummyErr
    pymongo = type("_PM", (), {"errors": _DummyErrors})()
import os

from telegram import Update, ReplyKeyboardMarkup, InlineKeyboardButton, InlineKeyboardMarkup, BotCommand, BotCommandScopeChat
from telegram.constants import ParseMode
from telegram.ext import (Application, CommandHandler, ContextTypes,
                          MessageHandler, filters, Defaults, ConversationHandler, CallbackQueryHandler,
                          PicklePersistence, InlineQueryHandler, ApplicationHandlerStop, TypeHandler)

from config import config
try:
    import observability as _observability
except Exception:
    _observability = None


def _noop(*_a, **_k):  # type: ignore[unused-argument]
    return None


def _default_generate_request_id() -> str:
    try:
        return str(int(time.time() * 1000))[-8:]
    except Exception:
        return ""



def _observability_attr(name: str, default):
    if _observability is None:
        return default
    try:
        return getattr(_observability, name)
    except AttributeError:
        return default


setup_structlog_logging = _observability_attr("setup_structlog_logging", _noop)
init_sentry = _observability_attr("init_sentry", _noop)
get_log_level_from_env = _observability_attr(
    "get_log_level_from_env",
    lambda default="INFO": (str(os.getenv("LOG_LEVEL") or default)).strip().upper() or "INFO",
)
bind_request_id = _observability_attr("bind_request_id", _noop)
generate_request_id = _observability_attr("generate_request_id", _default_generate_request_id)
emit_event = _observability_attr("emit_event", _noop)
bind_user_context = _observability_attr("bind_user_context", _noop)
bind_command = _observability_attr("bind_command", _noop)
get_observability_context = _observability_attr("get_observability_context", lambda: {})
from metrics import (
    telegram_updates_total,
    track_file_saved,
    track_search_performed,
    track_performance,
    errors_total,
    record_request_outcome,
)
from rate_limiter import RateLimiter
try:
    # Optional advanced limits backend (limits + Redis)
    from limits import RateLimitItemPerMinute
    from limits.storage import RedisStorage, MemoryStorage
    from limits.strategies import MovingWindowRateLimiter
    _LIMITS_AVAILABLE = True
except Exception:
    RateLimitItemPerMinute = None  # type: ignore[assignment]
    RedisStorage = None  # type: ignore[assignment]
    MemoryStorage = None  # type: ignore[assignment]
    MovingWindowRateLimiter = None  # type: ignore[assignment]
    _LIMITS_AVAILABLE = False
from database import CodeSnippet, DatabaseManager, db
from services import code_service as code_processor
from bot_handlers import AdvancedBotHandlers  # still used by legacy code
from bot_handlers import set_activity_reporter as set_bh_activity_reporter
from conversation_handlers import MAIN_KEYBOARD, get_save_conversation_handler
from conversation_handlers import set_activity_reporter as set_ch_activity_reporter
# ×™×™×‘×•× ×“×—×•×™ ×©×œ ×”-activity_reporter ×‘×ª×•×š ×”-run-time ×‘×œ×‘×“ ×›×“×™ ×œ×× ×•×¢ ×™×¦×™×¨×ª ×—×™×‘×•×¨×™× ×‘×–××Ÿ import
from github_menu_handler import GitHubMenuHandler
from backup_menu_handler import BackupMenuHandler
from handlers.drive.menu import GoogleDriveMenuHandler
from handlers.drive.utils import extract_schedule_key as drive_extract_schedule_key
def get_drive_handler_from_application(application: Application) -> tuple[Any, bool]:
    """
    ×”×—×–×¨ ××ª ××•×¤×¢ GoogleDriveMenuHandler ××ª×•×š application.

    Returns (handler, restored_flag). restored_flag ××¦×™×™×Ÿ ×× × ××œ×¦× ×• ×œ×©×—×–×¨ ××ª
    ×”×”×¤× ×™×” ×“×¨×š ×”×××¤×™×™×Ÿ `_drive_handler` ×œ××—×¨ ×©-bot_data ××™×‘×“ ××ª ×”××¤×ª×—.
    """
    handler = None
    restored = False
    try:
        bot_data = getattr(application, "bot_data", None)
    except Exception:
        bot_data = None
    if isinstance(bot_data, dict):
        handler = bot_data.get("drive_handler")
    if handler:
        return handler, restored
    fallback = getattr(application, "_drive_handler", None)
    if fallback:
        if isinstance(bot_data, dict):
            try:
                bot_data["drive_handler"] = fallback
            except Exception:
                pass
        handler = fallback
        restored = True
    return handler, restored
from handlers.documents import DocumentHandler
from file_manager import backup_manager
from large_files_handler import large_files_handler
from user_stats import user_stats
from cache_commands import setup_cache_handlers  # enabled
# from enhanced_commands import setup_enhanced_handlers  # disabled
from batch_commands import setup_batch_handlers
from html import escape as html_escape
try:
    from aiohttp import web  # for internal web server
except Exception:
    class _DummyWeb:
        class Application:
            def __init__(self, *a, **k): pass
        class AppRunner:
            def __init__(self, *a, **k): pass
            async def setup(self): pass
        class TCPSite:
            def __init__(self, *a, **k): pass
            async def start(self): pass
        async def json_response(*a, **k):
            return None
    web = _DummyWeb()

# (Lock mechanism constants removed)

# ×”×’×“×¨×ª ×œ×•×’×™× ×‘×¡×™×¡×™×ª + structlog + Sentry
_LOG_LEVEL_NAME = get_log_level_from_env("INFO")
try:
    _LOG_LEVEL = int(_LOG_LEVEL_NAME) if str(_LOG_LEVEL_NAME).isdigit() else getattr(logging, str(_LOG_LEVEL_NAME).upper(), logging.INFO)
except Exception:
    _LOG_LEVEL_NAME = "INFO"
    _LOG_LEVEL = logging.INFO

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=_LOG_LEVEL,
    handlers=[logging.StreamHandler(sys.stdout)],
)
try:
    from utils import install_sensitive_filter
    install_sensitive_filter()
except Exception:
    pass
try:
    setup_structlog_logging(_LOG_LEVEL_NAME)
    init_sentry()
except Exception:
    # ××œ ×ª×›×©×™×œ ××ª ×”××¤×œ×™×§×¦×™×” ×× ×ª×¦×•×¨×ª observability × ×›×©×œ×”
    pass

# OpenTelemetry (best-effort, fail-open)
try:
    from observability_otel import setup_telemetry as _setup_otel  # type: ignore

    _setup_otel(
        service_name=str(os.getenv("OTEL_SERVICE_NAME") or "codebot-bot"),
        service_version=os.getenv("SERVICE_VERSION") or os.getenv("RENDER_GIT_COMMIT") or None,
        environment=os.getenv("ENVIRONMENT") or os.getenv("ENV") or None,
        flask_app=None,
    )
except Exception:
    pass

# ×¡×’×™×¨×ª ×¡×©×Ÿ aiohttp ××©×•×ª×£ ×‘×¡×™×•× ×”×ª×”×œ×™×š (best-effort)
@atexit.register
def _shutdown_http_shared_session() -> None:
    try:
        from http_async import close_session  # type: ignore
    except Exception:
        return
    loop: asyncio.AbstractEventLoop | None = None
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = None
    if loop is not None and not loop.is_closed():
        try:
            running = bool(loop.is_running())
        except Exception:
            running = False
        if not running:
            try:
                coro = close_session()
            except Exception:
                coro = None
            if coro is not None:
                try:
                    loop.run_until_complete(coro)
                except Exception:
                    try:
                        coro.close()  # type: ignore[attr-defined]
                    except Exception:
                        pass
                else:
                    return
        # ×× ×”×œ×•×œ××” ×¤×¢×™×œ×” ××™ ××¤×©×¨ ×œ×”××ª×™×Ÿ ×œ×” ×›××Ÿ â€“ × ×©×ª××© ×‘×œ×•×œ××” ×–×× ×™×ª
    try:
        tmp_loop = asyncio.new_event_loop()
        original_loop: asyncio.AbstractEventLoop | None = None
        try:
            try:
                original_loop = asyncio.get_event_loop()
            except RuntimeError:
                original_loop = None
            try:
                asyncio.set_event_loop(tmp_loop)
            except Exception:
                pass
            try:
                coro = close_session()
            except Exception:
                coro = None
            if coro is not None:
                try:
                    tmp_loop.run_until_complete(coro)
                except Exception:
                    try:
                        coro.close()  # type: ignore[attr-defined]
                    except Exception:
                        pass
        finally:
            tmp_loop.close()
            try:
                if original_loop is None or (original_loop.is_closed() if original_loop else True):
                    asyncio.set_event_loop(None)
                else:
                    asyncio.set_event_loop(original_loop)
            except Exception:
                pass
    except Exception:
        # ××œ ×ª×”×¨×•×¡ ×›×™×‘×•×™
        pass

# Optional: Initialize OpenTelemetry for the bot process as well (no Flask app here)
try:
    from observability_otel import setup_telemetry as _setup_otel
    _setup_otel(
        service_name="code-keeper-bot",
        service_version=os.getenv("APP_VERSION", ""),
        environment=os.getenv("ENVIRONMENT", os.getenv("ENV", "production")),
        flask_app=None,
    )
except Exception:
    pass

logger = logging.getLogger(__name__)


def _command_label_from_handler(handler) -> str:
    """×”×¤×§×ª ×©× ×¤×§×•×“×” ×™×“×™×“×•×ª×™ ×œ××“×“×™× ××ª×•×š CommandHandler."""
    try:
        commands = list(getattr(handler, "commands", []) or [])
    except Exception:
        commands = []
    if commands:
        name = sorted(str(cmd).lstrip('/') for cmd in commands if cmd)[:1]
        if name:
            return f"/{name[0]}"
    try:
        base = getattr(handler.callback, "__name__", "")
    except Exception:
        base = ""
    base = (base or "command").lstrip('_')
    return f"/{base}" if not base.startswith('/') else base


def _wrap_command_callback(callback, command_label: str):
    if getattr(callback, "_metrics_wrapped", False):
        return callback

    if inspect.iscoroutinefunction(callback):
        async def _wrapped(update, context, *args, __orig=callback):
            start = time.perf_counter()
            status_code = 200
            status_label: str | None = None
            try:
                return await __orig(update, context, *args)
            except ApplicationHandlerStop:
                status_code = 499
                status_label = "cancelled"
                raise
            except Exception:
                status_code = 500
                status_label = "error"
                raise
            finally:
                try:
                    record_request_outcome(
                        status_code,
                        max(0.0, time.perf_counter() - start),
                        source="telegram",
                        command=command_label,
                        cache_hit=None,
                        status_label=status_label,
                    )
                except Exception:
                    pass
        _wrapped._metrics_wrapped = True  # type: ignore[attr-defined]
        try:
            _wrapped.__name__ = getattr(callback, "__name__", "wrapped_command")
        except Exception:
            pass
        return _wrapped

    def _wrapped_sync(update, context, *args, __orig=callback):
        start = time.perf_counter()
        status_code = 200
        status_label: str | None = None
        try:
            return __orig(update, context, *args)
        except ApplicationHandlerStop:
            status_code = 499
            status_label = "cancelled"
            raise
        except Exception:
            status_code = 500
            status_label = "error"
            raise
        finally:
            try:
                record_request_outcome(
                    status_code,
                    max(0.0, time.perf_counter() - start),
                    source="telegram",
                    command=command_label,
                    cache_hit=None,
                    status_label=status_label,
                )
            except Exception:
                pass

    _wrapped_sync._metrics_wrapped = True  # type: ignore[attr-defined]
    return _wrapped_sync


def _instrument_command_handlers(application) -> None:
    from telegram.ext import CommandHandler as _CommandHandler  # local import to avoid cycles

    try:
        raw_handlers = getattr(application, "handlers", None)
    except Exception:
        return

    handlers: list[Any] = []
    if isinstance(raw_handlers, dict):
        for group in raw_handlers.values():
            try:
                handlers.extend(list(group or []))
            except TypeError:
                continue
    elif raw_handlers:
        try:
            handlers = list(raw_handlers)
        except TypeError:
            handlers = [raw_handlers]

    for handler in handlers:
        if not isinstance(handler, _CommandHandler):
            continue
        try:
            callback = handler.callback
        except Exception:
            continue
        if getattr(callback, "_metrics_wrapped", False):
            continue
        label = _command_label_from_handler(handler)
        wrapped = _wrap_command_callback(callback, label)
        try:
            handler.callback = wrapped
        except Exception:
            pass


def _wrap_github_callback(callback):
    if getattr(callback, "_metrics_wrapped", False):
        return callback

    async def _wrapped(update, context, *args, __orig=callback):
        query = getattr(update, "callback_query", None)
        raw = str(getattr(query, "data", "") or "")
        action = (raw.split(":", 1)[0] or "unknown").strip() or "unknown"
        start = time.perf_counter()
        status_code = 200
        status_label: str | None = None
        try:
            return await __orig(update, context, *args)
        except ApplicationHandlerStop:
            status_code = 499
            status_label = "cancelled"
            raise
        except Exception:
            status_code = 500
            status_label = "error"
            raise
        finally:
            try:
                record_request_outcome(
                    status_code,
                    max(0.0, time.perf_counter() - start),
                    source="telegram",
                    handler=f"github:{action}",
                    cache_hit=None,
                    status_label=status_label,
                )
            except Exception:
                pass

    _wrapped._metrics_wrapped = True  # type: ignore[attr-defined]
    try:
        _wrapped.__name__ = getattr(callback, "__name__", "github_callback")
    except Exception:
        pass
    return _wrapped


def _wrap_handler_callback(callback, handler_label: str):
    if getattr(callback, "_metrics_wrapped", False):
        return callback

    if inspect.iscoroutinefunction(callback):
        async def _wrapped(update, context, *args, __orig=callback):
            start = time.perf_counter()
            status_code = 200
            status_label: str | None = None
            try:
                return await __orig(update, context, *args)
            except ApplicationHandlerStop:
                status_code = 499
                status_label = "cancelled"
                raise
            except Exception:
                status_code = 500
                status_label = "error"
                raise
            finally:
                try:
                    record_request_outcome(
                        status_code,
                        max(0.0, time.perf_counter() - start),
                        source="telegram",
                        handler=handler_label,
                        cache_hit=None,
                        status_label=status_label,
                    )
                except Exception:
                    pass
        _wrapped._metrics_wrapped = True  # type: ignore[attr-defined]
        return _wrapped

    def _wrapped_sync(update, context, *args, __orig=callback):
        start = time.perf_counter()
        status_code = 200
        status_label: str | None = None
        try:
            return __orig(update, context, *args)
        except ApplicationHandlerStop:
            status_code = 499
            status_label = "cancelled"
            raise
        except Exception:
            status_code = 500
            status_label = "error"
            raise
        finally:
            try:
                record_request_outcome(
                    status_code,
                    max(0.0, time.perf_counter() - start),
                    source="telegram",
                    handler=handler_label,
                    cache_hit=None,
                    status_label=status_label,
                )
            except Exception:
                pass

    _wrapped_sync._metrics_wrapped = True  # type:ignore[attr-defined]
    return _wrapped_sync


async def _cancel_command_fallback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Handler ××¡×™× ×›×¨×•× ×™ ××—×™×“ ×œ×¡×™×•× ×©×™×—×” ×›××©×¨ ×”××©×ª××© ××¤×¢×™×œ /cancel."""
    return ConversationHandler.END


def _redis_socket_available(redis_url: str, timeout: float = 0.25) -> bool:
    """
    ×‘×“×™×§×ª reachability ×‘×¡×™×¡×™×ª ×œ-Redis ×›×“×™ ×œ×”×™×× ×¢ ××”××ª× ×” ××¨×•×›×” ×‘×–××Ÿ ×˜×¡×˜×™×/CI.

    ×× ×œ× × ×™×ª×Ÿ ×œ×”×’×™×¢ ×œ-Redis ×‘××”×™×¨×•×ª, × ×—×–×•×¨ False ×•× ×©×ª××© ×‘×¤×•×œ×‘×§.
    """
    if not redis_url:
        return False
    try:
        parsed = urlparse(str(redis_url))
    except Exception:
        return False

    scheme = (parsed.scheme or "").lower()
    default_ports = {
        "redis": 6379,
        "rediss": 6379,
        "redis+sentinel": 26379,
    }
    default_port = default_ports.get(scheme)
    if default_port is None:
        return False

    host = parsed.hostname
    try:
        port = parsed.port
    except ValueError:
        port = None

    if host is None:
        netloc = parsed.netloc
        if not netloc:
            return False
        if "@" in netloc:
            netloc = netloc.split("@", 1)[1]
        first_endpoint = netloc.split(",", 1)[0]
        first_endpoint = first_endpoint.strip()
        if not first_endpoint:
            return False
        if first_endpoint.startswith("[") and "]" in first_endpoint:
            end_idx = first_endpoint.find("]")
            host = first_endpoint[1:end_idx]
            remainder = first_endpoint[end_idx + 1:]
            if remainder.startswith(":"):
                try:
                    port = int(remainder[1:])
                except ValueError:
                    port = None
        else:
            if ":" in first_endpoint:
                host_part, port_part = first_endpoint.rsplit(":", 1)
                host = host_part
                try:
                    port = int(port_part)
                except ValueError:
                    port = None
            else:
                host = first_endpoint

    if not host:
        return False

    port = port or default_port
    if not port:
        return False

    try:
        sock = socket.create_connection((host, int(port)), timeout=timeout)
    except Exception:
        return False
    try:
        sock.close()
    except Exception:
        pass
    return True

# ×”×‘×˜×—×ª ×œ×•×œ××ª asyncio ×›×‘×¨×™×¨×ª ××—×“×œ (×ª××™×›×” ×‘-Python 3.11 ×‘×¡×‘×™×‘×ª ×˜×¡×˜×™×)
# ××ª×§×™×Ÿ Policy ×—×¡×™×Ÿ ×©××™×™×¦×¨ ×œ×•×œ××” ×—×“×©×” ×× ××™×Ÿ ××—×ª ×–××™× ×”, ×’× ×× asyncio.run() × ×™×§×” ××ª ×”×œ×•×œ××”.
try:
    class _ResilientEventLoopPolicy(asyncio.DefaultEventLoopPolicy):
        def get_event_loop(self):  # type: ignore[override]
            try:
                return super().get_event_loop()
            except RuntimeError:
                loop = self.new_event_loop()
                self.set_event_loop(loop)
                return loop

    # ×”×ª×§× ×” ×—×“-×¤×¢××™×ª ×©×œ ×”-Policy. ×× ×›×‘×¨ ×”×•×ª×§×Ÿ Policy ×—×™×¦×•× ×™ (×›×’×•×Ÿ uvloop) ×œ× × × ×¡×” ×œ×”×—×œ×™×£ ×‘×›×•×—.
    try:
        current_policy = asyncio.get_event_loop_policy()
        # × ×ª×§×™×Ÿ ×¨×§ ×× ×–×• ×”-DefaultPolicy ×›×“×™ ×œ× ×œ×©×‘×•×¨ ×§×•× ×¤×™×’ ×§×™×™×
        if isinstance(current_policy, asyncio.DefaultEventLoopPolicy):
            asyncio.set_event_loop_policy(_ResilientEventLoopPolicy())
    except Exception:
        # ×‘××™×“×” ×•×”×§×¨×™××” get_event_loop_policy ×¢×¦××” × ×›×©×œ×ª, × × ×¡×” ×œ×”×ª×§×™×Ÿ ×™×©×™×¨×•×ª
        try:
            asyncio.set_event_loop_policy(_ResilientEventLoopPolicy())
        except Exception:
            pass

    # fail-safe: × ×¡×” ×œ×•×•×“× ×©×™×© ×œ×•×œ××” × ×•×›×—×™×ª ×’× ×›×¢×ª
    try:
        asyncio.get_event_loop()
    except RuntimeError:
        try:
            _loop = asyncio.new_event_loop()
            asyncio.set_event_loop(_loop)
        except Exception:
            # Fail-open: ××™×Ÿ ×œ×”×¤×™×œ ×‘×–××Ÿ import
            pass
except Exception:
    # ×œ× × ×›×©×™×œ ××ª ×”-import ×× ×™×© ×‘×¢×™×” ×‘××“×™× ×™×•×ª ×”×œ×•×œ××”
    pass

# ×¨×©×™××ª ×§×™×“×•×“×™× ×œ× ×™×¡×™×•×Ÿ ×§×¨×™××ª ×§×‘×¦×™× (× ×™×ª× ×ª ×œ×“×¨×™×¡×” ×‘×˜×¡×˜×™×)
ENCODINGS_TO_TRY = [
    'utf-8',
    'windows-1255',
    'iso-8859-8',
    'cp1255',
    'utf-16',
    'latin-1',
]
def _register_catch_all_callback(application, callback_fn) -> None:
    """×¨×™×©×•× CallbackQueryHandler ×›×œ×œ×™ ×‘×§×‘×•×¦×” ×××•×—×¨×ª, ×¢× fallback ×›×©×”-API ×œ× ×ª×•××š ×‘-group.

    × ×•×¢×“ ×œ×”×™×× ×¢ ××›×©×œ×™ ×˜×¡×˜×™×/×¡×˜××‘×™× (TypeError ×¢×œ group), ×•×‘×• ×‘×–××Ÿ ×œ×©××¨ ×§×“×™××•×™×•×ª ×‘×¤×¨×•×“×§×©×Ÿ.
    """
    handler = CallbackQueryHandler(callback_fn)
    try:
        application.add_handler(handler, group=5)
    except TypeError:
        # ×¡×‘×™×‘×ª ×˜×¡×˜/×¡×˜××‘ ×œ×œ× ×ª××™×›×” ×‘×¤×¨××˜×¨ group
        application.add_handler(handler)
    except Exception as e:
        # ×“×•×•×— ×—×¨×™×’×” ×›×“×™ ×©×œ× × ×‘×œ×¢ ×©×’×™××•×ª ×¨×™×©×•× ×©×§×˜×•×ª
        logger.error(f"Failed to register catch-all CallbackQueryHandler: {e}")

# ×”×•×“×¢×ª ×”×ª×—×œ×” ××¨×©×™××”
logger.info("ğŸš€ ××¤×¢×™×œ ×‘×•×˜ ×§×•×“ ××ª×§×“× - ×’×¨×¡×” ×¤×¨×•!")
try:
    emit_event("bot_start", msg_he="××¤×¢×™×œ ××ª ×”×‘×•×˜", severity="info")
except Exception:
    pass

# ×”×¤×—×ª×ª ×¨×¢×© ×‘×œ×•×’×™×
logging.getLogger("httpx").setLevel(logging.ERROR)  # ×¨×§ ×©×’×™××•×ª ×§×¨×™×˜×™×•×ª
logging.getLogger("telegram.ext.Updater").setLevel(logging.ERROR)
logging.getLogger("telegram.ext.Application").setLevel(logging.WARNING)

# Reporter ×™×•×•×¦×¨ ×•×™×•×–×¨×§ ×‘×–××Ÿ ×¨×™×¦×” ×œ××—×¨ ×‘× ×™×™×ª ×”××¤×œ×™×§×¦×™×” ×•×”×§×•× ×¤×™×’
reporter = None

# ===== ×¢×–×¨: ×©×œ×™×—×ª ×”×•×“×¢×ª ××“××™×Ÿ =====
def get_admin_ids() -> list[int]:
    try:
        raw = os.getenv('ADMIN_USER_IDS')
        if not raw:
            return []
        return [int(x.strip()) for x in raw.split(',') if x.strip().isdigit()]
    except Exception:
        return []

async def notify_admins(context: ContextTypes.DEFAULT_TYPE, text: str) -> None:
    try:
        # Alert Pipeline Consolidation:
        # ×œ× ×©×•×œ×—×™× ×”×•×“×¢×•×ª "××“××™×Ÿ" ×™×©×™×¨×•×ª ×“×¨×š bot.send_message (×–×” ×¢×•×§×£ suppress/Rule Engine).
        # ×‘××§×•× ×–×”, ××¤×™×§×™× internal_alert ×•×××¤×©×¨×™× ×œ×× ×•×¢ ×”×›×œ×œ×™× ×œ×”×—×œ×™×˜ ××/×œ××Ÿ ×œ×©×œ×•×—.
        try:
            from internal_alerts import emit_internal_alert  # type: ignore
        except Exception:
            emit_internal_alert = None  # type: ignore

        if emit_internal_alert is None:
            return

        # ×©×•××¨×™× ××ª ×”×˜×§×¡×˜ ×‘×ª×•×¨ summary; ×¤×¨×˜×™× × ×•×¡×¤×™× (×›××• ×¨×©×™××ª ××“××™× ×™×) ×¨×§ ×œ×”×§×©×¨.
        # NOTE: ×œ× ××¢×‘×™×¨×™× token/chat_id ×•×›×“' ×›×“×™ ×œ× ×œ×”×“×œ×™×£ ××™×“×¢ ×¨×’×™×©.
        admin_ids = get_admin_ids()
        emit_internal_alert(
            "admin_notification",
            severity="info",
            summary=str(text or ""),
            source="main.notify_admins",
            admin_ids=admin_ids,
        )
    except Exception:
        pass

# ===== Admin: /recycle_backfill =====
async def recycle_backfill_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """×××œ× deleted_at ×•-deleted_expires_at ×œ×¨×©×•××•×ª ××—×•×§×•×ª ×¨×›×•×ª ×•×—×•×©×‘ TTL.

    ×©×™××•×©: /recycle_backfill [X]
    X = ×™××™× ×œ×ª×•×§×£ ×¡×œ (×‘×¨×™×¨×ª ××—×“×œ ××”×§×•× ×¤×™×’ RECYCLE_TTL_DAYS)
    ×”×¤×§×•×“×” ×–××™× ×” ×œ×× ×”×œ×™× ×‘×œ×‘×“.
    """
    try:
        user_id = update.effective_user.id if update and update.effective_user else 0
        admin_ids = get_admin_ids()
        if not admin_ids or user_id not in admin_ids:
            try:
                await update.message.reply_text("âŒ ×¤×§×•×“×” ×–××™× ×” ×œ×× ×”×œ×™× ×‘×œ×‘×“")
            except Exception:
                pass
            return

        # ×§×‘×™×¢×ª TTL ×‘×™××™×
        try:
            ttl_days = int(context.args[0]) if context.args else int(getattr(config, 'RECYCLE_TTL_DAYS', 7) or 7)
        except Exception:
            ttl_days = int(getattr(config, 'RECYCLE_TTL_DAYS', 7) or 7)
        ttl_days = max(1, ttl_days)

        now = datetime.now(timezone.utc)
        expires = now + timedelta(days=ttl_days)

        # ×•×“× ××™× ×“×§×¡×™ TTL ×•××—"×› Backfill ×‘×©×ª×™ ×”×§×•×œ×§×¦×™×•×ª
        from database import db as _db
        results = []
        for coll_name, friendly in (("collection", "×§×‘×¦×™× ×¨×’×™×œ×™×"), ("large_files_collection", "×§×‘×¦×™× ×’×“×•×œ×™×")):
            coll = getattr(_db, coll_name, None)
            # ×—×©×•×‘: ××œ ×ª×©×ª××©×• ×‘-truthiness ×¢×œ ×§×•×œ×§×¦×™×” ×©×œ PyMongo
            if coll is None:
                results.append((friendly, 0, 0, "collection-missing"))
                continue
            # ensure TTL index idempotently
            try:
                coll.create_index("deleted_expires_at", expireAfterSeconds=0, name="deleted_ttl")
            except Exception:
                # ×œ× ×§×¨×™×˜×™; × ××©×™×š
                pass

            modified_deleted_at = 0
            modified_deleted_exp = 0
            # backfill deleted_at where missing
            try:
                if hasattr(coll, 'update_many'):
                    r1 = coll.update_many({"is_active": False, "deleted_at": {"$exists": False}}, {"$set": {"deleted_at": now}})
                    modified_deleted_at = int(getattr(r1, 'modified_count', 0) or 0)
            except Exception:
                pass
            # backfill deleted_expires_at where missing
            try:
                if hasattr(coll, 'update_many'):
                    r2 = coll.update_many({"is_active": False, "deleted_expires_at": {"$exists": False}}, {"$set": {"deleted_expires_at": expires}})
                    modified_deleted_exp = int(getattr(r2, 'modified_count', 0) or 0)
            except Exception:
                pass

            results.append((friendly, modified_deleted_at, modified_deleted_exp, ""))

        # ×“×•"×—
        lines = [
            f"ğŸ§¹ Backfill ×¡×œ ××™×—×–×•×¨ (TTL={ttl_days} ×™××™×)",
        ]
        for friendly, c_at, c_exp, err in results:
            if err:
                lines.append(f"â€¢ {friendly}: ×“×™×œ×•×’ ({err})")
            else:
                lines.append(f"â€¢ {friendly}: deleted_at={c_at}, deleted_expires_at={c_exp}")
        try:
            await update.message.reply_text("\n".join(lines))
        except Exception:
            pass
    except Exception as e:
        try:
            await update.message.reply_text(f"âŒ ×©×’×™××” ×‘-backfill: {html_escape(str(e))}")
        except Exception:
            pass

async def log_user_activity(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    ×¨×™×©×•× ×¤×¢×™×œ×•×ª ××©×ª××© ×‘××¢×¨×›×ª.
    
    Args:
        update: ××•×‘×™×™×§×˜ Update ××˜×œ×’×¨×
        context: ×”×§×•× ×˜×§×¡×˜ ×©×œ ×”×©×™×—×”
    
    Note:
        ×¤×•× ×§×¦×™×” ×–×• × ×§×¨××ª ××•×˜×•××˜×™×ª ×¢×‘×•×¨ ×›×œ ×¤×¢×•×œ×” ×©×œ ××©×ª××©
    """
    if not update.effective_user:
        return

    # ×“×’×™××” ×œ×”×¤×—×ª×ª ×¢×•××¡: ×¨×§ ~25% ××”××™×¨×•×¢×™× ×™×¢×“×›× ×• ××™×™×“×™×ª ××ª ×”-DB
    try:
        import random as _rnd
        sampled = (_rnd.random() < 0.25)
    except Exception:
        sampled = True

    # ×¨×™×©×•× ×‘×¡×™×¡×™ ×œ×’××¨×™ ××—×•×¥ ×œ-try ×›×“×™ ×œ× ×œ×—×¡×•× ××ª ×”×¤×œ×•××•
    try:
        # ×›×“×™ ×œ×©××¨ ×¡×¤×™ milestones, ×× ×“×•×’××™× â€” × ×›×¤×™×œ ××ª ×”××©×§×œ ×‘×”×ª×× ×œ×”×¡×ª×‘×¨×•×ª ×”×“×’×™××”
        if sampled:
            # p=0.25 -> weight=4; ×× ××©×ª× ×” â€” × ×©××‘ ××”×§×•× ×¤×™×’ ×‘×¢×ª×™×“
            weight = 4
            try:
                user_stats.log_user(update.effective_user.id, update.effective_user.username, weight=weight)
            except TypeError:
                # ×ª××™××•×ª ×œ××—×•×¨ ×œ×˜×¡×˜×™×/×¡×‘×™×‘×” ×™×©× ×” ×œ×œ× ×¤×¨××˜×¨ weight
                user_stats.log_user(update.effective_user.id, update.effective_user.username)
    except Exception:
        pass

    # milestones â€” ×œ×”×¨×¦×” ××¡×™× ×›×¨×•× ×™×ª ×›×š ×©×œ× ×ª×—×¡×•× ××ª ×”×”×•×“×¢×” ×œ××©×ª××©
    async def _milestones_job(user_id: int, username: str | None):
        try:
            # ×˜×¢×™× ×” ×“×™× ××™×ª ×©×œ ××•×“×•×œ ×”-DB ×›×“×™ ×œ×¢×‘×•×“ ×”×™×˜×‘ ×¢× monkeypatch ×‘×˜×¡×˜×™×
            from database import db as _db
            users_collection = _db.db.users if getattr(_db, 'db', None) else None
            if users_collection is None:
                return
            doc = users_collection.find_one({"user_id": user_id}, {"total_actions": 1, "milestones_sent": 1}) or {}
            total_actions = int(doc.get("total_actions") or 0)
            already_sent = set(doc.get("milestones_sent") or [])
            milestones = [50, 100, 200, 500, 1000]
            pending = [m for m in milestones if m <= total_actions and m not in already_sent]
            if not pending:
                return
            milestone = max(pending)
            # ×”×ª×¨××ª ××“××™×Ÿ ××•×§×“××ª (×œ×¦×•×¨×š × ×™×˜×•×¨), ×‘× ×•×¡×£ ×œ×”×ª×¨××” ××—×¨×™ ×¢×“×›×•×Ÿ DB
            if milestone >= 500:
                uname = (username or f"User_{user_id}")
                display = f"@{uname}" if uname and not str(uname).startswith('@') else str(uname)
                # ×§×¨×™××” ×™×©×™×¨×” ×œ×œ× ×¢×˜×™×¤×ª try ×›×“×™ ×©×œ× × ×‘×œ×¢ ×‘×©×•×’×’; ×”-wrapper ×”×—×™×¦×•× ×™ ×™×ª×¤×•×¡ ×—×¨×™×’×•×ª
                await notify_admins(context, f"ğŸ“¢ ××©×ª××© {display} ×”×’×™×¢ ×œÖ¾{milestone} ×¤×¢×•×œ×•×ª ×‘×‘×•×˜")
            res = users_collection.update_one(
                {"user_id": user_id, "milestones_sent": {"$ne": milestone}},
                {"$addToSet": {"milestones_sent": milestone}, "$set": {"updated_at": datetime.now(timezone.utc)}}
            )
            if getattr(res, 'modified_count', 0) > 0:
                messages = {
                    50: (
                        "×•×•××•! ××ª×” ×‘×™×Ÿ ×”××©×ª××©×™× ×”××•×‘×™×œ×™× ×‘×‘×•×˜ ğŸ”¥\n"
                        "×”× ×•×›×—×•×ª ×©×œ×š ×¢×•×©×” ×œ× ×• ×©××— ğŸ˜Š\n"
                        "×™×© ×œ×š ×¨×¢×™×•× ×•×ª ××• ×“×‘×¨×™× ×©×”×™×™×ª ×¨×•×¦×” ×œ×¨××•×ª ×›××Ÿ?\n"
                        "××•×–××Ÿ ×œ×›×ª×•×‘ ×œÖ¾@moominAmir"
                    ),
                    100: (
                        "ğŸ’¯ ×¤×¢×•×œ×•×ª!\n"
                        "×›× ×¨××” ×©××ª×” ×›×‘×¨ ×™×•×“×¢ ××ª ×”×‘×•×˜ ×™×•×ª×¨ ×˜×•×‘ ××× ×™ ğŸ˜‚\n"
                        "×™××œ×œ×”, ××•×œ×™ × ×¢×©×” ×œ×š ×ª×¢×•×“×ª ××©×ª××© ×•×ª×™×§? ğŸ†"
                    ),
                    200: (
                        "×•×•××•! 200 ×¤×¢×•×œ×•×ª! ğŸš€\n"
                        "××ª×” ×œ×’××¨×™ ×‘×™×Ÿ ×”××©×ª××©×™× ×”×›×™ ×¤×¢×™×œ×™×.\n"
                        "×™×© ×¤×™×¦'×¨ ×©×”×™×™×ª ×¨×•×¦×” ×œ×¨××•×ª ×‘×”××©×š?\n"
                        "×¡×¤×¨ ×œ× ×• ×‘Ö¾@moominAmir"
                    ),
                    500: (
                        "500 ×¤×¢×•×œ×•×ª! ğŸ”¥\n"
                        "××’×™×¢ ×œ×š ×ª×•×“×” ×¢× ×§×™×ª ×¢×œ ×”×ª××™×›×”! ğŸ©µ"
                    ),
                    1000: (
                        "×”×’×¢×ª ×œÖ¾1000 ×¤×¢×•×œ×•×ª! ğŸ‰\n"
                        "××ª×” ××’×“×” ×—×™×” ×©×œ ×”×‘×•×˜ ×”×–×” ğŸ™Œ\n"
                        "×ª×•×“×” ×©××ª×” ××™×ª× ×• ×œ××•×¨×š ×”×“×¨×š ğŸ’™\n"
                        "×”×¦×¢×•×ª ×œ×©×™×¤×•×¨ ×™×ª×§×‘×œ×• ×‘×‘×¨×›×” â£ï¸\n"
                        "@moominAmir"
                    ),
                }
                try:
                    await context.bot.send_message(chat_id=user_id, text=messages.get(milestone, ""))
                except Exception:
                    pass
            # ×”×ª×¨××” ×œ××“××™×Ÿ ×œ××™×œ×¡×˜×•× ×™× ××©××¢×•×ª×™×™× (500+) â€” ×’× ×× ×›×‘×¨ ×¡×•××Ÿ, ×œ× ××¡×•×›×Ÿ ×œ×©×œ×•×— ×¤×¢× × ×•×¡×¤×ª
            if milestone >= 500:
                uname = (username or f"User_{user_id}")
                display = f"@{uname}" if uname and not str(uname).startswith('@') else str(uname)
                await notify_admins(context, f"ğŸ“¢ ××©×ª××© {display} ×”×’×™×¢ ×œÖ¾{milestone} ×¤×¢×•×œ×•×ª ×‘×‘×•×˜")
        except Exception:
            pass

    try:
        jq = getattr(context, "job_queue", None) or getattr(context.application, "job_queue", None)
        if jq is not None:
            # ×”×¨×¦×” ××™×™×“×™×ª ×‘×¨×§×¢ ×œ×œ× ×—×¡×™××”
            jq.run_once(lambda _ctx: context.application.create_task(_milestones_job(update.effective_user.id, update.effective_user.username)), when=0)
        else:
            # fallback: ×™×¦×™×¨×ª ××©×™××” ××¡×™× ×›×¨×•× ×™×ª ×™×©×™×¨×•×ª
            import asyncio as _aio
            _aio.create_task(_milestones_job(update.effective_user.id, update.effective_user.username))
    except Exception:
        pass

# =============================================================================
# MONGODB LOCK MANAGEMENT (FINAL, NO-GUESSING VERSION)
# =============================================================================

LOCK_ID = "code_keeper_bot_lock"  # legacy fallback
LOCK_COLLECTION = os.getenv("LOCK_COLLECTION", "locks")  # keep legacy default for safe rollouts
LOCK_TIMEOUT_MINUTES = 5  # legacy fallback (deprecated)

# Global lock state (used by cleanup + heartbeat)
_LOCK_SERVICE_ID: str | None = None
_LOCK_OWNER_ID: str | None = None
_LOCK_HEARTBEAT: "_MongoLockHeartbeat | None" = None

def get_lock_collection():
    """
    ××—×–×™×¨ ××ª ×§×•×œ×§×¦×™×™×ª ×”× ×¢×™×œ×•×ª ×××¡×“ ×”× ×ª×•× ×™×.
    
    Returns:
        pymongo.collection.Collection: ×§×•×œ×§×¦×™×™×ª ×”× ×¢×™×œ×•×ª
    
    Raises:
        SystemExit: ×× ××¡×“ ×”× ×ª×•× ×™× ×œ× ××•×ª×—×œ ×›×¨××•×™
    
    Note:
        ××©×ª××© ×‘××¡×“ ×”× ×ª×•× ×™× ×©×›×‘×¨ × ×‘×—×¨ ×‘-DatabaseManager
    """
    try:
        # Use the already-selected database from DatabaseManager
        selected_db = db.db
        if selected_db is None:
            logger.critical("DatabaseManager.db is not initialized!")
            try:
                emit_event("db_lock_db_missing", severity="critical", event="db_lock_db_missing")
            except Exception:
                pass
            sys.exit(1)
        # Optional: small debug to help diagnose DB mismatches
        try:
            logger.debug(f"Using DB for locks: {selected_db.name}")
        except Exception:
            pass
        return selected_db[LOCK_COLLECTION]
    except Exception as e:
        logger.critical(f"Failed to get lock collection from DatabaseManager: {e}", exc_info=True)
        try:
            emit_event("db_lock_get_failed", severity="critical", error=str(e))
        except Exception:
            pass
        sys.exit(1)

# New: ensure TTL index on expires_at so stale locks get auto-removed

def ensure_lock_indexes() -> None:
    """
    ×™×•×¦×¨ ××™× ×“×§×¡ TTL ×¢×œ ×©×“×” expires_at ×œ× ×™×§×•×™ ××•×˜×•××˜×™ ×©×œ × ×¢×™×œ×•×ª ×™×©× ×•×ª.
    
    Note:
        ×× ×™×¦×™×¨×ª ×”××™× ×“×§×¡ × ×›×©×œ×ª, ×”××¢×¨×›×ª ×ª××©×™×š ×œ×¢×‘×•×“ ×œ×œ× TTL ××•×˜×•××˜×™
    """
    try:
        lock_collection = get_lock_collection()
        # TTL based on the absolute expiration time in the document
        # Backward compatibility: support both legacy `expires_at` and new `expiresAt`
        failures: list[str] = []
        try:
            lock_collection.create_index("expires_at", expireAfterSeconds=0, name="lock_expires_at_ttl")
        except Exception as e:
            failures.append(str(e))
        try:
            lock_collection.create_index("expiresAt", expireAfterSeconds=0, name="lock_expiresAt_ttl")
        except Exception as e:
            failures.append(str(e))
        if failures:
            msg = "; ".join([f for f in failures if f])
            if not msg:
                msg = "ttl_index_failed"
            logger.warning(f"Could not ensure TTL index for lock collection: {msg}")
            try:
                emit_event("lock_ttl_index_failed", severity="warn", error=msg)
            except Exception:
                pass
    except Exception as e:
        # Non-fatal; continue without TTL if index creation fails
        logger.warning(f"Could not ensure TTL index for lock collection: {e}")
        try:
            emit_event("lock_ttl_index_failed", severity="warn", error=str(e))
        except Exception:
            pass


def _env_bool(name: str, default: bool) -> bool:
    try:
        raw = os.getenv(name)
        if raw is None:
            return bool(default)
        val = str(raw).strip().lower()
        if val in {"1", "true", "yes", "y", "on"}:
            return True
        if val in {"0", "false", "no", "n", "off"}:
            return False
        return bool(default)
    except Exception:
        return bool(default)


def _env_int(name: str, default: int) -> int:
    try:
        raw = os.getenv(name)
        if raw is None:
            return int(default)
        raw = str(raw).strip()
        if not raw:
            return int(default)
        return int(float(raw))
    except Exception:
        return int(default)


def _env_float(name: str, default: float) -> float:
    try:
        raw = os.getenv(name)
        if raw is None:
            return float(default)
        raw = str(raw).strip()
        if not raw:
            return float(default)
        return float(raw)
    except Exception:
        return float(default)


def _utcnow() -> datetime:
    return datetime.now(timezone.utc)


def _default_owner_id() -> str:
    rid = (os.getenv("RENDER_INSTANCE_ID") or "").strip()
    if rid:
        # ×—×©×•×‘: owner ×—×™×™×‘ ×œ×”×™×•×ª ×™×™×—×•×“×™ ×‘×¨××ª ×ª×”×œ×™×š.
        # ××—×¨×ª ×›××” ×ª×”×œ×™×›×™× ×‘××•×ª×• Render instance (×œ××©×œ overlapped restart / multi-worker)
        # ×™×—×©×‘×• ×‘×˜×¢×•×ª "×–×” ×× ×™" ×•×™×¢×©×• reacquire/heartbeat ×‘××§×‘×™×œ.
        return f"{rid}:{os.getpid()}"
    # fallback: stable enough per-process, and visible for forensics
    try:
        host = (os.getenv("HOSTNAME") or "").strip() or socket.gethostname()
    except Exception:
        host = "unknown-host"
    return f"{host}:{os.getpid()}"


def _default_host_label() -> str:
    v = (os.getenv("RENDER_SERVICE_NAME") or "").strip()
    if v:
        return v
    try:
        return (os.getenv("HOSTNAME") or "").strip() or socket.gethostname()
    except Exception:
        return "unknown-host"


def _compute_heartbeat_interval_seconds(*, lease_seconds: int, explicit: float | None) -> float:
    if explicit is not None and explicit > 0:
        return max(5.0, float(explicit))
    # default: 40% of lease, minimum 5 seconds
    return max(5.0, float(lease_seconds) * 0.4)


def _compute_passive_wait_seconds(min_seconds: float, max_seconds: float) -> float:
    lo = max(0.0, float(min_seconds))
    hi = max(lo, float(max_seconds))
    if hi <= lo:
        return lo
    return float(random.uniform(lo, hi))


_LOCK_SIGNALS_INSTALLED = False
_LOCK_ORIG_SIGNAL_HANDLERS: dict[int, object] = {}


def _install_lock_signal_handlers(*, service_id: str, owner_id: str) -> None:
    """×”×ª×§× ×ª handlers ×œ-SIGTERM/SIGINT ×œ×©×—×¨×•×¨ ×œ×•×§ ×œ×¤× ×™ ×™×¦×™××”.

    best-effort: ×× ×¤×œ×˜×¤×•×¨××”/×¡×¤×¨×™×™×” ××—×¨×ª ×”×ª×§×™× ×” handler, × × ×¡×” ×œ×©×¨×©×¨ ××œ×™×•.
    """
    global _LOCK_SIGNALS_INSTALLED
    if _LOCK_SIGNALS_INSTALLED:
        return
    # ××œ ×ª×™×’×¢ ×‘-signal handlers ×‘×˜×¡×˜×™×
    if os.getenv("PYTEST_CURRENT_TEST"):
        return

    def _handler(signum, _frame):  # noqa: ANN001
        try:
            try:
                emit_event(
                    "lock_signal_received",
                    severity="warn",
                    signal=int(signum),
                    service_id=service_id,
                    owner=owner_id,
                )
            except Exception:
                pass
            try:
                cleanup_mongo_lock()
            except Exception:
                pass
        finally:
            # Chain to original handler if it is callable
            orig = _LOCK_ORIG_SIGNAL_HANDLERS.get(int(signum))
            if callable(orig):
                try:
                    orig(signum, _frame)  # type: ignore[misc]
                except Exception:
                    pass
            # Ensure we exit even if chaining did nothing
            try:
                os._exit(0)
            except Exception:
                raise SystemExit(0)

    for sig in (getattr(signal, "SIGTERM", None), getattr(signal, "SIGINT", None)):
        if sig is None:
            continue
        try:
            _LOCK_ORIG_SIGNAL_HANDLERS[int(sig)] = signal.getsignal(sig)
        except Exception:
            _LOCK_ORIG_SIGNAL_HANDLERS[int(sig)] = None
        try:
            signal.signal(sig, _handler)
        except Exception:
            # ignore platforms that do not allow setting signals
            pass

    _LOCK_SIGNALS_INSTALLED = True


class _MongoLockHeartbeat:
    def __init__(
        self,
        *,
        lock_collection,
        service_id: str,
        owner_id: str,
        host_label: str,
        lease_seconds: int,
        interval_seconds: float,
    ) -> None:
        self._lock_collection = lock_collection
        self._service_id = service_id
        self._owner_id = owner_id
        self._host_label = host_label
        self._lease_seconds = int(lease_seconds)
        self._interval_seconds = float(interval_seconds)
        self._stop = threading.Event()
        self._thread: threading.Thread | None = None
        self._last_ok_monotonic = time.monotonic()
        self._local_expires_at = _utcnow() + timedelta(seconds=self._lease_seconds)
        try:
            self._instance_id = (os.getenv("RENDER_INSTANCE_ID") or "").strip()
        except Exception:
            self._instance_id = ""

    def _handle_lost_lock(self, reason: str) -> None:
        """
        × ×§×¨××ª ×›××©×¨ ×”-Heartbeat ××–×”×” ×©××™×‘×“× ×• ××ª ×”× ×¢×™×œ×” (××• ×©×× ×—× ×• ×¢×œ ×¡×£ ×¤×§×™×¢×”).
        ××‘×¦×¢×ª ×™×¦×™××” ×›×¤×•×™×” (Fail-Fast) ×›×“×™ ×œ×× ×•×¢ ××¦×‘ ×©×œ Zombie Bot ×•-telegram.error.Conflict.
        """
        try:
            emit_event(
                "lock_fail_fast_exit",
                severity="critical",
                service_id=self._service_id,
                owner=self._owner_id,
                host=self._host_label,
                instance=self._instance_id,
                pid=int(os.getpid()),
                reason=str(reason),
            )
        except Exception:
            pass

        logger.critical(f"ğŸš¨ CRITICAL: Lock ownership lost! Reason: {reason}")
        logger.critical(
            f"ğŸ’€ Killing process {os.getpid()} immediately to prevent telegram.error.Conflict..."
        )

        # × ×•×ª× ×™× ×œ×œ×•×’×™× ×¨×’×¢ ×œ×”×™×›×ª×‘ (×‘×¨×©×ª/×“×™×¡×§). ×‘×˜×¡×˜×™× ×œ× ×¨×•×¦×™× ×”×©×”×™×™×” ×××™×ª×™×ª.
        try:
            sleep_seconds = 0.0 if os.getenv("PYTEST_CURRENT_TEST") else 1.0
        except Exception:
            sleep_seconds = 1.0
        try:
            if sleep_seconds > 0:
                time.sleep(float(sleep_seconds))
        except Exception:
            pass

        # ×”×¨×’ ××™×™×“×™ ×©×œ ×›×œ ×”×ª×”×œ×™×š (×›×•×œ×œ Threads ×•-Greenlets).
        # ×§×•×“ 1 ××¡××Ÿ ×œ-Render ×©×”×™×™×ª×” ×™×¦×™××” ×œ× ×ª×§×™× ×” (×›×“×™ ×©×™×¤×¢×™×œ ××—×“×© ×× ×¦×¨×™×š).
        os._exit(1)

    def start(self) -> None:
        if self._thread is not None:
            return
        t = threading.Thread(target=self._run, name="mongo_lock_heartbeat", daemon=True)
        self._thread = t
        t.start()
        try:
            emit_event(
                "lock_heartbeat_started",
                severity="info",
                service_id=self._service_id,
                owner=self._owner_id,
                interval_seconds=float(self._interval_seconds),
                lease_seconds=int(self._lease_seconds),
            )
        except Exception:
            pass

    def stop(self, *, join_timeout_seconds: float = 2.0) -> None:
        try:
            self._stop.set()
        except Exception:
            pass
        t = self._thread
        if t is None:
            return
        try:
            t.join(timeout=float(join_timeout_seconds))
        except Exception:
            pass

    def _run(self) -> None:
        # In tests we keep behavior deterministic and avoid background threads unless explicitly enabled.
        if os.getenv("PYTEST_CURRENT_TEST") and not _env_bool("LOCK_ENABLE_HEARTBEAT_IN_TESTS", False):
            return

        while not self._stop.is_set():
            # Wait first (so a caller can stop immediately on shutdown).
            # ×—×©×•×‘: ×œ× ××¡×ª××›×™× ×¨×§ ×¢×œ interval ×§×‘×•×¢.
            # ×× ×”-lease ××ª×§×¨×‘ ×œ×¤×§×™×¢×” ×•×”-network × ×›×©×œ, interval ×’×“×•×œ ×™×›×•×œ ×œ×™×¦×•×¨ "×—×œ×•×Ÿ ×—×¤×™×¤×”"
            # ×©×‘×• ×”×œ×•×§ ×¤×’ ×‘-Mongo ××‘×œ ×”××•×¤×¢ ×¢×“×™×™×Ÿ ×—×™ ×¢×“ ×”×˜×™×§ ×”×‘×.
            # ×œ×›×Ÿ ×× ×—× ×• ××§×¦×¨×™× sleep ×›××©×¨ ××ª×§×¨×‘×™× ×œ-expiry ×”××§×•××™.
            try:
                if self._should_exit_due_to_local_expiry():
                    try:
                        emit_event(
                            "lock_heartbeat_local_expired_exiting",
                            severity="critical",
                            service_id=self._service_id,
                            owner=self._owner_id,
                        )
                    except Exception:
                        pass
                    logger.critical(
                        "Local lock lease is about to expire; exiting to prevent double polling."
                    )
                    self._handle_lost_lock("Local lock lease is about to expire (pre-heartbeat)")
            except Exception:
                # best-effort only
                pass

            sleep_seconds = self._compute_next_sleep_seconds()
            try:
                self._stop.wait(timeout=float(sleep_seconds))
            except Exception:
                time.sleep(float(sleep_seconds))
            if self._stop.is_set():
                break
            self._tick_once()

    def _compute_next_sleep_seconds(self, *, now: datetime | None = None) -> float:
        """×§×•×‘×¢ ×›××” ×–××Ÿ ×œ×™×©×•×Ÿ ×¢×“ × ×™×¡×™×•×Ÿ heartbeat ×”×‘×.

        ×”×¢×™×§×¨×•×Ÿ: interval ×§×‘×•×¢ ×”×•× ×‘×¨×™×¨×ª ××—×“×œ, ××‘×œ ×›×©××ª×§×¨×‘×™× ×œ-expiry ×”××§×•××™
        ×× ×—× ×• ××ª×¢×•×¨×¨×™× ××•×§×“× ×™×•×ª×¨ (expiry_guard) ×›×“×™ ×œ×× ×•×¢ ×—×œ×•×Ÿ ×—×¤×™×¤×”.
        """
        if now is None:
            now = _utcnow()
        try:
            remaining = float((self._local_expires_at - now).total_seconds())
        except Exception:
            remaining = float(self._interval_seconds)

        expiry_guard_seconds = 2.0
        # Wake up no later than (expiry - guard)
        wake_in = min(float(self._interval_seconds), max(0.2, remaining - expiry_guard_seconds))
        return max(0.2, float(wake_in))

    def _should_exit_due_to_local_expiry(self, *, now: datetime | None = None) -> bool:
        if now is None:
            now = _utcnow()
        try:
            return now >= (self._local_expires_at - timedelta(seconds=2))
        except Exception:
            return False

    def _tick_once(self) -> None:
        """×¨×™×¦×ª heartbeat ××—×ª (××•×¤×¨×“×ª ×œ×˜×¡×˜×™×)."""
        now = _utcnow()
        # ××—×©×‘×™× ×™×¢×“ ×—×“×©, ××‘×œ ×œ× "×××¨×™×›×™×" ××§×•××™×ª ×œ×¤× ×™ ×©×”×¢×“×›×•×Ÿ ×”×¦×œ×™×— ×‘×¤×•×¢×œ ×‘-MongoDB.
        # ××—×¨×ª: ×ª×§×œ×” ×¨×’×¢×™×ª (timeout/failover) ×™×›×•×œ×” ×œ×’×¨×•× ×œ× ×• ×œ×—×©×•×‘ ×©×™×© ×œ× ×• lease,
        # ×‘×¢×•×“ ×©×‘-Mongo ×”× ×¢×™×œ×” ×¤×’×” ×•××•×¤×¢ ××—×¨ ×™×›×•×œ ×œ×¨×›×•×© ××•×ª×” -> double polling.
        target_exp = now + timedelta(seconds=self._lease_seconds)

        try:
            res = self._lock_collection.update_one(
                {"_id": self._service_id, "owner": self._owner_id},
                {
                    "$set": {
                        "expiresAt": target_exp,
                        "expires_at": target_exp,  # legacy alias
                        "updatedAt": now,
                        "host": self._host_label,
                        "instance": self._instance_id,
                        "pid": int(os.getpid()),
                    }
                },
            )
            matched = int(getattr(res, "matched_count", 0) or 0)
            if matched <= 0:
                # Ownership lost: exit immediately to prevent dual polling.
                try:
                    emit_event(
                        "lock_ownership_lost",
                        severity="critical",
                        service_id=self._service_id,
                        owner=self._owner_id,
                    )
                except Exception:
                    pass
                self._handle_lost_lock("Database document mismatch (stolen lock)")

            # ×¢×“×›×•×Ÿ ×”×¦×œ×™×— ×•×”××¡××š ×¢×“×™×™×Ÿ ×‘×‘×¢×œ×•×ª× ×• -> ×¢×›×©×™×• ××•×ª×¨ ×œ×¢×“×›×Ÿ ××ª ×”-expiry ×”××§×•××™
            self._local_expires_at = target_exp
            self._last_ok_monotonic = time.monotonic()
        except Exception as e:
            # If we fail to refresh close to local expiry, exit rather than risk polling without a valid lease.
            try:
                emit_event(
                    "lock_heartbeat_failed",
                    severity="error",
                    service_id=self._service_id,
                    owner=self._owner_id,
                    error=str(e),
                )
            except Exception:
                pass
            logger.warning(f"Mongo lock heartbeat failed: {e}", exc_info=True)

            try:
                # ×—×©×•×‘: ××©×ª××©×™× ×‘-expiry ×”××—×¨×•×Ÿ ×©×”×¦×œ×—× ×• ×œ×—×“×© ×‘×¤×•×¢×œ,
                # ×•×œ× ×‘"×™×¢×“" ×”× ×•×›×—×™ ×©× ×›×©×œ, ×›×“×™ ×œ× ×œ×”××¨×™×š ××§×•××™×ª ×‘×˜×¢×•×ª.
                # ×—×©×•×‘ ×œ× ×¤×—×•×ª: ×“×•×’××™× ×–××Ÿ ××—×“×© ×›××Ÿ, ×›×™ update_one ×™×›×•×œ ×œ×”×™×ª×§×¢ ×–××Ÿ ×¨×‘
                # (timeout/failover), ×•××– now ××ª×—×™×œ×ª ×”×¤×•× ×§×¦×™×” ×¢×œ×•×œ ×œ×”×™×•×ª "×™×©×Ÿ" ××“×™.
                check_now = _utcnow()
                if check_now >= (self._local_expires_at - timedelta(seconds=2)):
                    try:
                        emit_event(
                            "lock_heartbeat_expiring_exiting",
                            severity="critical",
                            service_id=self._service_id,
                            owner=self._owner_id,
                            error=str(e),
                        )
                    except Exception:
                        pass
                    self._handle_lost_lock(f"Lease expired during network error ({e})")
            except Exception:
                # If we can't reason about expiry, prefer staying alive; ownership-loss check will kill us if needed.
                pass


def cleanup_mongo_lock() -> bool:
    """
    ×× ×§×” ××ª × ×¢×™×œ×ª MongoDB ×‘×¢×ª ×™×¦×™××” ××”×ª×•×›× ×™×ª.
    
    Returns:
        bool: True ×× ×”× ×™×§×•×™ ×‘×•×¦×¢ ×œ×œ× ×©×’×™××” ×œ×•×’×™×ª/×—×™×‘×•×¨, False ×× ×›×©×œ (×œ××©×œ client ×¡×’×•×¨)
    
    Note:
        ×¤×•× ×§×¦×™×” ×–×• × ×¨×©××ª ×¢× atexit ×•×¨×¦×” ××•×˜×•××˜×™×ª ×‘×¡×™×•× ×”×ª×•×›× ×™×ª
    """
    try:
        # Stop heartbeat first (best-effort)
        global _LOCK_HEARTBEAT
        try:
            hb = _LOCK_HEARTBEAT
            _LOCK_HEARTBEAT = None
            if hb is not None:
                hb.stop()
        except Exception:
            pass

        # If DB client is not available, skip quietly (× ×—×©×‘ ×›×”×¦×œ×—×” â€” ××™×Ÿ ××” ×œ× ×§×•×ª)
        try:
            if 'db' in globals() and getattr(db, "client", None) is None:
                logger.debug("Mongo client not available during lock cleanup; skipping.")
                return True
        except Exception:
            pass

        lock_collection = get_lock_collection()
        pid = os.getpid()
        service_id = _LOCK_SERVICE_ID or (os.getenv("SERVICE_ID") or LOCK_ID)
        owner_id = _LOCK_OWNER_ID or _default_owner_id()
        # Delete only if we're the owner. Legacy fallback: if owner is missing, allow pid-based cleanup.
        result = lock_collection.delete_one(
            {
                "_id": service_id,
                "$or": [
                    {"owner": owner_id},
                    {"owner": {"$exists": False}, "pid": int(pid)},
                ],
            }
        )
        if result.deleted_count > 0:
            logger.info(f"Lock '{service_id}' released successfully. owner={owner_id} pid={pid}")
            try:
                emit_event("lock_released", severity="info", pid=pid, service_id=service_id, owner=owner_id)
            except Exception:
                pass
        # ×’× ×× ×œ× × ××—×§ â€” ×”× ×™×§×•×™ idempotent; × ×—×©×‘ ×›×”×¦×œ×—×”
        return True
    except pymongo.errors.InvalidOperation:
        logger.warning("Mongo client already closed; skipping lock cleanup.")
        try:
            emit_event("lock_cleanup_skipped_client_closed", severity="warn")
        except Exception:
            pass
        return False
    except Exception as e:
        logger.error(f"Error while releasing MongoDB lock: {e}", exc_info=True)
        try:
            emit_event("lock_release_error", severity="error", error=str(e))
        except Exception:
            pass
        return False

def manage_mongo_lock():
    """
    ×¨×•×›×© × ×¢×™×œ×” ××‘×•×–×¨×ª ×‘-MongoDB ×›×“×™ ×œ×”×‘×˜×™×— ×©×¨×§ ××•×¤×¢ ××—×“ ×©×œ ×”×‘×•×˜ ×¨×¥.
    
    Returns:
        bool: True ×× ×”× ×¢×™×œ×” × ×¨×›×©×” ×‘×”×¦×œ×—×”, False ××—×¨×ª
    
    Note:
        ×ª×•××š ×‘×”××ª× ×” ×œ×©×—×¨×•×¨ × ×¢×™×œ×” ×§×™×™××ª ×¢×‘×•×¨ blue/green deployments
    """
    wait_health = _LockWaitHealthServer(port=-1)
    try:
        try:
            ensure_lock_indexes()
        except Exception:
            logger.warning("could not ensure lock indexes; continuing")
        lock_collection = get_lock_collection()
        service_id = (os.getenv("SERVICE_ID") or LOCK_ID).strip() or LOCK_ID
        owner_id = _default_owner_id()
        host_label = _default_host_label()
        instance_id = (os.getenv("RENDER_INSTANCE_ID") or "").strip()
        pid = int(os.getpid())

        # Config
        lease_seconds = max(5, _env_int("LOCK_LEASE_SECONDS", 60))
        hb_override = os.getenv("LOCK_HEARTBEAT_INTERVAL")
        hb_explicit = None
        try:
            hb_explicit = float(hb_override) if (hb_override is not None and str(hb_override).strip()) else None
        except Exception:
            hb_explicit = None
        heartbeat_interval = _compute_heartbeat_interval_seconds(lease_seconds=lease_seconds, explicit=hb_explicit)

        wait_for_acquire = _env_bool("LOCK_WAIT_FOR_ACQUIRE", False)
        # Backward compatible alias: LOCK_MAX_WAIT_SECONDS (legacy)
        acquire_max_wait = _env_float("LOCK_ACQUIRE_MAX_WAIT", 0.0)
        if acquire_max_wait <= 0:
            acquire_max_wait = float(_env_int("LOCK_MAX_WAIT_SECONDS", 0) or 0)
        wait_min = _env_float("LOCK_WAIT_MIN_SECONDS", 15.0)
        wait_max = _env_float("LOCK_WAIT_MAX_SECONDS", 45.0)
        active_retry_interval = float(_env_float("LOCK_RETRY_INTERVAL_SECONDS", 1.0))

        fail_open = _env_bool("LOCK_FAIL_OPEN", False)

        start_monotonic = time.monotonic()

        # Optionally start a tiny health server while we wait (Render-safe)
        wait_health = _LockWaitHealthServer.maybe_start_when_waiting()

        while True:
            now = _utcnow()
            exp = now + timedelta(seconds=int(lease_seconds))

            # Attempt: create lock doc
            try:
                lock_collection.insert_one(
                    {
                        "_id": service_id,
                        "owner": owner_id,
                        "host": host_label,
                        "instance": instance_id,
                        "pid": pid,
                        "createdAt": now,
                        "updatedAt": now,
                        "expiresAt": exp,
                        "expires_at": exp,  # legacy alias
                    }
                )
                logger.info(f"âœ… MongoDB lock acquired. service_id={service_id} owner={owner_id} pid={pid}")
                try:
                    emit_event("lock_acquired", severity="info", pid=pid, service_id=service_id, owner=owner_id)
                except Exception:
                    pass
                break
            except DuplicateKeyError:
                # Document exists; attempt takeover if expired, or idempotent refresh if already ours.
                result = None
                try:
                    # Prefer ReturnDocument if available; otherwise, keep compatibility with older pymongo stubs.
                    try:
                        from pymongo import ReturnDocument  # type: ignore
                        _ret_after = ReturnDocument.AFTER
                    except Exception:  # pragma: no cover
                        _ret_after = True

                    result = lock_collection.find_one_and_update(
                        {
                            "_id": service_id,
                            "$or": [
                                {"owner": owner_id},
                                {"expiresAt": {"$lte": now}},
                                {"expires_at": {"$lte": now}},
                            ],
                        },
                        {
                            "$set": {
                                "owner": owner_id,
                                "host": host_label,
                                "instance": instance_id,
                                "pid": pid,
                                "updatedAt": now,
                                "expiresAt": exp,
                                "expires_at": exp,
                            },
                            "$setOnInsert": {"createdAt": now},
                        },
                        return_document=_ret_after,
                    )
                except Exception:
                    result = None

                if result and isinstance(result, dict) and result.get("owner") == owner_id:
                    logger.info(f"âœ… MongoDB lock re-acquired. service_id={service_id} owner={owner_id} pid={pid}")
                    try:
                        emit_event("lock_reacquired", severity="info", pid=pid, service_id=service_id, owner=owner_id)
                    except Exception:
                        pass
                    break

                # Not ours, not expired => wait
                if wait_for_acquire:
                    if acquire_max_wait > 0 and (time.monotonic() - start_monotonic) >= float(acquire_max_wait):
                        logger.warning("Timeout waiting for lock; exiting gracefully.")
                        try:
                            emit_event(
                                "lock_wait_timeout",
                                severity="warn",
                                max_wait_seconds=float(acquire_max_wait),
                                service_id=service_id,
                            )
                        except Exception:
                            pass
                        try:
                            wait_health.stop()
                        except Exception:
                            pass
                        return False

                    sleep_s = max(0.2, float(active_retry_interval))
                    logger.info(
                        f"Lock busy (active wait). service_id={service_id} will retry in {sleep_s:.1f}s..."
                    )
                    try:
                        emit_event(
                            "lock_waiting_existing",
                            severity="warn",
                            mode="active",
                            sleep_seconds=float(sleep_s),
                            service_id=service_id,
                        )
                    except Exception:
                        pass
                    time.sleep(sleep_s)
                    continue

                # Passive wait with jitter to avoid restart loops (default)
                sleep_s = _compute_passive_wait_seconds(wait_min, wait_max)
                logger.warning(
                    f"Another instance holds the lock; waiting (passive) {sleep_s:.1f}s. service_id={service_id}"
                )
                try:
                    emit_event(
                        "lock_waiting_existing",
                        severity="warn",
                        mode="passive",
                        sleep_seconds=float(sleep_s),
                        service_id=service_id,
                    )
                except Exception:
                    pass
                time.sleep(float(sleep_s))
                continue

            except Exception as e:
                # Unexpected insert error: break to outer handler
                raise e

        # Acquired: stop wait health server if started
        try:
            wait_health.stop()
        except Exception:
            pass

        # Save global ownership state for cleanup/heartbeat
        global _LOCK_SERVICE_ID, _LOCK_OWNER_ID, _LOCK_HEARTBEAT
        _LOCK_SERVICE_ID = service_id
        _LOCK_OWNER_ID = owner_id

        # Ensure lock is released on exit ASAP after ownership is established
        # (×’× ×× ×©×œ×‘×™× ×××•×—×¨×™× ×™×•×ª×¨ ×™×™×›×©×œ×•)
        try:
            atexit.register(cleanup_mongo_lock)
        except Exception:
            pass

        # Start heartbeat (disabled by default in tests unless explicitly enabled)
        try:
            hb = _MongoLockHeartbeat(
                lock_collection=lock_collection,
                service_id=service_id,
                owner_id=owner_id,
                host_label=host_label,
                lease_seconds=int(lease_seconds),
                interval_seconds=float(heartbeat_interval),
            )
            _LOCK_HEARTBEAT = hb
            hb.start()
        except Exception as e:
            # Fail-closed: if we can't keep ownership fresh, better to not start polling
            logger.error(f"Failed to start lock heartbeat: {e}", exc_info=True)
            try:
                emit_event("lock_heartbeat_start_failed", severity="error", error=str(e), service_id=service_id)
            except Exception:
                pass
            # ×—×©×•×‘: ××œ ×ª×©××™×¨ lock ×™×ª×•× ×‘××•× ×’×• ×× ×”-heartbeat ×œ× ×¢×œ×”.
            try:
                res = lock_collection.delete_one({"_id": service_id, "owner": owner_id})
                if int(getattr(res, "deleted_count", 0) or 0) > 0:
                    try:
                        emit_event(
                            "lock_released",
                            severity="warn",
                            service_id=service_id,
                            owner=owner_id,
                            pid=int(pid),
                            reason="heartbeat_start_failed",
                        )
                    except Exception:
                        pass
            except Exception:
                pass
            # × ×§×” state ×’×œ×•×‘×œ×™ ×›×“×™ ×œ×× ×•×¢ cleanup ×¢×ª×™×“×™ ×¢×œ owner "××—×¨"
            try:
                _LOCK_HEARTBEAT = None
                _LOCK_SERVICE_ID = None
                _LOCK_OWNER_ID = None
            except Exception:
                pass
            if not fail_open:
                return False
            # Fail-open explicit: continue without lock (still log loudly)
            return True

        # Install signal handlers after lock ownership is established
        try:
            _install_lock_signal_handlers(service_id=service_id, owner_id=owner_id)
        except Exception:
            pass
        return True

    except Exception as e:
        # Ensure wait health server is not left running in any exception path
        try:
            wait_health.stop()
        except Exception:
            pass
        logger.error(f"Failed to acquire MongoDB lock: {e}", exc_info=True)
        try:
            emit_event("lock_acquire_failed", severity="error", error=str(e))
        except Exception:
            pass
        # Fail-closed by default: don't run polling without a lock (unless explicitly opted-in)
        if _env_bool("LOCK_FAIL_OPEN", False):
            return True
        return False
    finally:
        # Best-effort cleanup: never leave the temporary health server bound to PORT
        try:
            wait_health.stop()
        except Exception:
            pass


class _LockWaitHealthServer:
    """×©×¨×ª HTTP ××™× ×™××œ×™ ×œ-/ /health /healthz ×‘×–××Ÿ ×”××ª× ×” ×œ×œ×•×§.

    ××˜×¨×”: ×œ×× ×•×¢ restart-loop ×‘-Render ×›××©×¨ ×”×©×™×¨×•×ª ××•×’×“×¨ ×›-Web Service ×¢× health check.
    """

    def __init__(self, *, port: int) -> None:
        self._port = int(port)
        self._thread: threading.Thread | None = None
        self._server = None

    @classmethod
    def maybe_start_when_waiting(cls) -> "_LockWaitHealthServer":
        # Enable only on platforms that expose PORT (Render/Heroku), and only if explicitly enabled.
        # Default is enabled to align with Render "health passes while waiting".
        if not _env_bool("LOCK_WAIT_HEALTH_SERVER_ENABLED", True):
            return cls(port=-1)
        raw_port = os.getenv("PORT")
        if raw_port is None:
            return cls(port=-1)
        try:
            port = int(str(raw_port).strip() or "0")
        except Exception:
            port = 0
        if port <= 0:
            return cls(port=-1)
        srv = cls(port=port)
        try:
            srv.start()
        except Exception:
            pass
        return srv

    def start(self) -> None:
        if self._port <= 0:
            return
        if self._thread is not None:
            return

        # Use stdlib HTTP server to avoid dependency or asyncio loop juggling.
        from http.server import BaseHTTPRequestHandler, HTTPServer  # local import

        class _Handler(BaseHTTPRequestHandler):
            def do_GET(self):  # noqa: N802
                try:
                    path = str(getattr(self, "path", "") or "")
                except Exception:
                    path = "/"
                if path in {"/", "/health", "/healthz"}:
                    payload = b'{"status":"ok","mode":"waiting_for_lock"}'
                    self.send_response(200)
                    self.send_header("Content-Type", "application/json; charset=utf-8")
                    self.send_header("Content-Length", str(len(payload)))
                    self.end_headers()
                    self.wfile.write(payload)
                    return
                self.send_response(404)
                self.end_headers()

            def log_message(self, *_a, **_k):  # noqa: ANN001, D401
                # silence request logs
                return

        httpd = HTTPServer(("0.0.0.0", int(self._port)), _Handler)
        self._server = httpd

        def _run():
            try:
                httpd.serve_forever(poll_interval=0.5)
            except Exception:
                return

        t = threading.Thread(target=_run, name="lock_wait_health_http", daemon=True)
        self._thread = t
        t.start()
        try:
            emit_event("lock_wait_health_server_started", severity="info", port=int(self._port))
        except Exception:
            pass

    def stop(self) -> None:
        httpd = self._server
        if httpd is None:
            return
        try:
            httpd.shutdown()
        except Exception:
            pass
        try:
            httpd.server_close()
        except Exception:
            pass
        self._server = None

# =============================================================================
# Global reference to the current bot instance
# ××©××© ×›×“×™ ×œ××¤×©×¨ ×œ-main() ×œ×¢×©×•×ª reuse ×©×œ ××™× ×¡×˜× ×¡ ×§×™×™× (×œ×¦×¨×›×™ ×˜×¡×˜×™×/××ª×—×•×œ)
CURRENT_BOT: CodeKeeperBot | None = None  # ×™×•×’×“×¨ ×‘×ª×•×š CodeKeeperBot.__init__


class HelpEntry(TypedDict):
    """×ª×™××•×¨ ×©×œ ×©×•×¨×ª ×¢×–×¨×”."""
    commands: tuple[str, ...]
    description: str | None
    suffix: NotRequired[str]


class HelpSection(TypedDict):
    """×§×‘×•×¦×ª ×¤×§×•×“×•×ª ×œ×œ× ×›×¤×ª×•×¨×™×."""
    title: str
    entries: list[HelpEntry]
    admin_only: NotRequired[bool]
    entries_source: NotRequired[str]


HELP_SECTIONS: list[HelpSection] = [
    {
        "title": "ğŸ”” <b>×ª×–×›×•×¨×•×ª</b>",
        "entries": [
            {"commands": ("remind",), "description": "×™×¦×™×¨×ª ×ª×–×›×•×¨×ª ×—×›××”"},
            {"commands": ("reminders",), "description": "×¨×©×™××ª ×ª×–×›×•×¨×•×ª ×•× ×™×”×•×œ"},
        ],
    },
    {
        "title": "ğŸ¨ <b>×ª××•× ×•×ª ×§×•×“</b>",
        "entries": [
            {"commands": ("image",), "description": "×™×™×¦×•×¨ ×ª××•× ×” ××¢×•×¦×‘×ª", "suffix": " &lt;×§×•×‘×¥&gt;"},
            {"commands": ("preview",), "description": "×ª×¦×•×’×” ××§×“×™××” ×©×œ ×§×•×‘×¥", "suffix": " &lt;×§×•×‘×¥&gt;"},
        ],
    },
    {
        "title": "ğŸ§° <b>××˜××•×Ÿ</b>",
        "entries": [
            {"commands": ("cache_stats",), "description": "×”×¦×’×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ××˜××•×Ÿ (Cache)"},
            {"commands": ("clear_cache",), "description": "× ×™×§×•×™ ××˜××•×Ÿ ×œ××©×ª××© ×”× ×•×›×—×™"},
        ],
    },
    {
        "title": "ğŸ—ï¸ <b>×¨×¤×§×˜×•×¨×™× ×’</b>",
        "entries": [
            {"commands": ("refactor",), "description": "×¨×¤×§×˜×•×¨×™× ×’ ××•×˜×•××˜×™ ×œ×§×•×‘×¥", "suffix": " &lt;×§×•×‘×¥&gt;"},
        ],
    },
    {
        "title": "âš™ï¸ <b>×× ×”×œ (××•×’×‘×œ)</b>",
        "admin_only": True,
        "entries_source": "chatops_catalog",
        "entries": [
            {
                "commands": ("status",),
                "description": "×“×•×— ×—×œ×•×Ÿ ×–××Ÿ + ×‘×“×™×§×•×ª ×‘×¨×™××•×ª (UTC)",
                "suffix": " <code>--since 15m</code> | <code>--from 2025-12-16T10:00 --to 2025-12-16T10:15</code>",
            },
            {
                "commands": ("errors",),
                "description": "Top ×©×’×™××•×ª + ×“×•×— ×—×œ×•×Ÿ ×–××Ÿ (UTC)",
                "suffix": " <code>--since 15m</code> | <code>--from ... --to ...</code> | <code>--endpoint /api</code> | <code>--min_severity ERROR</code>",
            },
            {"commands": ("metrics", "uptime"), "description": None},
        ],
    },
]

SUPPORT_FOOTER = "×œ×‘×¢×™×•×ª ××• ×”×¦×¢×•×ª: @moominAmir"

HELP_SECTION_COMMANDS = {
    cmd.lower()
    for section in HELP_SECTIONS
    for entry in section["entries"]
    for cmd in entry["commands"]
}

# ×¤×§×•×“×•×ª ×©××•×¤×™×¢×•×ª ×‘×¡×§×©× ×™× ×©××™× × admin (×›×“×™ ×œ× ×œ×©×›×¤×œ ××•×ª×Ÿ ×‘×¡×§×©×Ÿ ChatOps ××“××™× ×™)
NON_ADMIN_SECTION_COMMANDS: set[str] = {
    cmd.lower()
    for section in HELP_SECTIONS
    if not bool(section.get("admin_only"))
    for entry in section["entries"]
    for cmd in entry["commands"]
}

HELP_EXCLUDED_COMMANDS: set[str] = {"start", "help", "cancel", "done"}

STATIC_HELP_MESSAGE = (
    "<b>ğŸ“š ×¢×–×¨×” â€“ ×¤×§×•×“×•×ª ×œ×œ× ×›×¤×ª×•×¨×™×</b>\n\n"
    "ğŸ”” <b>×ª×–×›×•×¨×•×ª</b>\n"
    "â€¢ <code>/remind</code> â€“ ×™×¦×™×¨×ª ×ª×–×›×•×¨×ª ×—×›××”\n"
    "â€¢ <code>/reminders</code> â€“ ×¨×©×™××ª ×ª×–×›×•×¨×•×ª ×•× ×™×”×•×œ\n\n"
    "ğŸ¨ <b>×ª××•× ×•×ª ×§×•×“</b>\n"
    "â€¢ <code>/image</code> &lt;×§×•×‘×¥&gt; â€“ ×™×™×¦×•×¨ ×ª××•× ×” ××¢×•×¦×‘×ª\n"
    "â€¢ <code>/preview</code> &lt;×§×•×‘×¥&gt; â€“ ×ª×¦×•×’×” ××§×“×™××”\n\n"
    "ğŸ§° <b>××˜××•×Ÿ</b>\n"
    "â€¢ <code>/cache_stats</code> â€“ ×”×¦×’×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ××˜××•×Ÿ (Cache)\n"
    "â€¢ <code>/clear_cache</code> â€“ × ×™×§×•×™ ××˜××•×Ÿ ×œ××©×ª××© ×”× ×•×›×—×™\n\n"
    "ğŸ—ï¸ <b>×¨×¤×§×˜×•×¨×™× ×’</b>\n"
    "â€¢ <code>/refactor</code> &lt;×§×•×‘×¥&gt; â€“ ×¨×¤×§×˜×•×¨×™× ×’ ××•×˜×•××˜×™ ×œ×§×•×‘×¥\n\n"
    f"{SUPPORT_FOOTER}"
)

@functools.lru_cache(maxsize=1)
def _load_chatops_commands_catalog() -> list[dict[str, Any]]:
    """×˜×•×¢×Ÿ ××ª ×§×˜×œ×•×’ ×¤×§×•×“×•×ª ChatOps ××ª×•×š commands.json (×–×” ××§×•×¨ ×”×××ª ×©×œ ×”×ª×™×¢×•×“)."""
    try:
        path = Path(__file__).resolve().parent / "webapp" / "static" / "data" / "commands.json"
        raw = path.read_text(encoding="utf-8")
        data = json.loads(raw)
        if not isinstance(data, list):
            return []
        return [item for item in data if isinstance(item, dict)]
    except Exception:
        return []


def _build_chatops_help_entries_from_catalog() -> list[HelpEntry]:
    """×××™×¨ ××ª ×§×˜×œ×•×’ ChatOps ×œ×¨×©×™××ª HelpEntry ×‘×¤×•×¨××˜ ×©×œ /help."""
    try:
        from html import escape as html_escape

        out: list[HelpEntry] = []
        for item in _load_chatops_commands_catalog():
            if str(item.get("type", "")).strip().lower() != "chatops":
                continue

            name = str(item.get("name", "")).strip()
            if not name.startswith("/"):
                continue

            # name ×™×›×•×œ ×œ×”×™×•×ª ×œ××©×œ "/observe -v" ××• "/check commands"
            parts = [p for p in name.split() if p.strip()]
            if not parts:
                continue

            cmd_token = parts[0].lstrip("/").strip().lower()
            if not cmd_token:
                continue
            # ×× ×™×¢×ª ×›×¤×™×œ×•×™×•×ª: ×× ×”×¤×§×•×“×” ×›×‘×¨ ××•×¦×’×ª ×‘×¡×§×©×Ÿ ×¦×™×‘×•×¨×™ (×›××• cache_stats/clear_cache),
            # ×œ× × ×¦×™×’ ××•×ª×” ×©×•×‘ ×ª×—×ª "×× ×”×œ (××•×’×‘×œ)".
            if cmd_token in NON_ADMIN_SECTION_COMMANDS:
                continue

            description_raw = item.get("description")
            description = description_raw.strip() if isinstance(description_raw, str) else None
            if not description:
                description = None

            suffix_chunks: list[str] = []
            for extra in parts[1:]:
                suffix_chunks.append(f"<code>{html_escape(str(extra))}</code>")

            args = item.get("arguments", [])
            if isinstance(args, list) and args:
                arg_codes = [
                    f"<code>{html_escape(str(a))}</code>"
                    for a in args
                    if isinstance(a, (str, int, float)) and str(a).strip()
                ]
                if arg_codes:
                    suffix_chunks.append(" | ".join(arg_codes))

            suffix = (" " + " ".join(suffix_chunks)) if suffix_chunks else ""
            out.append({"commands": (cmd_token,), "description": description, "suffix": suffix})

        return out
    except Exception:
        return []


def _split_long_message(text: str, *, max_len: int = 3900) -> list[str]:
    """
    ××¤×¦×œ ×”×•×“×¢×” ××¨×•×›×” ×œ×›××” ×”×•×“×¢×•×ª (×œ×¤×™ ×©×•×¨×•×ª) ×›×“×™ ×œ×”×™×©××¨ ××ª×—×ª ×œ××’×‘×œ×ª ×˜×œ×’×¨×.

    ×”×¢×¨×”: ×× ×—× ×• ××¤×¦×œ×™× ×œ×¤×™ '\n' ×‘×œ×‘×“ ×›×“×™ ×œ× ×œ×©×‘×•×¨ HTML (×›×œ ×”×ª×’×™× ×”× in-line).
    """
    try:
        if not isinstance(text, str) or not text:
            return [""]
        if len(text) <= max_len:
            return [text]
        lines = text.split("\n")
        chunks: list[str] = []
        buf: list[str] = []
        cur = 0
        for line in lines:
            add = (len(line) + (1 if buf else 0))
            if buf and (cur + add) > max_len:
                chunks.append("\n".join(buf))
                buf = [line]
                cur = len(line)
            else:
                if buf:
                    cur += 1  # newline
                buf.append(line)
                cur += len(line)
        if buf:
            chunks.append("\n".join(buf))
        return chunks or [text]
    except Exception:
        return [text]


def _resolve_section_entries(section: HelpSection) -> list[HelpEntry]:
    """×××¤×©×¨ ×œ×¡×§×©×Ÿ ×œ×”×‘×™× entries ×××§×•×¨ ×“×™× ××™, ×¢× fallback ×œ×¨×©×™××” ×”×§×©×™×—×”."""
    try:
        if section.get("entries_source") == "chatops_catalog":
            dyn = _build_chatops_help_entries_from_catalog()
            if dyn:
                return dyn
    except Exception:
        pass
    return section.get("entries", [])


def _collect_commands_from_handler(handler, seen_ids: set[int]) -> set[str]:
    """Extract command names (lowercase) from a handler or nested handlers."""
    commands: set[str] = set()
    if handler is None:
        return commands
    handler_id = id(handler)
    if handler_id in seen_ids:
        return commands
    seen_ids.add(handler_id)

    if isinstance(handler, CommandHandler):
        for cmd in getattr(handler, "commands", []) or []:
            names: list[str] = []
            if isinstance(cmd, str):
                names = [cmd]
            else:
                candidate = getattr(cmd, "command", None)
                if candidate is None:
                    candidate = getattr(cmd, "name", None)
                if isinstance(candidate, str):
                    names = [candidate]
                elif isinstance(candidate, (list, tuple, set)):
                    names = [str(item) for item in candidate if isinstance(item, str)]
            for name in names:
                if name:
                    commands.add(name.lower())
        return commands

    if isinstance(handler, ConversationHandler):
        kwargs: dict[str, Any] = getattr(handler, "kwargs", {}) if isinstance(getattr(handler, "kwargs", {}), dict) else {}
        entry_points = getattr(handler, "entry_points", None)
        if entry_points is None:
            entry_points = kwargs.get("entry_points")
        for nested in entry_points or []:
            commands |= _collect_commands_from_handler(nested, seen_ids)
        states = getattr(handler, "states", None)
        if states is None:
            states = kwargs.get("states")
        for nested_list in (states or {}).values():
            for nested in nested_list or []:
                commands |= _collect_commands_from_handler(nested, seen_ids)
        fallbacks = getattr(handler, "fallbacks", None)
        if fallbacks is None:
            fallbacks = kwargs.get("fallbacks")
        for nested in fallbacks or []:
            commands |= _collect_commands_from_handler(nested, seen_ids)
        return commands

    # Composite handler (tuple/list) â€“ iterate children if ×§×™×™××™×
    if isinstance(handler, (list, tuple, set)):
        for nested in handler:
            commands |= _collect_commands_from_handler(nested, seen_ids)

    return commands


def _get_registered_commands(application) -> set[str]:
    """Return the set of command names registered on the given application."""
    if application is None:
        return set()

    handlers_container = getattr(application, "handlers", None)
    if handlers_container is None:
        return set()

    command_names: set[str] = set()

    if isinstance(handlers_container, dict):
        iterable = handlers_container.values()
    else:
        iterable = handlers_container

    for entry in iterable:
        handler = entry
        if isinstance(entry, tuple) and entry:
            handler = entry[0]
        command_names |= _collect_commands_from_handler(handler, set())

    return command_names


def _build_debug_commands_report(
    *,
    registered_commands: set[str],
    public_menu_commands: list[Any] | None = None,
    personal_menu_commands: list[Any] | None = None,
) -> str:
    """
    ×‘×•× ×” ×“×•×— ×“×™×‘×•×’ ×¢×œ ×¤×§×•×“×•×ª slash:
    - ×›×œ ×”×¤×§×•×“×•×ª ×©× ×¨×©××• ×›-CommandHandler ×‘-runtime (×›×•×œ×œ ×›××œ×” ×©×œ× ×‘×ª×¤×¨×™×˜ ×˜×œ×’×¨×)
    - (××•×¤×¦×™×•× ×œ×™) ×”×©×•×•××” ××•×œ get_my_commands ×›×“×™ ×œ×–×”×•×ª ×¤×§×•×“×•×ª "××•×¡×ª×¨×•×ª" ××”×ª×¤×¨×™×˜
    """
    from html import escape as html_escape

    registered = sorted({str(c).lower().lstrip("/") for c in (registered_commands or set()) if c})
    registered_set = set(registered)

    def _extract_menu_names(cmds: list[Any] | None) -> set[str]:
        names: set[str] = set()
        for cmd in cmds or []:
            try:
                name = getattr(cmd, "command", None)
            except Exception:
                name = None
            if isinstance(name, str) and name.strip():
                names.add(name.strip().lower().lstrip("/"))
        return names

    public_names = _extract_menu_names(public_menu_commands)
    personal_names = _extract_menu_names(personal_menu_commands)
    menu_union = public_names | personal_names

    hidden = sorted(registered_set - menu_union) if menu_union else []
    menu_only = sorted(menu_union - registered_set) if menu_union else []

    lines: list[str] = []
    lines.append("ğŸ” <b>Debug Commands Report</b>")
    lines.append("")
    lines.append(f"ğŸ“Š <b>×¡×”\"×› ×¤×§×•×“×•×ª ×¨×©×•××•×ª ×‘×§×•×“:</b> {len(registered)}")
    lines.append("")
    lines.append("âœ… <b>All Registered Commands (runtime):</b>")
    all_text = "\n".join(f"/{c}" for c in registered) if registered else "(none)"
    lines.append(f"<pre>{html_escape(all_text)}</pre>")

    if public_menu_commands is not None or personal_menu_commands is not None:
        lines.append("")
        pub_text = "\n".join(f"/{c}" for c in sorted(public_names)) if public_names else "(none)"
        per_text = "\n".join(f"/{c}" for c in sorted(personal_names)) if personal_names else "(none)"
        lines.append(f"ğŸ“‹ <b>Menu Commands (Telegram):</b> ×¦×™×‘×•×¨×™×•×ª {len(public_names)} | ××™×©×™×•×ª {len(personal_names)}")
        lines.append("<b>×¦×™×‘×•×¨×™×•×ª:</b>")
        lines.append(f"<pre>{html_escape(pub_text)}</pre>")
        lines.append("<b>××™×©×™×•×ª:</b>")
        lines.append(f"<pre>{html_escape(per_text)}</pre>")

        if menu_union:
            lines.append("")
            lines.append(f"âš ï¸ <b>Hidden Commands (×‘×§×•×“ ××‘×œ ×œ× ×‘×ª×¤×¨×™×˜):</b> {len(hidden)}")
            hidden_text = "\n".join(f"/{c}" for c in hidden) if hidden else "(none)"
            lines.append(f"<pre>{html_escape(hidden_text)}</pre>")

            # ×©×™××•×©×™ ×œ×–×™×”×•×™ "×“×¨×™×¤×˜" â€“ ×¤×§×•×“×•×ª ×©× ×©××¨×• ×‘×ª×¤×¨×™×˜ ××‘×œ ×œ× ×§×™×™××•×ª ×‘×§×•×“ ×™×•×ª×¨
            lines.append(f"â„¹ï¸ <b>Menu-only (×‘×ª×¤×¨×™×˜ ××‘×œ ×œ× ×‘×§×•×“):</b> {len(menu_only)}")
            menu_only_text = "\n".join(f"/{c}" for c in menu_only) if menu_only else "(none)"
            lines.append(f"<pre>{html_escape(menu_only_text)}</pre>")

    return "\n".join(lines)


def _build_help_message(registered_commands: set[str], *, is_admin: bool = False) -> str:
    """Compose the help text for commands without dedicated buttons."""
    available_commands = {cmd.lower() for cmd in registered_commands if isinstance(cmd, str)}
    lines: list[str] = ["<b>ğŸ“š ×¢×–×¨×” â€“ ×¤×§×•×“×•×ª ×œ×œ× ×›×¤×ª×•×¨×™×</b>", ""]
    has_sections = False

    for section in HELP_SECTIONS:
        if bool(section.get("admin_only")) and not is_admin:
            continue
        section_lines: list[str] = []
        for entry in _resolve_section_entries(section):
            commands = [cmd for cmd in entry["commands"] if cmd in available_commands]
            if not commands:
                continue
            suffix = entry.get("suffix", "")
            cmd_text = " ".join(f"<code>/{cmd}</code>" for cmd in commands) + suffix
            if entry["description"]:
                section_lines.append(f"â€¢ {cmd_text} â€“ {entry['description']}")
            else:
                section_lines.append(f"â€¢ {cmd_text}")
        if section_lines:
            has_sections = True
            lines.append(section["title"])
            lines.extend(section_lines)
            lines.append("")

    # ×”×¡×¨×ª ×¡×¢×™×£ "×¤×§×•×“×•×ª × ×•×¡×¤×•×ª" ×œ×¤×™ ×”×“×¨×™×©×” â€“ ××¦×™×’×™× ×¨×§ ××ª ×”×§×˜×’×•×¨×™×•×ª ×”××•×’×“×¨×•×ª
    if not has_sections:
        return STATIC_HELP_MESSAGE

    while lines and not lines[-1].strip():
        lines.pop()

    lines.append("")
    lines.append(SUPPORT_FOOTER)

    return "\n".join(lines)


class CodeKeeperBot:
    """
    ×”××—×œ×§×” ×”×¨××©×™×ª ×©×œ Code Keeper Bot.
    
    ××—×œ×§×” ×–×• ×× ×”×œ×ª ××ª ×›×œ ×”×¤×•× ×§×¦×™×•× ×œ×™×•×ª ×©×œ ×”×‘×•×˜, ×›×•×œ×œ:
    - ×”×’×“×¨×ª handlers ×œ×¤×§×•×“×•×ª ×•××¡×¨×™×
    - × ×™×”×•×œ ×©×™×—×•×ª ××•×¨×›×‘×•×ª
    - ××™× ×˜×’×¨×¦×™×•×ª ×¢× ×©×™×¨×•×ª×™× ×—×™×¦×•× ×™×™×
    - × ×™×”×•×œ ××¡×“ × ×ª×•× ×™×
    
    Attributes:
        application: ××•×‘×™×™×§×˜ Application ×©×œ python-telegram-bot
        github_handler: ×× ×”×œ ××™× ×˜×’×¨×¦×™×™×ª GitHub
        backup_handler: ×× ×”×œ ××¢×¨×›×ª ×”×’×™×‘×•×™×™×
    """
    
    def __init__(self):
        def _env_float(name: str, default: float) -> float:
            try:
                v = os.getenv(name)
                if v is None:
                    return float(default)
                v = str(v).strip()
                if not v:
                    return float(default)
                return float(v)
            except Exception:
                return float(default)

        def _env_int(name: str, default: int) -> int:
            try:
                v = os.getenv(name)
                if v is None:
                    return int(default)
                v = str(v).strip()
                if not v:
                    return int(default)
                return int(float(v))
            except Exception:
                return int(default)

        def _apply_ptb_timeouts(builder: Any) -> Any:
            """
            Best-effort apply network timeouts to python-telegram-bot builder.

            ×× ×—× ×• ×œ× ×× ×™×—×™× API ×§×©×™×— (×›×™ PTB ×”×©×ª× ×” ×‘×™×Ÿ ×’×¨×¡××•×ª), ×•×œ×›×Ÿ ××¤×¢×™×œ×™× ×¨×§
            ×× ×”×©×™×˜×” ×§×™×™××ª. ×›×š ×œ× × ×©×‘×•×¨ ×˜×¡×˜×™×/×¡×‘×™×‘×•×ª ××™× ×™××œ×™×•×ª.
            """
            # Defaults tuned to reduce getUpdates "409 Conflict" caused by network jitter:
            # - long polling timeout (server-side) is configured in run_polling (see main()).
            connect_timeout = _env_float("TELEGRAM_CONNECT_TIMEOUT_SECS", 10.0)
            pool_timeout = _env_float("TELEGRAM_POOL_TIMEOUT_SECS", 10.0)
            read_timeout = _env_float("TELEGRAM_READ_TIMEOUT_SECS", 30.0)
            write_timeout = _env_float("TELEGRAM_WRITE_TIMEOUT_SECS", 30.0)

            for method_name, value in (
                ("connect_timeout", connect_timeout),
                ("pool_timeout", pool_timeout),
                ("read_timeout", read_timeout),
                ("write_timeout", write_timeout),
            ):
                try:
                    m = getattr(builder, method_name, None)
                    if callable(m):
                        m(value)
                except Exception:
                    # Fail-open: do not block bot startup because of builder API mismatch
                    pass
            return builder

        # ×™×¦×™×¨×ª ×ª×™×§×™×™×” ×–×× ×™×ª ×¢× ×”×¨×©××•×ª ×›×ª×™×‘×”
        DATA_DIR = "/tmp"
        if not os.path.exists(DATA_DIR):
            os.makedirs(DATA_DIR, exist_ok=True)
            
        # ×™×¦×™×¨×ª persistence ×œ×©××™×¨×ª × ×ª×•× ×™× ×‘×™×Ÿ ×”×¤×¢×œ×•×ª
        persistence = PicklePersistence(filepath=f"{DATA_DIR}/bot_data.pickle")
        
        # ×‘××¦×‘ ×‘×“×™×§×•×ª/CI, ×—×œ×§ ××ª×œ×•×™×•×ª ×”×˜×œ×’×¨× (Updater ×¤× ×™××™) ×¢×œ×•×œ×•×ª ×œ×”×™×›×©×œ.
        # × ×©×ª××© ×‘×‘× ××™ ×”×¨×’×™×œ, ×•×× × ×›×©×œ â€“ × ×‘× ×” Application ××™× ×™××œ×™ ×¢× ×˜×•×§×Ÿ ×“××”.
        try:
            _builder = (
                Application.builder()
                .token(config.BOT_TOKEN)
                .defaults(Defaults(parse_mode=ParseMode.HTML))
                .persistence(persistence)
                .post_init(setup_bot_data)
            )
            _builder = _apply_ptb_timeouts(_builder)
            self.application = _builder.build()
        except Exception:
            dummy_token = os.getenv("DUMMY_BOT_TOKEN", "dummy_token")
            # × ×¡×” ×œ×‘× ×•×ª ×œ×œ× persistence/post_init ×›×“×™ ×œ×¢×§×•×£ Updater ×¤× ×™××™
            try:
                _builder = (
                    Application.builder()
                    .token(dummy_token)
                    .defaults(Defaults(parse_mode=ParseMode.HTML))
                )
                _builder = _apply_ptb_timeouts(_builder)
                self.application = _builder.build()
            except Exception:
                # ×‘× ××™ ×™×“× ×™ ××™× ×™××œ×™: ××•×‘×™×™×§×˜ ×¢× ×”×××©×§×™× ×”×“×¨×•×©×™× ×œ×˜×¡×˜×™×/×¡×‘×™×‘×•×ª ×—×¡×¨×•×ª
                class _MiniApp:
                    def __init__(self):
                        self.handlers = []
                        self.bot_data = {}
                        self._error_handlers = []
                        class _JobQ:
                            def run_once(self, *a, **k):
                                return None
                        self.job_queue = _JobQ()
                    def add_handler(self, *a, **k):
                        # ×©××™×¨×” ×‘××‘× ×” ×™×¦×™×‘ ×œ×˜×¡×˜×™×: (args_tuple, kwargs_dict)
                        # args_tuple ××•×‘×˜×— ×‘××•×¨×š â‰¥ 2 ×›×š ×©-index [1] ×œ× ×™×§×¨×•×¡.
                        handler_obj = None
                        if len(a) >= 1:
                            handler_obj = a[0]
                        else:
                            # ×§×œ×˜ ××œ×˜×¨× ×˜×™×‘×™ × ×“×™×¨: handler ×‘×§×•×•××¨×’×¡
                            handler_obj = k.get('handler') or k.get('callback')
                        # group ×™×›×•×œ ×œ×”×’×™×¢ ×›××¨×’×•×× ×˜ ×©× ×™ ××• ×‘×§×•×•××¨×’×¡
                        group_val = a[1] if len(a) >= 2 else k.get('group')
                        # ×‘× ×” args ×‘××•×¨×š 2 ×œ×¤×—×•×ª â€“ ××©×›×¤×œ ××ª ×”-handler ×›×“×™ ×œ×¡×¤×§ args[1]
                        norm_args = (handler_obj, handler_obj)
                        norm_kwargs = dict(k)
                        if 'group' not in norm_kwargs:
                            norm_kwargs['group'] = group_val
                        self.handlers.append((norm_args, norm_kwargs))
                    def remove_handler(self, *a, **k):
                        # ×”×¡×¨×” ×©×§×˜×” â€“ ×©××•×¨ ×¢×œ API, ×œ× ×”×›×¨×—×™ ×œ×˜×¡×˜×™×
                        return None
                    def add_error_handler(self, *a, **k):
                        self._error_handlers.append((a, k))
                    async def run_polling(self, *a, **k):
                        # Fallback ×©×§×˜: ××™×Ÿ polling ×××™×ª×™; ×××¤×©×¨ start ×œ×œ× ×§×¨×™×¡×”
                        return None
                self.application = _MiniApp()
        # ××©×ª× ×™ ×¢×–×¨ ×¢×‘×•×¨ ×©×¢×¨ ×ª×—×–×•×§×” (TTL ×™×•×¤×¢×œ ×‘×¡×•×£ setup_handlers)
        self._maintenance_gate_pending = False
        self._maintenance_warmup_secs = None
        self._maintenance_clear_handlers_cb = None

        # ×”×ª×§× ×ª ××ª×× ×§×•×¨×œ×¦×™×” ×œ×¤× ×™ ×¨×™×©×•× ×©××¨ ×”-handlers
        try:
            self._install_correlation_layer()
        except Exception:
            pass
        try:
            self._install_tracing_layer()
        except Exception:
            pass

        # ×™×¦×™×¨×ª ×•×”×–×¨×§×ª Activity Reporter ×‘×–××Ÿ ×¨×™×¦×” (××•× ×¢ ×—×™×‘×•×¨×™× ××¨×•×‘×™× ×‘×–××Ÿ import)
        try:
            mongodb_uri = (
                os.getenv('REPORTER_MONGODB_URL')
                or os.getenv('REPORTER_MONGODB_URI')
                or getattr(config, 'MONGODB_URL', None)
            )
            service_id = os.getenv('REPORTER_SERVICE_ID', getattr(config, 'BOT_LABEL', 'CodeBot'))
            # ×ª××™×›×” ×‘× ×˜×¨×•×œ ×“×™×•×•×— ×¤×¢×™×œ×•×ª ×“×¨×š ENV
            disable_reporter = bool(int((os.getenv('DISABLE_ACTIVITY_REPORTER', '0') or '0').strip() or 0))
            if disable_reporter:
                class _NoopReporter:
                    def report_activity(self, user_id):
                        return None
                created_reporter = _NoopReporter()
            else:
                # ×™×™×‘×•× ×‘×–××Ÿ ×¨×™×¦×” ×‘×œ×‘×“ ×›×“×™ ×œ×× ×•×¢ ×™×¦×™×¨×ª ×œ×§×•×— Mongo ×‘×–××Ÿ import ×‘××•×“×•×œ×™× ××—×¨×™×
                try:
                    from activity_reporter import create_reporter  # noqa: WPS433 (runtime import by design)
                except Exception:
                    # ×× ×”××•×“×•×œ ×œ× ×–××™×Ÿ/× ×›×©×œ â€” ×¢×‘×•×¨ ×œ-noop
                    class _NoopReporter:
                        def report_activity(self, user_id):
                            return None
                    created_reporter = _NoopReporter()
                else:
                    # ×™×¦×™×¨×” ×‘×˜×•×—×”: SimpleActivityReporter ××˜×¤×œ ×‘×—×•×¡×¨ pymongo ×‘×¡×‘×™×‘×”
                    created_reporter = create_reporter(
                        mongodb_uri=mongodb_uri,
                        service_id=service_id,
                        service_name="CodeBot",
                    )
            # ×¢×“×›×•×Ÿ ×’×œ×•×‘×œ×™ ×‘××•×“×•×œ ×–×”
            global reporter
            reporter = created_reporter
            # ×”×–×¨×§×” ×œ××•×“×•×œ×™× ×©×ª×œ×•×™×™× ×‘-report_activity
            try:
                set_bh_activity_reporter(created_reporter)
            except Exception:
                pass
            try:
                set_ch_activity_reporter(created_reporter)
            except Exception:
                pass
            try:
                from refactor_handlers import set_activity_reporter as set_rh_activity_reporter
                set_rh_activity_reporter(created_reporter)
            except Exception:
                pass
        except Exception:
            # ×‘×¡×‘×™×‘×•×ª CI/×˜×¡×˜×™×, ××œ × ×›×©×™×œ ××ª ×”×‘× ×™×™×”
            reporter = None

        self.document_handler = DocumentHandler(
            notify_admins=notify_admins,
            get_reporter=lambda: reporter,
            log_user_activity=log_user_activity,
            encodings_to_try=lambda: ENCODINGS_TO_TRY,
            emit_event=emit_event,
            errors_total=errors_total,
        )

        self.setup_handlers()
        self._activate_maintenance_warmup_if_pending()
        self.advanced_handlers = AdvancedBotHandlers(self.application)
        # ×¨×™×©×•× ×§×˜×’×•×¨×™×™×ª "â­ ××•×¢×“×¤×™×" ×œ×ª×¤×¨×™×˜ "ğŸ“š ×”×§×‘×¦×™×"
        try:
            from conversation_handlers import setup_favorites_category_handlers as _setup_fav
            _setup_fav(self.application)
        except Exception:
            pass
        # Rate limiter instance (×œ××—×¨ ×‘× ×™×™×ª ×”××¤×œ×™×§×¦×™×”)
        try:
            self._rate_limiter = RateLimiter(max_per_minute=int(getattr(config, 'RATE_LIMIT_PER_MINUTE', 30) or 30))
            # ×”×’×“×¨×ª ×“×’×œ shadow ×›×‘×¨×™×¨×ª ××—×“×œ (×’× ×× ××™×Ÿ ××’×‘×™×œ ××ª×§×“×)
            self._shadow_mode = bool(getattr(config, 'RATE_LIMIT_SHADOW_MODE', False))
            # ××ª×—×•×œ ××©×ª× ×™× ×›×“×™ ×œ×× ×•×¢ AttributeError downstream
            self._advanced_limiter = None
            self._limits_storage = None
            self._per_user_global = None

            if _LIMITS_AVAILABLE:
                try:
                    redis_url = getattr(config, 'REDIS_URL', None) or os.getenv('REDIS_URL')
                    storage = None
                    use_memory_fallback = False

                    if redis_url:
                        # ×•×“× ×—×™×‘×•×¨ ××”×™×¨ ×œ-Redis; ×× × ×›×©×œ, × ×©×ª××© ×‘-MemoryStorage ×›×“×™ ×œ×× ×•×¢ TIMEOUT ×‘×˜×¡×˜×™×
                        connect_timeout = getattr(config, 'REDIS_CONNECT_TIMEOUT', None)
                        try:
                            connect_timeout = float(connect_timeout) if connect_timeout is not None else 0.25
                        except Exception:
                            connect_timeout = 0.25
                        connect_timeout = max(0.05, connect_timeout)

                        if _redis_socket_available(str(redis_url), timeout=connect_timeout):
                            try:
                                storage = RedisStorage(str(redis_url))
                            except Exception:
                                storage = None
                                use_memory_fallback = True
                        else:
                            use_memory_fallback = True

                        if use_memory_fallback and storage is None:
                            try:
                                logger.warning(
                                    "Redis advanced limiter ×œ× × ×’×™×© â€“ ××¢×‘×¨ ×œ-MemoryStorage",
                                    extra={"redis_url": str(redis_url)},
                                )
                            except Exception:
                                pass

                    if storage is None and redis_url and use_memory_fallback and MemoryStorage is not None:
                        try:
                            storage = MemoryStorage()
                        except Exception:
                            storage = None

                    if storage is not None:
                        self._limits_storage = storage
                        self._advanced_limiter = MovingWindowRateLimiter(storage)
                        self._per_user_global = RateLimitItemPerMinute(50)
                except Exception:
                    self._advanced_limiter = None
        except Exception:
            self._rate_limiter = RateLimiter(max_per_minute=30)
            self._shadow_mode = False

        # ×—×©×™×¤×” ×’×œ×•×‘×œ×™×ª ×©×œ ×”××•×‘×™×™×§×˜ ×”× ×•×›×—×™ ×¢×‘×•×¨ main()/×˜×¡×˜×™×
        try:
            global CURRENT_BOT
            CURRENT_BOT = self
        except Exception:
            pass

    def _install_correlation_layer(self) -> None:
        """×¨×™×©×•× Handler ××•×§×“× ×©××™×™×¦×¨ ×•××§×©×¨ request_id ×•××•×“×“ ××˜×¨×™×§×•×ª ×‘×¡×™×¡×™×•×ª."""
        async def _pre_update(update: Update, context: ContextTypes.DEFAULT_TYPE):
            # request_id ×§×¦×¨ ×•× ×•×—
            try:
                req_id = context.user_data.get("request_id") if hasattr(context, "user_data") else None
            except Exception:
                req_id = None
            if not req_id:
                req_id = generate_request_id()
                try:
                    if hasattr(context, "user_data"):
                        context.user_data["request_id"] = req_id
                except Exception:
                    pass
            # ×›×¨×•×š ×œ-contextvars ×›×š ×©×™×•×¤×™×¢ ×‘×›×œ ×¨×©×•××ª ×œ×•×’ ×‘×”××©×š ×”×©×¨×©×•×¨
            try:
                bind_request_id(req_id)
            except Exception:
                pass
            try:
                user = getattr(update, "effective_user", None)
                chat = getattr(update, "effective_chat", None)
                uid = getattr(user, "id", None)
                cid = getattr(chat, "id", None)
                bind_user_context(user_id=uid, chat_id=cid)
            except Exception:
                pass
            try:
                command_name = ""
                message = getattr(update, "effective_message", None)
                if message is not None:
                    text = getattr(message, "text", None)
                    if isinstance(text, str):
                        parts = text.split()
                        if parts and parts[0].startswith("/"):
                            command_name = parts[0]
                if not command_name:
                    callback = getattr(update, "callback_query", None)
                    if callback is not None:
                        data = getattr(callback, "data", None)
                        if isinstance(data, str):
                            parts = data.split()
                            if parts:
                                command_name = parts[0]
                if not command_name and getattr(update, "inline_query", None):
                    command_name = "inline_query"
                if command_name:
                    cleaned = command_name.strip()
                    if cleaned.startswith("/"):
                        cleaned = cleaned[1:]
                    if "@" in cleaned:
                        cleaned = cleaned.split("@", 1)[0]
                    cleaned = cleaned.lower()
                    if cleaned:
                        bind_command(f"bot:{cleaned}")
                        try:
                            if hasattr(context, "user_data"):
                                context.user_data["command"] = cleaned
                                # ×‘×™×˜×•×œ ××¦×‘ ×—×™×¤×•×© ×¢×œ ×›×œ ×¤×§×•×“×”
                                context.user_data.pop('awaiting_search_text', None)
                                context.user_data.pop('search_ctx', None)
                        except Exception:
                            pass
            except Exception:
                pass
            # ×¢×“×›×•×Ÿ ××˜×¨×™×§×” ×›×œ×œ×™×ª ×¢×œ ×¡×•×’ ×”-update
            try:
                upd_type = (
                    "callback_query" if getattr(update, "callback_query", None) else
                    "inline_query" if getattr(update, "inline_query", None) else
                    "message" if getattr(update, "message", None) else
                    "other"
                )
                if telegram_updates_total is not None:
                    telegram_updates_total.labels(type=upd_type, status="received").inc()
            except Exception:
                pass

        handler = TypeHandler(Update, _pre_update)  # ×›×œ ×”-Updates
        try:
            self.application.add_handler(handler, group=-100)
        except TypeError:
            self.application.add_handler(handler)
        except Exception:
            # ××œ ×ª×›×©×™×œ ××ª ×”××¤×œ×™×§×¦×™×” ×‘××§×¨×” ×©×œ ×›×©×œ
            pass

    def _install_tracing_layer(self) -> None:
        """Wrap process_update with OTEL span for end-to-end tracing."""
        app = getattr(self, "application", None)
        if app is None:
            return
        original = getattr(app, "process_update", None)
        if not callable(original):
            return
        if getattr(app, "_codebot_tracing_installed", False):
            return
        try:
            from observability_instrumentation import start_span, set_current_span_attributes  # type: ignore
        except Exception:
            return
        if not callable(start_span):  # type: ignore[call-arg]
            return

        setattr(app, "_codebot_tracing_installed", True)

        def _normalize_command(value: str | None) -> str:
            try:
                if not value:
                    return ""
                cleaned = str(value).strip().lower()
                if cleaned.startswith("/"):
                    cleaned = cleaned[1:]
                if "@" in cleaned:
                    cleaned = cleaned.split("@", 1)[0]
                return cleaned[:80]
            except Exception:
                return ""

        def _derive_command(update: Update) -> str:
            try:
                message = getattr(update, "effective_message", None)
                if message is not None:
                    text = getattr(message, "text", None)
                    if isinstance(text, str):
                        parts = text.split()
                        if parts and parts[0].startswith("/"):
                            return _normalize_command(parts[0])
                callback = getattr(update, "callback_query", None)
                if callback is not None:
                    data = getattr(callback, "data", None)
                    if isinstance(data, str) and data:
                        return _normalize_command(data.split()[0])
                inline = getattr(update, "inline_query", None)
                if inline is not None:
                    query = getattr(inline, "query", None)
                    if isinstance(query, str) and query:
                        return _normalize_command(query.split()[0])
            except Exception:
                return ""
            return ""

        def _collect_attrs(update: Update | None) -> dict[str, str]:
            attrs: dict[str, str] = {"component": "telegram.bot"}
            try:
                ctx = get_observability_context() or {}
            except Exception:
                ctx = {}
            if isinstance(ctx, dict):
                cmd_ctx = _normalize_command(ctx.get("command")) if ctx.get("command") else ""
                if cmd_ctx:
                    attrs["command"] = cmd_ctx
                req_id = str(ctx.get("request_id", "")).strip()
                if req_id:
                    attrs["request_id"] = req_id
                user_hash = str(ctx.get("user_id", "")).strip()
                if user_hash:
                    attrs["user_id_hash"] = user_hash
                chat_hash = str(ctx.get("chat_id", "")).strip()
                if chat_hash:
                    attrs["chat_id_hash"] = chat_hash
            if update is not None:
                try:
                    upd_id = getattr(update, "update_id", None)
                    if upd_id is not None:
                        attrs["update.id"] = str(int(upd_id))
                except Exception:
                    pass
                try:
                    if getattr(update, "callback_query", None):
                        attrs["update.type"] = "callback_query"
                    elif getattr(update, "inline_query", None):
                        attrs["update.type"] = "inline_query"
                    elif getattr(update, "message", None):
                        attrs["update.type"] = "message"
                    else:
                        attrs.setdefault("update.type", "other")
                except Exception:
                    pass
                try:
                    if "command" not in attrs:
                        derived = _derive_command(update)
                        if derived:
                            attrs["command"] = derived
                except Exception:
                    pass
            return attrs

        @functools.wraps(original)
        async def _process_update_with_span(update: Update, *args, **kwargs):
            span_attrs = _collect_attrs(update)
            span_cm = start_span("bot.update", span_attrs)
            span = span_cm.__enter__()
            if span is not None:
                try:
                    set_current_span_attributes({"component": "telegram.bot"})
                except Exception:
                    pass
            error: Exception | None = None
            try:
                result = await original(update, *args, **kwargs)
                if span is not None:
                    try:
                        span.set_attribute("status", "ok")  # type: ignore[attr-defined]
                    except Exception:
                        pass
                return result
            except Exception as exc:
                error = exc
                if span is not None:
                    try:
                        span.set_attribute("status", "error")  # type: ignore[attr-defined]
                        span.set_attribute("error_signature", type(exc).__name__)  # type: ignore[attr-defined]
                    except Exception:
                        pass
                raise
            finally:
                if error is None:
                    span_cm.__exit__(None, None, None)
                else:
                    span_cm.__exit__(type(error), error, getattr(error, "__traceback__", None))

        setattr(app, "process_update", _process_update_with_span)
    
    def _activate_maintenance_warmup_if_pending(self) -> None:
        """××ª×–××Ÿ ××ª ×—×œ×•×Ÿ ×”-warmup ×¨×§ ××—×¨×™ ×©×›×œ ×”-handlers ×”×•×’×“×¨×•."""
        if not getattr(self, "_maintenance_gate_pending", False):
            return

        try:
            warmup_secs = int(
                self._maintenance_warmup_secs
                if self._maintenance_warmup_secs is not None
                else getattr(config, "MAINTENANCE_AUTO_WARMUP_SECS", 30)
            )
        except Exception:
            warmup_secs = 30
        warmup_secs = max(1, warmup_secs)

        try:
            self._maintenance_active_until_ts = time.time() + warmup_secs
        except Exception:
            self._maintenance_active_until_ts = time.time() + 30

        cb = getattr(self, "_maintenance_clear_handlers_cb", None)
        if cb is not None:
            try:
                self.application.job_queue.run_once(cb, when=warmup_secs, name="maintenance_clear_handlers")
            except Exception:
                pass

        self._maintenance_gate_pending = False
    
    def setup_handlers(self):
        """×”×’×“×¨×ª ×›×œ ×”-handlers ×©×œ ×”×‘×•×˜ ×‘×¡×“×¨ ×”× ×›×•×Ÿ"""

        # Maintenance gate: if enabled, short-circuit most interactions
        # ×©×™××•×© ×‘-getattr ×¢×‘×•×¨ ×ª××™××•×ª ×œ×˜×¡×˜×™× ×©××—×œ×™×¤×™× ××ª config ×‘××•×‘×™×™×§×˜ ××™× ×™××œ×™
        maintenance_flag_raw = getattr(config, "MAINTENANCE_MODE", False)

        def _coerce_flag(value):
            try:
                if value is None:
                    return None
                if isinstance(value, str):
                    normalized = value.strip().lower()
                    if not normalized:
                        return None
                    if normalized in {"1", "true", "yes", "on"}:
                        return True
                    if normalized in {"0", "false", "no", "off"}:
                        return False
                    return None
                if isinstance(value, (bool, int)):
                    return bool(value)
            except Exception:
                return None
            return None

        maintenance_flag = _coerce_flag(maintenance_flag_raw)

        env_override = _coerce_flag(os.getenv("MAINTENANCE_MODE"))
        if env_override is not None:
            maintenance_flag = env_override

        if maintenance_flag is None:
            maintenance_flag = False

        DEFAULT_MAINTENANCE_WARMUP_GRACE_SECS = 0.75

        if maintenance_flag:
            # ×”×’×“×¨×ª ×—×œ×•×Ÿ ×–××Ÿ ×¤× ×™××™ ×©×‘×• ×”×•×“×¢×ª ×ª×—×–×•×§×” ×¤×¢×™×œ×”, ×›×š ×©×’× ×× ××—×™×§×ª ×”-handlers ×œ× ×ª×ª×‘×¦×¢
            # ×”×”×•×“×¢×” ×ª×™×›×‘×” ××•×˜×•××˜×™×ª ×œ××—×¨ ×”-warmup. ×”×—×™×©×•×‘ ×‘×¤×•×¢×œ × ×“×—×” ×œ×¡×•×£ setup_handlers ×›×“×™
            # ×œ×× ×•×¢ ×§×™×¦×•×¨ ××œ××›×•×ª×™ ×©×œ ×”×—×œ×•×Ÿ ×‘×–××Ÿ ×¨×™×©×•× ×”-handlers.
            try:
                warmup_secs = max(1, int(getattr(config, 'MAINTENANCE_AUTO_WARMUP_SECS', 30)))
            except Exception:
                warmup_secs = 30
            self._maintenance_warmup_secs = warmup_secs
            self._maintenance_active_until_ts = None
            self._maintenance_gate_pending = True

            async def maintenance_reply(update: Update, context: ContextTypes.DEFAULT_TYPE):
                # ×× ×—×œ×•×Ÿ ×”-warmup ×”×¡×ª×™×™×, ××œ ×ª×©×œ×— ×”×•×“×¢×ª ×ª×—×–×•×§×”
                try:
                    raw_active_until = getattr(self, "_maintenance_active_until_ts", None)
                except Exception:
                    raw_active_until = None
                # ×¤×¨×©× ×•×ª:
                # None => ×ª×—×–×•×§×” ×¤×¢×™×œ×” (××™×Ÿ TTL)
                # 0 ××• ×¢×¨×š ×©×œ×™×œ×™ => ×ª×—×–×•×§×” ×× ×•×˜×¨×œ×ª
                # > 0 => ×ª×—×–×•×§×” ×¤×¢×™×œ×” ×¢×“ timestamp ×–×”
                try:
                    active_until = float(raw_active_until) if raw_active_until is not None else None
                except Exception:
                    active_until = None
                try:
                    grace_value = getattr(
                        config, "MAINTENANCE_WARMUP_GRACE_SECS", DEFAULT_MAINTENANCE_WARMUP_GRACE_SECS
                    )
                    grace_secs = max(0.0, float(grace_value))
                except Exception:
                    grace_secs = DEFAULT_MAINTENANCE_WARMUP_GRACE_SECS
                now = time.time()
                is_active = True if active_until is None else (active_until > 0 and now < (active_until + grace_secs))
                if not is_active:
                    return ConversationHandler.END

                maintenance_text = getattr(config, "MAINTENANCE_MESSAGE", "") or ""
                sent = False

                callback_query = getattr(update, "callback_query", None)
                if callback_query is not None:
                    try:
                        try:
                            await callback_query.answer(cache_time=1, show_alert=False)
                        except Exception:
                            pass
                        await callback_query.edit_message_text(maintenance_text)
                        sent = True
                    except Exception:
                        sent = False

                if not sent:
                    message = getattr(update, "message", None)
                    if message is None:
                        message = getattr(update, "effective_message", None)
                    if message is None and callback_query is not None:
                        message = getattr(callback_query, "message", None)
                    if message is not None and hasattr(message, "reply_text"):
                        try:
                            await message.reply_text(maintenance_text)
                            sent = True
                        except Exception:
                            sent = False

                if not sent:
                    try:
                        bot = getattr(context, "bot", None)
                        if bot is None:
                            # fallback ×œ-bot ×“×¨×š application (×‘××§×¨×™× ×©×‘×”× context.bot ×œ× ×§×™×™×)
                            bot = getattr(getattr(context, "application", None), "bot", None)
                        if bot is None:
                            bot = getattr(getattr(context, "app", None), "bot", None)

                        chat = getattr(update, "effective_chat", None)
                        chat_id = getattr(chat, "id", None)
                        if chat_id is None:
                            # × ×¡×” ×œ×”×¤×™×§ chat_id ×××©×ª××© ××• ××”×•×“×¢×” ×× ×§×™×™×
                            message = getattr(update, "message", None) or getattr(update, "effective_message", None)
                            chat_id = getattr(getattr(message, "chat", None), "id", None) or getattr(message, "chat_id", None)
                        if chat_id is None:
                            user = getattr(update, "effective_user", None)
                            chat_id = getattr(user, "id", None)

                        if bot is not None and chat_id is not None:
                            await bot.send_message(chat_id=chat_id, text=maintenance_text)
                            sent = True
                    except Exception:
                        pass

                return ConversationHandler.END
            # Catch-all high-priority handlers during maintenance (keep references for clean removal)
            self._maintenance_message_handler = MessageHandler(filters.ALL, maintenance_reply)
            self._maintenance_callback_handler = CallbackQueryHandler(maintenance_reply)
            self.application.add_handler(self._maintenance_message_handler, group=-100)
            self.application.add_handler(self._maintenance_callback_handler, group=-100)
            logger.warning("MAINTENANCE_MODE is ON â€” all updates will receive maintenance message")
            # ××œ ×ª×—×¡×•× ×œ×’××¨×™: ×œ××—×¨ warmup ××•×˜×•××˜×™, ×”×¡×¨ ×ª×—×–×•×§×” (×œ×œ× Redeploy)
            # Schedule removing maintenance handlers via JobQueue instead of create_task
            async def _clear_handlers_cb(context: ContextTypes.DEFAULT_TYPE):
                try:
                    app = self.application
                    if getattr(self, "_maintenance_message_handler", None) is not None:
                        app.remove_handler(self._maintenance_message_handler, group=-100)
                    if getattr(self, "_maintenance_callback_handler", None) is not None:
                        app.remove_handler(self._maintenance_callback_handler, group=-100)
                    # × ×˜×¨×œ ××™×™×“×™×ª ××ª ×”×—×œ×•×Ÿ ×”×¤×¢×™×œ ×›×“×™ ×œ×× ×•×¢ ×©×œ×™×—×ª ×”×•×“×¢×•×ª ×ª×—×–×•×§×” ××™×•×ª×¨×•×ª
                    try:
                        self._maintenance_active_until_ts = 0
                    except Exception:
                        pass
                    logger.warning("MAINTENANCE_MODE auto-warmup window elapsed; resuming normal operation")
                except Exception:
                    pass
            self._maintenance_clear_handlers_cb = _clear_handlers_cb
            # ×××©×™×›×™× ×œ×¨×©×•× ××ª ×©××¨ ×”-handlers ×›×“×™ ×©×™×§×œ×˜×• ××•×˜×•××˜×™×ª ××—×¨×™ ×”-warmup

        # ×¡×¤×•×¨ ××ª ×”-handlers
        handler_count = len(self.application.handlers)
        logger.info(f"ğŸ” ×›××•×ª handlers ×œ×¤× ×™: {handler_count}")
        try:
            emit_event("handlers_count_before", severity="info", count=handler_count)
        except Exception:
            pass

        # --- Rate limiting gate (×’×‘×•×” ×¢×“×™×¤×•×ª, ×œ×¤× ×™ ×©××¨ ×”-handlers) ---
        async def _rate_limit_gate(update: Update, context: ContextTypes.DEFAULT_TYPE):
            try:
                user = (
                    getattr(update, 'effective_user', None)
                    or getattr(getattr(update, 'callback_query', None), 'from_user', None)
                )
                user_id = int(getattr(user, 'id', 0) or 0)
            except Exception:
                user_id = 0
            if user_id:
                # ×¢×§×™×¤×ª ××“××™×Ÿ â€“ ××“××™× ×™× ×œ× ××•×’×‘×œ×™× ×¢"×™ ×”×©×¢×¨ ×”×’×œ×•×‘×œ×™
                try:
                    admins = get_admin_ids()
                except Exception:
                    admins = []
                if admins and user_id in admins:
                    return  # ××¢×‘×¨ ×—×•×¤×©×™ ×œ××“××™×Ÿ

                # Fallback-counter ×¤×©×•×˜ ×¤×¨-××©×ª××© ×‘×—×œ×•×Ÿ ×©×œ 60×©×³ ×›×“×™ ×œ×›×¡×•×ª ×ª×§×œ×•×ª × ×“×™×¨×•×ª
                # ×‘××™××•×© ×”×¨××©×™ ×©×œ ×”××’×‘×™×œ. ×œ× ××—×œ×™×£ ××ª ×”××’×‘×™×œ, ×¨×§ ××—××™×¨ ×× ×¦×¨×™×š.
                blocked_by_local = False
                try:
                    udata = getattr(context, 'user_data', None)
                    if isinstance(udata, dict):
                        now_ts = time.time()
                        local = udata.get('_rl_local')
                        limit_val = int(getattr(getattr(self, '_rate_limiter', object()), 'max_per_minute', 30) or 30)
                        if not isinstance(local, dict) or (now_ts - float(local.get('start_ts', 0.0) or 0.0)) >= 60.0:
                            local = {'start_ts': now_ts, 'count': 0}
                            # ×©××•×¨ ××™×™×“×™×ª ××ª ×ª×—×™×œ×ª ×”×—×œ×•×Ÿ ×”×—×“×© ×›×“×™ ×œ× ×œ××‘×“ state ×’× ×× ×ª×ª×¨×—×© ×—×¡×™××” ×‘×‘×§×©×” ×”× ×•×›×—×™×ª
                            udata['_rl_local'] = local
                        # ×¡×¤×¨ ××ª ×”×§×¨×™××” ×”× ×•×›×—×™×ª ×‘×—×œ×•×Ÿ ×”× ×•×›×—×™
                        next_count = int(local.get('count', 0)) + 1
                        if next_count > limit_val:
                            blocked_by_local = True
                            # ××œ ×ª×¢×“×›×Ÿ ××ª ×”××•× ×” ×›××©×¨ ×—×•×¡××™× â€“ × ×©××•×¨ ×¢×œ ×¢×§×‘×™×•×ª ××™× ×™××œ×™×ª
                        else:
                            local['count'] = next_count
                            udata['_rl_local'] = local
                except Exception:
                    # ×× ×™×© ×©×’×™××”, ××œ ×ª×—×¡×•× â€“ × ×©×¢×Ÿ ×¢×œ ×”××’×‘×™×œ ×”×¨××©×™
                    blocked_by_local = False

                # ×‘×“×™×§×” ×‘××’×‘×™×œ ×”×¨××©×™
                try:
                    allowed = await self._rate_limiter.check_rate_limit(user_id)
                except Exception:
                    allowed = True

                # Optional: advanced per-user global limit in shadow mode (logging only)
                try:
                    adv = getattr(self, '_advanced_limiter', None)
                    if adv is not None and hasattr(self, '_per_user_global'):
                        key = f"tg:global:{user_id}"
                        ok = adv.hit(self._per_user_global, key)
                        if not ok and getattr(self, '_shadow_mode', False):
                            logger.info(
                                "Rate limit would block (shadow mode)",
                                extra={"user_id": user_id, "scope": "global", "limit": "global_user"},
                            )
                        # ×‘××¦×‘ shadow ××™×Ÿ ×—×¡×™××” ×¢×œ ×‘×¡×™×¡ advanced; × ×©×¢× ×™× ×¢×œ in-memory gate
                except Exception:
                    pass

                should_block = (not allowed) or blocked_by_local
                if should_block:
                    # ×—×¡×™××” ×©×§×˜×” + ×”×•×“×¢×” ×§×¦×¨×”
                    try:
                        cq = getattr(update, 'callback_query', None)
                        if cq is not None:
                            await cq.answer("×™×•×ª×¨ ××“×™ ×‘×§×©×•×ª, × ×¡×” ×©×•×‘ ×¢×•×“ ×¨×’×¢", show_alert=False, cache_time=1)
                        else:
                            msg = getattr(update, 'message', None)
                            if msg is not None:
                                await msg.reply_text("âš ï¸ ×™×•×ª×¨ ××“×™ ×‘×§×©×•×ª, × ×¡×” ×©×•×‘ ×‘×¢×•×“ ××¡×¤×¨ ×©× ×™×•×ª")
                    except Exception:
                        pass
                    raise ApplicationHandlerStop
                else:
                    # Soft-warning ×‘-80% ××”×¡×£ â€“ ×”×•×“×¢×” ××“×™×‘×” ×œ×œ× ×—×¡×™××”
                    try:
                        ratio = 0.0
                        if hasattr(self._rate_limiter, 'get_current_usage_ratio'):
                            ratio = float(await self._rate_limiter.get_current_usage_ratio(user_id))
                        if ratio >= 0.8:
                            # ×× ×˜×™-×¡×¤××: ××–×”×¨×” ×œ×›×œ ×”×™×•×ª×¨ ×¤×¢× ×‘×“×§×” ×œ××©×ª××©
                            now_ts = time.time()
                            udata = getattr(context, 'user_data', None)
                            last_ts = 0.0
                            if isinstance(udata, dict):
                                try:
                                    last_ts = float(udata.get('_soft_warn_ts', 0.0) or 0.0)
                                except Exception:
                                    last_ts = 0.0
                            if (now_ts - last_ts) >= 60.0:
                                try:
                                    cq = getattr(update, 'callback_query', None)
                                    if cq is not None:
                                        await cq.answer("Heads-up: ××ª×” ××ª×§×¨×‘ ×œ××’×‘×œ×ª ×”×§×¦×‘ (80%+)", show_alert=False, cache_time=1)
                                    else:
                                        msg = getattr(update, 'message', None)
                                        if msg is not None:
                                            await msg.reply_text("â„¹ï¸ ×—×™×•×•×™: ××ª×” ××ª×§×¨×‘ ×œ××’×‘×œ×ª ×”×§×¦×‘. ×× ×ª××©×™×š ×‘×§×¦×‘ ×”×–×” ×™×™×ª×›×Ÿ ×©×ª×—×¡× ×–×× ×™×ª.")
                                except Exception:
                                    pass
                                if isinstance(udata, dict):
                                    udata['_soft_warn_ts'] = now_ts
                    except Exception:
                        pass

        # ×—×©×™×¤×” ×œ×¦×¨×›×™ ×‘×“×™×§×•×ª: ×©××•×¨ ×”×¤× ×™×” ×œ×©×¢×¨ ×‘×¨××ª ×”××•×‘×™×™×§×˜
        self._rate_limit_gate = _rate_limit_gate

        # ×”×•×¡×£ ×›×©×›×‘×ª ×¡×™× ×•×Ÿ ××•×§×“××ª ×¢×‘×•×¨ ×”×•×“×¢×•×ª ×•×œ×—×™×¦×•×ª
        try:
            self.application.add_handler(MessageHandler(filters.ALL, _rate_limit_gate), group=-90)
            self.application.add_handler(CallbackQueryHandler(_rate_limit_gate), group=-90)
        except Exception:
            pass

        # Add conversation handler
        conversation_handler = get_save_conversation_handler(
            db,
            callback_query_handler_cls=CallbackQueryHandler,
        )
        self.application.add_handler(conversation_handler)
        logger.info("ConversationHandler × ×•×¡×£")
        try:
            emit_event("conversation_handler_added", severity="info")
        except Exception:
            pass

        # ×¡×¤×•×¨ ×©×•×‘
        handler_count_after = len(self.application.handlers)
        logger.info(f"ğŸ” ×›××•×ª handlers ××—×¨×™: {handler_count_after}")
        try:
            emit_event("handlers_count_after", severity="info", count=handler_count_after)
        except Exception:
            pass

        # --- GitHub handlers - ×—×™×™×‘×™× ×œ×”×™×•×ª ×œ×¤× ×™ ×”-handler ×”×’×œ×•×‘×œ×™! ---
        # ×™×¦×™×¨×ª instance ×™×—×™×“ ×©×œ GitHubMenuHandler ×•×©××™×¨×” ×‘-bot_data
        github_handler = GitHubMenuHandler()
        try:
            github_handler.handle_menu_callback = _wrap_github_callback(github_handler.handle_menu_callback)
        except Exception:
            pass
        try:
            github_handler.handle_text_input = _wrap_handler_callback(github_handler.handle_text_input, "github:text_input")
        except Exception:
            pass
        try:
            github_handler.handle_file_upload = _wrap_handler_callback(github_handler.handle_file_upload, "github:file_upload")
        except Exception:
            pass
        self.application.bot_data['github_handler'] = github_handler
        logger.info("âœ… GitHubMenuHandler instance created and stored in bot_data")
        try:
            emit_event("github_handler_ready", severity="info")
        except Exception:
            pass
        # ×™×¦×™×¨×ª BackupMenuHandler ×•×©××™×¨×”
        backup_handler = BackupMenuHandler()
        self.application.bot_data['backup_handler'] = backup_handler
        logger.info("âœ… BackupMenuHandler instance created and stored in bot_data")
        try:
            emit_event("backup_handler_ready", severity="info")
        except Exception:
            pass

        # ×™×¦×™×¨×ª GoogleDriveMenuHandler ×•×©××™×¨×”
        drive_handler = GoogleDriveMenuHandler()
        self.application.bot_data['drive_handler'] = drive_handler
        # ×©××•×¨ ×’× ×¢×•×ª×§ ×™×©×™×¨ ×¢×œ ×”-application ×›×“×™ ×œ×”×ª×’×‘×¨ ×¢×œ ××¦×‘×™× ×©×‘×”× bot_data ××ª××¤×¡ (Persistence/Reload)
        try:
            setattr(self.application, "_drive_handler", drive_handler)
        except Exception:
            pass
        logger.info("âœ… GoogleDriveMenuHandler instance created and stored in bot_data")
        try:
            emit_event("drive_handler_ready", severity="info")
        except Exception:
            pass
        
        # ×”×•×¡×£ ×¤×§×•×“×ª github
        self.application.add_handler(CommandHandler("github", github_handler.github_menu_command))
        # ×”×•×¡×£ ×ª×¤×¨×™×˜ ×’×™×‘×•×™/×©×—×–×•×¨
        async def show_backup_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
            await backup_handler.show_backup_menu(update, context)
        self.application.add_handler(CommandHandler("backup", show_backup_menu))
        self.application.add_handler(CallbackQueryHandler(backup_handler.handle_callback_query, pattern=r'^(backup_|backup_add_note:.*)'))
        
        # ×”×•×¡×£ ××ª ×”-callbacks ×©×œ GitHub - ×—×©×•×‘! ×œ×¤× ×™ ×”-handler ×”×’×œ×•×‘×œ×™
        self.application.add_handler(
                        CallbackQueryHandler(github_handler.handle_menu_callback, 
                               pattern=r'^(select_repo|upload_file|upload_saved|show_current|set_token|set_folder|close_menu|folder_|repo_|repos_page_|upload_saved_|back_to_menu|repo_manual|noop|analyze_repo|analyze_current_repo|analyze_other_repo|show_suggestions|show_full_analysis|download_analysis_json|back_to_analysis|back_to_analysis_menu|back_to_summary|choose_my_repo|enter_repo_url|suggestion_\d+|github_menu|logout_github|delete_file_menu|delete_repo_menu|confirm_delete_repo|confirm_delete_repo_step1|confirm_delete_file|danger_delete_menu|download_file_menu|browse_repo|browse_open:.*|browse_select_download:.*|browse_select_delete:.*|browse_page:.*|download_zip:.*|multi_toggle|multi_execute|multi_clear|safe_toggle|browse_toggle_select:.*|inline_download_file:.*|view_more|view_back|browse_select_view:.*|browse_ref_menu|browse_refs_branches_page_.*|browse_refs_tags_page_.*|browse_select_ref:.*|browse_search|browse_search_page:.*|notifications_menu|notifications_toggle|notifications_toggle_pr|notifications_toggle_issues|notifications_interval_.*|notifications_check_now|notifications_sentry_test|share_folder_link:.*|share_selected_links|pr_menu|create_pr_menu|branches_page_.*|pr_select_head:.*|confirm_create_pr|merge_pr_menu|prs_page_.*|merge_pr:.*|confirm_merge_pr|validate_repo|git_checkpoint|git_checkpoint_doc:.*|git_checkpoint_doc_skip|restore_checkpoint_menu|restore_tags_page_.*|restore_select_tag:.*|restore_branch_from_tag:.*|restore_revert_pr_from_tag:.*|restore_commit_menu|restore_commits_page_.*|restore_select_commit:.*|restore_branch_from_commit:.*|restore_revert_pr_from_commit:.*|rcb:.*|rcpr:.*|open_pr_from_branch:.*|choose_upload_branch|upload_branches_page_.*|upload_select_branch:.*|upload_select_branch_tok:.*|choose_upload_folder|upload_select_folder:.*|upload_folder_root|upload_folder_current|upload_folder_custom|upload_folder_create|create_folder|confirm_saved_upload|refresh_saved_checks|github_backup_menu|github_backup_help|github_backup_db_list|github_restore_zip_to_repo|github_restore_zip_setpurge:.*|github_restore_zip_list|github_restore_zip_from_backup:.*|github_repo_restore_backup_setpurge:.*|gh_upload_cat:.*|gh_upload_repo:.*|gh_upload_large:.*|backup_menu|github_create_repo_from_zip|github_new_repo_name|github_set_new_repo_visibility:.*|upload_paste_code|cancel_paste_flow|gh_upload_zip_browse:.*|gh_upload_zip_page:.*|gh_upload_zip_select:.*|gh_upload_zip_select_idx:.*|backup_add_note:.*|github_import_repo|import_repo_branches_page_.*|import_repo_select_branch:.*|import_repo_start|import_repo_cancel)')
            )

        # ×”×•×¡×£ ××ª ×”-callbacks ×©×œ Google Drive
        self.application.add_handler(
            CallbackQueryHandler(
                drive_handler.handle_callback,
                pattern=r'^(drive_menu|drive_auth|drive_poll_once|drive_cancel_auth|drive_backup_now|drive_sel_zip|drive_sel_all|drive_sel_adv|drive_advanced|drive_adv_by_repo|drive_adv_large|drive_adv_other|drive_choose_folder|drive_choose_folder_adv|drive_folder_default|drive_folder_auto|drive_folder_set|drive_folder_back|drive_folder_cancel|drive_schedule|drive_set_schedule:.*|drive_status|drive_adv_multi_toggle|drive_adv_upload_selected|drive_logout|drive_logout_do|drive_simple_confirm|drive_adv_confirm|drive_make_zip_now|drive_help)$'
            )
        )

        # Inline query handler
        self.application.add_handler(InlineQueryHandler(github_handler.handle_inline_query))
        
        # ×”×’×“×¨ conversation handler ×œ×”×¢×œ××ª ×§×‘×¦×™×
        from github_menu_handler import FILE_UPLOAD, REPO_SELECT, FOLDER_SELECT
        async def _upload_cancel(update: Update, context: ContextTypes.DEFAULT_TYPE):
            try:
                cq = getattr(update, "callback_query", None)
                if cq is not None:
                    await cq.answer("×”×¢×œ××” ×‘×•×˜×œ×”", show_alert=False)
            except Exception:
                pass
            return ConversationHandler.END

        upload_conv_handler = ConversationHandler(
            entry_points=[
                CallbackQueryHandler(github_handler.handle_menu_callback, pattern='^upload_file$')
            ],
            states={
                FILE_UPLOAD: [
                    MessageHandler(filters.Document.ALL, github_handler.handle_file_upload)
                ],
                REPO_SELECT: [
                    MessageHandler(filters.TEXT & ~filters.COMMAND, github_handler.handle_text_input)
                ],
                FOLDER_SELECT: [
                    MessageHandler(filters.TEXT & ~filters.COMMAND, github_handler.handle_text_input)
                ]
            },
            fallbacks=[
                CommandHandler('cancel', _upload_cancel),
                CallbackQueryHandler(_upload_cancel, pattern=r'^cancel$')
            ]
        )
        
        self.application.add_handler(upload_conv_handler)
        
        # ×”×•×¡×£ handler ×›×œ×œ×™ ×œ×˜×™×¤×•×œ ×‘×§×œ×˜ ×˜×§×¡×˜ ×©×œ GitHub (×›×•×œ×œ URL ×œ× ×™×ª×•×—)
        async def handle_github_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
            # ×”×¢×‘×¨ ×›×œ ×§×œ×˜ ×¨×œ×•×•× ×˜×™ ×œ×× ×”×œ GitHub ×œ×¤×™ ×“×’×œ×™× ×‘-user_data
            message = getattr(update, "message", None)
            if message is None:
                logger.debug("handle_github_text: update without message, ignoring")
                return False
            message_text = getattr(message, "text", None)
            if message_text is None:
                logger.debug("handle_github_text: missing text payload, ignoring")
                return False
            text = (message_text or '').strip()
            main_menu_texts = {"â• ×”×•×¡×£ ×§×•×“ ×—×“×©", "ğŸ“š ×”×¦×’ ××ª ×›×œ ×”×§×‘×¦×™× ×©×œ×™", "ğŸ“‚ ×§×‘×¦×™× ×’×“×•×œ×™×", "ğŸ”§ GitHub", "ğŸ  ×ª×¤×¨×™×˜ ×¨××©×™", "âš¡ ×¢×™×‘×•×“ Batch"}
            if text in main_menu_texts:
                # × ×§×” ×“×’×œ×™× ×›×“×™ ×œ×× ×•×¢ ×˜×¨×™×’×¨ ×©×’×•×™
                context.user_data.pop('awaiting_search_text', None)  # ×™×¦×™××” ××•×˜×•××˜×™×ª ×"××¦×‘ ×—×™×¤×•×©"
                context.user_data.pop('search_ctx', None)
                context.user_data.pop('waiting_for_repo_url', None)
                context.user_data.pop('waiting_for_delete_file_path', None)
                context.user_data.pop('waiting_for_download_file_path', None)
                context.user_data.pop('waiting_for_new_repo_name', None)
                context.user_data.pop('waiting_for_selected_folder', None)
                context.user_data.pop('waiting_for_new_folder_path', None)
                context.user_data.pop('waiting_for_upload_folder', None)
                context.user_data.pop('return_to_pre_upload', None)
                # × ×§×” ×’× ×“×’×œ×™ "×”×“×‘×§ ×§×•×“" ×›×“×™ ×œ×¦××ª ×™×¤×” ××”×–×¨×™××”
                context.user_data.pop('waiting_for_paste_content', None)
                context.user_data.pop('waiting_for_paste_filename', None)
                context.user_data.pop('paste_content', None)
                return False
            # ×–×¨×™××ª ×”×•×¡×¤×ª ×”×¢×¨×” ×œ×’×™×‘×•×™ (××©×•×ª×¤×ª ×œ-GitHub/Backup)
            if context.user_data.get('waiting_for_backup_note_for'):
                backup_id = context.user_data.pop('waiting_for_backup_note_for')
                try:
                    from database import db
                    ok = db.save_backup_note(update.effective_user.id, backup_id, (text or '')[:1000])
                    if ok:
                        await update.message.reply_text(
                            "âœ… ×”×”×¢×¨×” × ×©××¨×”!",
                            reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("ğŸ”™ ×—×–×¨×”", callback_data=f"backup_details:{backup_id}")]])
                        )
                        # ×× ×¢ ×”×•×“×¢×ª "× ×¨××” ×©×–×” ×§×˜×¢ ×§×•×“!" ×¢×‘×•×¨ ×”×”×•×“×¢×” ×”×–×•
                        context.user_data['suppress_code_hint_once'] = True
                    else:
                        await update.message.reply_text("âŒ ×©××™×¨×ª ×”×”×¢×¨×” × ×›×©×œ×”")
                except Exception as e:
                    await update.message.reply_text(f"âŒ ×©×’×™××” ×‘×©××™×¨×ª ×”×”×¢×¨×”: {e}")
                return True
            # ×§×œ×˜ × ×ª×™×‘ ×™×¢×“ ×™×“× ×™ ×œ×¡×‘×™×‘×ª ×”×¢×œ××” (upload_folder_custom)
            if context.user_data.get('waiting_for_upload_folder'):
                # × ×™×ª×•×‘ ×˜×§×¡×˜ ×œ××˜×¤×œ ×˜×§×¡×˜×™× ×©×œ GitHub (×¡×× ×˜×™ ×•× ×§×™)
                return await github_handler.handle_text_input(update, context)

            if context.user_data.get('waiting_for_repo_url') or \
               context.user_data.get('waiting_for_delete_file_path') or \
               context.user_data.get('waiting_for_download_file_path') or \
               context.user_data.get('waiting_for_new_repo_name') or \
               context.user_data.get('waiting_for_selected_folder') or \
               context.user_data.get('waiting_for_new_folder_path') or \
               context.user_data.get('waiting_for_paste_content') or \
               context.user_data.get('waiting_for_paste_filename') or \
               context.user_data.get('browse_search_mode'):
                logger.info(f"ğŸ”— Routing GitHub-related text input from user {update.effective_user.id}")
                return await github_handler.handle_text_input(update, context)
            return False

        # ×”×•×¡×£ ××ª ×”-handler ×¢× ×¢×“×™×¤×•×ª ×’×‘×•×”×”
        self.application.add_handler(
            MessageHandler(filters.TEXT & ~filters.COMMAND, handle_github_text),
            group=-1  # ×¢×“×™×¤×•×ª ×’×‘×•×”×” ×××•×“
        )
        # ×”×•×¡×£ handler ×˜×§×¡×˜ ×œ-Drive (×§×•×“ ××™×©×•×¨)
        async def handle_drive_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
            return await drive_handler.handle_text(update, context)

        self.application.add_handler(
            MessageHandler(filters.TEXT & ~filters.COMMAND, handle_drive_text),
            group=-1
        )


        logger.info("âœ… GitHub handler × ×•×¡×£ ×‘×”×¦×œ×—×”")

        # Handler × ×¤×¨×“ ×œ×˜×™×¤×•×œ ×‘×˜×•×§×Ÿ GitHub
        async def handle_github_token(update: Update, context: ContextTypes.DEFAULT_TYPE):
            text = update.message.text
            if text.startswith('ghp_') or text.startswith('github_pat_'):
                user_id = update.message.from_user.id
                if user_id not in github_handler.user_sessions:
                    github_handler.user_sessions[user_id] = {}
                # ×©××™×¨×” ×‘×–×™×›×¨×•×Ÿ ×‘×œ×‘×“ ×œ×©×™××•×© ×©×•×˜×£
                github_handler.user_sessions[user_id]['github_token'] = text

                # ×©××•×¨ ×’× ×‘××¡×“ × ×ª×•× ×™× (×¢× ×”×¦×¤× ×” ×× ××•×’×“×¨ ××¤×ª×—)
                db.save_github_token(user_id, text)

                await update.message.reply_text(
                    "âœ… ×˜×•×§×Ÿ × ×©××¨ ×‘×”×¦×œ×—×”!\n"
                    "×›×¢×ª ×ª×•×›×œ ×œ×’×©×ª ×œ×¨×™×¤×•×–×™×˜×•×¨×™×– ×”×¤×¨×˜×™×™× ×©×œ×š.\n\n"
                    "×©×œ×— /github ×›×“×™ ×œ×—×–×•×¨ ×œ×ª×¤×¨×™×˜."
                )
                return

        # ×”×•×¡×£ ××ª ×”-handler
        self.application.add_handler(
            MessageHandler(filters.Regex('^(ghp_|github_pat_)'), handle_github_token),
            group=0  # ×¢×“×™×¤×•×ª ×’×‘×•×”×”
        )
        logger.info("âœ… GitHub token handler × ×•×¡×£ ×‘×”×¦×œ×—×”")

        # ×¤×§×•×“×” ×œ××—×™×§×ª ×˜×•×§×Ÿ GitHub
        async def handle_github_logout(update: Update, context: ContextTypes.DEFAULT_TYPE):
            user_id = update.effective_user.id
            # ××—×™×§×” ××”××¡×“ × ×ª×•× ×™×
            removed = db.delete_github_token(user_id)
            # × ×™×§×•×™ ××”×¡×©×Ÿ
            try:
                session = github_handler.get_user_session(user_id)
                session["github_token"] = None
                session['selected_repo'] = None
                session['selected_folder'] = None
            except Exception:
                pass
            # × ×™×§×•×™ ×§××© ×¨×™×¤×•×–×™×˜×•×¨×™×–
            context.user_data.pop('repos', None)
            context.user_data.pop('repos_cache_time', None)
            if removed:
                await update.message.reply_text("ğŸ” ×”×˜×•×§×Ÿ × ××—×§ ×‘×”×¦×œ×—×” ××”×—×©×‘×•×Ÿ ×©×œ×š.\nâœ… ×”×•×¡×¨×• ×’× ×”×’×“×¨×•×ª ×¨×™×¤×•/×ª×™×§×™×™×”.")
            else:
                await update.message.reply_text("â„¹ï¸ ×œ× × ××¦× ×˜×•×§×Ÿ ×œ×©×—×–×•×¨ ××• ×©××™×¨×¢×” ×©×’×™××”.")

        self.application.add_handler(CommandHandler("github_logout", handle_github_logout))

        # --- Guard ×’×œ×•×‘×œ×™ ×œ×œ×—×™×¦×•×ª ×›×¤×•×œ×•×ª ×¢×œ CallbackQuery (×§×“×™××•×ª ×’×‘×•×”×” ×‘×™×•×ª×¨) ---
        async def _global_callback_guard(update: Update, context: ContextTypes.DEFAULT_TYPE):
            try:
                if getattr(update, 'callback_query', None):
                    # ×‘×“×™×§×ª ×“×•×¤×œ×™×§×˜×™× ×§×¦×¨×” ×œ×›×œ ×”×›×¤×ª×•×¨×™×
                    try:
                        from utils import CallbackQueryGuard
                        if await CallbackQueryGuard.should_block_async(update, context):
                            try:
                                await update.callback_query.answer()
                            except Exception:
                                pass
                            # ×¢×¦×•×¨ ×¢×™×‘×•×“ × ×•×¡×£ ×©×œ ×”×”×•×“×¢×” ×”× ×•×›×—×™×ª
                            raise ApplicationHandlerStop()
                    except Exception:
                        pass
            except ApplicationHandlerStop:
                raise
            except Exception:
                pass

        # ×”×•×¡×£ ××ª ×”-guard ×‘×§×‘×•×¦×” ×‘×¢×œ×ª ×¢×“×™×¤×•×ª ×”×’×‘×•×”×” ×‘×™×•×ª×¨, ×œ×¤× ×™ ×›×œ ×”-handlers (×›×•×œ×œ batch/github/drive)
        self.application.add_handler(CallbackQueryHandler(_global_callback_guard), group=-100)

        # ×”×•×¡×¤×ª ×¤×§×•×“×•×ª batch (×¢×™×‘×•×“ ××¨×•×‘×” ×§×‘×¦×™×) ×œ××—×¨ ×”-guard ×›×š ×©×œ× ×™×¢×§×•×£ ××•×ª×•
        setup_batch_handlers(self.application)

        # --- Community Library handlers ---
        try:
            enabled_comm = bool(getattr(config, 'COMMUNITY_LIBRARY_ENABLED', True))
        except Exception:
            enabled_comm = True
        if enabled_comm:
            try:
                from conversation_handlers import (
                    community_submit_start,
                    community_collect_title,
                    community_collect_description,
                    community_collect_url,
                    community_collect_logo,
                    community_inline_approve,
                    community_reject_start,
                    community_collect_reject_reason,
                    # Snippet library
                    snippet_submit_start,
                    snippet_mode_regular_start,
                    snippet_mode_long_start,
                    snippet_collect_title,
                    snippet_collect_description,
                    snippet_collect_code,
                    snippet_collect_language,
                    snippet_long_collect_receive,
                    snippet_long_collect_done,
                    snippet_inline_approve,
                    snippet_reject_start,
                    snippet_collect_reject_reason,
                    show_community_hub,
                    community_catalog_menu,
                    snippets_menu,
                    # New helpers
                    community_hub_callback,
                    main_menu_callback,
                    submit_flows_cancel,
                    cancel,
                )
                from handlers.states import (
                    CL_COLLECT_TITLE,
                    CL_COLLECT_DESCRIPTION,
                    CL_COLLECT_URL,
                    CL_COLLECT_LOGO,
                    CL_REJECT_REASON,
                    SN_COLLECT_TITLE,
                    SN_COLLECT_DESCRIPTION,
                    SN_COLLECT_CODE,
                    SN_COLLECT_LANGUAGE,
                    SN_REJECT_REASON,
                    SN_LONG_COLLECT,
                )
                # Approve via inline button (admin-only wrapper inside function)
                self.application.add_handler(CallbackQueryHandler(community_inline_approve, pattern=r'^community_approve:'))
                # Community inline reject (reason collection)
                cl_reject_conv = ConversationHandler(
                    entry_points=[CallbackQueryHandler(community_reject_start, pattern=r'^community_reject:')],
                    states={
                        CL_REJECT_REASON: [MessageHandler(filters.TEXT & ~filters.COMMAND, community_collect_reject_reason)],
                    },
                    fallbacks=[CommandHandler('cancel', _cancel_command_fallback)],
                )
                self.application.add_handler(cl_reject_conv)
                # Snippet inline approve
                self.application.add_handler(CallbackQueryHandler(snippet_inline_approve, pattern=r'^snippet_approve:'))
                # Submission flow
                _logo_message_filter = filters.TEXT & ~filters.COMMAND
                try:
                    _photo_filter = getattr(filters, "PHOTO", None)
                    if _photo_filter is not None:
                        _logo_message_filter = (_photo_filter | filters.TEXT) & ~filters.COMMAND
                except Exception:
                    # ×× ×—×™×‘×•×¨ ×”×¤×™×œ×˜×¨×™× × ×›×©×œ (×œ××©×œ ×‘×¡×‘×™×‘×ª ×˜×¡×˜×™× ×¢× ×¡×˜××‘×™× ×¤×©×•×˜×™×),
                    # ×ª×™×©××¨ ×¨×§ ×‘×“×™×§×” ×¢×œ ×˜×§×¡×˜. ×—×©×•×‘ ×©×”-handler ×¢×“×™×™×Ÿ ×™×™×¨×©×.
                    _logo_message_filter = filters.TEXT & ~filters.COMMAND

                # ×“×¤×•×¡ ×˜×§×¡×˜×™× ×©×œ ×”×ª×¤×¨×™×˜ ×”×¨××©×™ ×œ×‘×™×˜×•×œ ××•×˜×•××˜×™ ×‘××”×œ×š ×ª×”×œ×™×›×™ ×”×’×©×”
                try:
                    import re as _re
                    _flat_main_menu = [t for row in MAIN_KEYBOARD for t in row]
                    _main_menu_regex = r'^(' + "|".join(_re.escape(t) for t in _flat_main_menu) + r')$'
                except Exception:
                    _main_menu_regex = r'^(?:)$'  # fallback: ×œ× ×ª×•×¤×¡ ×›×œ×•× ×‘××§×¨×” ×©×œ ×›×©×œ

                comm_conv = ConversationHandler(
                    entry_points=[CallbackQueryHandler(community_submit_start, pattern=r'^community_submit$')],
                    states={
                        CL_COLLECT_TITLE: [MessageHandler(filters.TEXT & ~filters.COMMAND, community_collect_title)],
                        CL_COLLECT_DESCRIPTION: [MessageHandler(filters.TEXT & ~filters.COMMAND, community_collect_description)],
                        CL_COLLECT_URL: [MessageHandler(filters.TEXT & ~filters.COMMAND, community_collect_url)],
                        CL_COLLECT_LOGO: [MessageHandler(_logo_message_filter, community_collect_logo)],
                    },
                    fallbacks=[
                        CommandHandler('cancel', _cancel_command_fallback),
                        CallbackQueryHandler(submit_flows_cancel, pattern=r'^cancel$'),
                        # ×‘×™×˜×•×œ ××•×˜×•××˜×™ ×›××©×¨ ×”××©×ª××© ×œ×•×—×¥ ×¢×œ ×›×¤×ª×•×¨ ××—×¨ ×‘×ª×¤×¨×™×˜ ×”×¨××©×™
                        MessageHandler(filters.Regex(_main_menu_regex), cancel),
                    ],
                )
                self.application.add_handler(comm_conv)
                # Snippet submission flow
                sn_conv = ConversationHandler(
                    entry_points=[
                        CallbackQueryHandler(snippet_submit_start, pattern=r'^snippet_submit$'),
                        CallbackQueryHandler(snippet_mode_regular_start, pattern=r'^snippet_mode_regular$'),
                        CallbackQueryHandler(snippet_mode_long_start, pattern=r'^snippet_mode_long$'),
                    ],
                    states={
                        SN_COLLECT_TITLE: [MessageHandler(filters.TEXT & ~filters.COMMAND, snippet_collect_title)],
                        SN_COLLECT_DESCRIPTION: [MessageHandler(filters.TEXT & ~filters.COMMAND, snippet_collect_description)],
                        SN_COLLECT_CODE: [MessageHandler(filters.TEXT & ~filters.COMMAND, snippet_collect_code)],
                        SN_COLLECT_LANGUAGE: [MessageHandler(filters.TEXT & ~filters.COMMAND, snippet_collect_language)],
                        SN_LONG_COLLECT: [
                            MessageHandler(filters.TEXT & ~filters.COMMAND, snippet_long_collect_receive),
                            CommandHandler('done', snippet_long_collect_done),
                        ],
                    },
                    fallbacks=[
                        CommandHandler('cancel', _cancel_command_fallback),
                        CallbackQueryHandler(submit_flows_cancel, pattern=r'^cancel$'),
                        # ×‘×™×˜×•×œ ××•×˜×•××˜×™ ×›××©×¨ ×”××©×ª××© ×œ×•×—×¥ ×¢×œ ×›×¤×ª×•×¨ ××—×¨ ×‘×ª×¤×¨×™×˜ ×”×¨××©×™
                        MessageHandler(filters.Regex(_main_menu_regex), cancel),
                    ],
                )
                self.application.add_handler(sn_conv)
                # Snippet reject reason flow
                sn_reject_conv = ConversationHandler(
                    entry_points=[CallbackQueryHandler(snippet_reject_start, pattern=r'^snippet_reject:')],
                    states={
                        SN_REJECT_REASON: [MessageHandler(filters.TEXT & ~filters.COMMAND, snippet_collect_reject_reason)],
                    },
                    fallbacks=[CommandHandler('cancel', _cancel_command_fallback)],
                )
                self.application.add_handler(sn_reject_conv)
                # Community hub menus
                self.application.add_handler(MessageHandler(filters.Regex("^ğŸ—ƒï¸ ××•×¡×£ ×”×§×”×™×œ×”$"), show_community_hub))
                self.application.add_handler(CallbackQueryHandler(community_catalog_menu, pattern=r'^community_catalog_menu$'))
                self.application.add_handler(CallbackQueryHandler(snippets_menu, pattern=r'^snippets_menu$'))
                # Back navigation helpers
                self.application.add_handler(CallbackQueryHandler(community_hub_callback, pattern=r'^community_hub$'))
                self.application.add_handler(CallbackQueryHandler(main_menu_callback, pattern=r'^main_menu$'))
                # Global cancel for submission flows (works also on entry screen)
                self.application.add_handler(CallbackQueryHandler(submit_flows_cancel, pattern=r'^cancel$'))
            except Exception as _e:
                try:
                    logger.info("Community library handlers not registered: %s", _e)
                except Exception:
                    pass

        # ×”×•×¡×¤×ª Refactoring handlers (×× ×–××™× ×™×)
        try:
            from refactor_handlers import setup_refactor_handlers as _setup_rf
            if callable(_setup_rf):
                _setup_rf(self.application)
                logger.info("âœ… RefactorHandlers ×”×•×’×“×¨×• (×¤×§×•×“×ª /refactor ×–××™× ×”)")
        except Exception as e:
            logger.warning(f"âš ï¸ ×“×™×œ×•×’ ×¢×œ RefactorHandlers: {e}")

        # --- ×¨×§ ××—×¨×™ ×›×œ ×”-handlers ×”×¡×¤×¦×™×¤×™×™×, ×”×•×¡×£ ××ª ×”-handler ×”×’×œ×•×‘×œ×™ ---
        # ×—×©×•×‘: ×”×•×¡×¤×” ×‘×§×‘×•×¦×” ×××•×—×¨×ª ×›×“×™ ×©×œ× ×ª×ª×¤×•×¡ ×œ×¤× ×™ handlers ×™×™×¢×•×“×™×™× (×œ××©×œ ××•×¢×“×¤×™×)
        from conversation_handlers import handle_callback_query
        _register_catch_all_callback(self.application, handle_callback_query)

        try:
            _instrument_command_handlers(self.application)
        except Exception:
            pass

        # ×¡×¤×•×¨ ×¡×•×¤×™
        final_handler_count = len(self.application.handlers)
        logger.info(f"ğŸ” ×›××•×ª handlers ×¡×•×¤×™×ª: {final_handler_count}")

        # ×”×“×¤×¡ ××ª ×›×œ ×”-handlers
        for i, handler in enumerate(self.application.handlers):
            logger.info(f"Handler {i}: {type(handler).__name__}")

        # --- ×©×œ×‘ 2: ×¨×™×©×•× ×©××¨ ×”×¤×§×•×“×•×ª ---
        # ×¤×§×•×“×ª ×× ×”×œ×™×: recycle_backfill
        self.application.add_handler(CommandHandler("recycle_backfill", recycle_backfill_command))
        # ×¤×§×•×“×•×ª ×× ×”×œ×™ ×¡×¤×¨×™×™×ª ×§×”×™×œ×”
        try:
            enabled_comm = bool(getattr(config, 'COMMUNITY_LIBRARY_ENABLED', True))
        except Exception:
            enabled_comm = True
        if enabled_comm:
            try:
                from conversation_handlers import (
                    community_queue_command, community_approve_command, community_reject_command,
                    snippet_queue_command, snippet_approve_command, snippet_reject_command,
                )
                self.application.add_handler(CommandHandler("community_queue", community_queue_command))
                self.application.add_handler(CommandHandler("community_approve", community_approve_command))
                self.application.add_handler(CommandHandler("community_reject", community_reject_command))
                # Snippet admin commands
                self.application.add_handler(CommandHandler("snippet_queue", snippet_queue_command))
                self.application.add_handler(CommandHandler("snippet_approve", snippet_approve_command))
                self.application.add_handler(CommandHandler("snippet_reject", snippet_reject_command))
            except Exception:
                pass
        # ×”×¤×§×•×“×” /start ×”××§×•×¨×™×ª ×”×•×¤×›×ª ×œ×”×™×•×ª ×—×œ×§ ××”-conv_handler, ××– ×”×™× ×œ× ×›××Ÿ.
        self.application.add_handler(CommandHandler("help", self.help_command))
        self.application.add_handler(CommandHandler("save", self.save_command))
        # self.application.add_handler(CommandHandler("list", self.list_command))  # ××—×•×§ - ××˜×•×¤×œ ×¢×œ ×™×“×™ ×”×›×¤×ª×•×¨ "ğŸ“š ×”×¦×’ ××ª ×›×œ ×”×§×‘×¦×™× ×©×œ×™"
        self.application.add_handler(CommandHandler("search", self.search_command))
        self.application.add_handler(CommandHandler("stats", self.stats_command))
        self.application.add_handler(CommandHandler("check", self.check_commands))

        # ChatOps: /jobs (Background Jobs Monitor)
        async def jobs_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
            try:
                from chatops.jobs_commands import handle_jobs_command
            except Exception:
                await update.message.reply_text("âŒ Jobs monitor ×œ× ×–××™×Ÿ ×›×¨×’×¢")
                return
            args_text = ""
            try:
                args_text = " ".join(getattr(context, "args", None) or [])
            except Exception:
                args_text = ""
            text = handle_jobs_command(args_text)
            try:
                await update.message.reply_text(
                    text,
                    parse_mode=ParseMode.MARKDOWN,
                    disable_web_page_preview=True,
                )
            except Exception:
                # fallback ×œ-plain
                await update.message.reply_text(text, disable_web_page_preview=True)

        self.application.add_handler(CommandHandler("jobs", jobs_command))
        
        # ×”×•×¡×¤×ª ×¤×§×•×“×•×ª cache
        setup_cache_handlers(self.application)
        
        # ×”×•×¡×¤×ª ×¤×§×•×“×•×ª ××©×•×¤×¨×•×ª (××•×˜×•-×”×©×œ××” ×•×ª×¦×•×’×” ××§×“×™××”) - disabled
        # setup_enhanced_handlers(self.application)

        # ×”×˜×¨××™× ×œ ×”×•×¡×¨ ×‘×¡×‘×™×‘×ª Render (Docker ×œ× ×–××™×Ÿ)


        # ×”×•×¡×¤×ª handlers ×œ×›×¤×ª×•×¨×™× ×”×—×“×©×™× ×‘××§×œ×“×ª ×”×¨××©×™×ª
        from conversation_handlers import handle_batch_button
        self.application.add_handler(MessageHandler(
            filters.Regex("^âš¡ ×¢×™×‘×•×“ Batch$"), 
            handle_batch_button
        ))
        # ×›×¤×ª×•×¨ ×œ×ª×¤×¨×™×˜ Google Drive
        async def show_drive_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
            await drive_handler.menu(update, context)
        self.application.add_handler(MessageHandler(
            filters.Regex("^â˜ï¸ Google Drive$"),
            show_drive_menu
        ))

        # ×¤×§×•×“×” /drive
        self.application.add_handler(CommandHandler("drive", show_drive_menu))
        
        # ×›×¤×ª×•×¨ Web App
        async def show_webapp(update: Update, context: ContextTypes.DEFAULT_TYPE):
            webapp_url = os.getenv('WEBAPP_URL', 'https://code-keeper-webapp.onrender.com')
            keyboard = [
                [InlineKeyboardButton("ğŸŒ ×¤×ª×— ××ª ×”-Web App", url=webapp_url)],
                [InlineKeyboardButton("ğŸ” ×”×ª×—×‘×¨ ×œ-Web App", url=f"{webapp_url}/login")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            await update.message.reply_text(
                "ğŸŒ <b>Web App - ×××©×§ × ×™×”×•×œ ××ª×§×“×</b>\n\n"
                "×¦×¤×” ×•× ×”×œ ××ª ×›×œ ×”×§×‘×¦×™× ×©×œ×š ×“×¨×š ×”×“×¤×“×¤×Ÿ:\n"
                "â€¢ ğŸ“Š ×“×©×‘×•×¨×“ ×¢× ×¡×˜×˜×™×¡×˜×™×§×•×ª\n"
                "â€¢ ğŸ” ×—×™×¤×•×© ×•×¡×™× ×•×Ÿ ××ª×§×“×\n"
                "â€¢ ğŸ‘ï¸ ×¦×¤×™×™×” ×‘×§×‘×¦×™× ×¢× ×”×“×’×©×ª syntax\n"
                "â€¢ ğŸ“¥ ×”×•×¨×“×ª ×§×‘×¦×™×\n"
                "â€¢ ğŸ“± ×¢×•×‘×“ ×‘×›×œ ××›×©×™×¨\n\n"
                "×œ×—×¥ ×¢×œ ×”×›×¤×ª×•×¨ ×œ××˜×” ×›×“×™ ×œ×¤×ª×•×—:",
                reply_markup=reply_markup,
                parse_mode=ParseMode.HTML
            )
        
        self.application.add_handler(MessageHandler(
            filters.Regex("^ğŸŒ Web App$"),
            show_webapp
        ))
        
        # ×¤×§×•×“×” /webapp
        self.application.add_handler(CommandHandler("webapp", show_webapp))
        
        # ×›×¤×ª×•×¨ ×—×“×© ×œ×ª×¤×¨×™×˜ ×’×™×‘×•×™/×©×—×–×•×¨

        # ×¤×§×•×“×” /docs â€“ ×©×œ×™×—×ª ×§×™×©×•×¨ ×œ×ª×™×¢×•×“
        async def show_docs(update: Update, context: ContextTypes.DEFAULT_TYPE):
            await update.message.reply_text(f"ğŸ“š ×ª×™×¢×•×“: {config.DOCUMENTATION_URL}")
        self.application.add_handler(CommandHandler("docs", show_docs))
        # ×”×•×¡×¨: ×›×¤×ª×•×¨×™ ×’×™×‘×•×™/×©×—×–×•×¨ ××”××§×œ×“×ª ×”×¨××©×™×ª. ×›×¢×ª ×ª×—×ª /github -> ğŸ§° ×’×™×‘×•×™ ×•×©×—×–×•×¨
        # self.application.add_handler(MessageHandler(
        #     filters.Regex("^(ğŸ“¦ ×’×™×‘×•×™ ××œ×|â™»ï¸ ×©×—×–×•×¨ ××’×™×‘×•×™|ğŸ§° ×’×™×‘×•×™/×©×—×–×•×¨)$"),
        #     show_backup_menu
        # ))
        
        # --- ×©×œ×‘ 3: ×¨×™×©×•× handler ×œ×§×‘×¦×™× ---
        self.application.add_handler(
            MessageHandler(filters.Document.ALL, self.handle_document)
        )
        
        # --- ×©×œ×‘ 4: ×¨×™×©×•× ×”××˜×¤×œ ×”×›×œ×œ×™ ×‘×¡×•×£ ---
        # ×”×•× ×™×¤×¢×œ ×¨×§ ×× ××£ ××—×“ ××”××˜×¤×œ×™× ×”×¡×¤×¦×™×¤×™×™× ×™×•×ª×¨ ×œ× ×ª×¤×¡ ××ª ×”×”×•×“×¢×”.
        self.application.add_handler(
            MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_text_message)
        )
        
        try:
            _instrument_command_handlers(self.application)
        except Exception:
            pass

        # --- ×©×œ×‘ 5: ×˜×™×¤×•×œ ×‘×©×’×™××•×ª ---
        self.application.add_error_handler(self.error_handler)
    
    # start_command ×”×•×¡×¨ - ConversationHandler ××˜×¤×œ ×‘×¤×§×•×“×ª /start
    
    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×¤×§×•×“×ª ×¢×–×¨×” ××¤×•×¨×˜×ª"""
        if reporter is not None:
            reporter.report_activity(update.effective_user.id)
        await log_user_activity(update, context)
        ctx_app = getattr(context, "application", None)
        ctx_commands = _get_registered_commands(ctx_app) if ctx_app else set()
        if ctx_commands:
            commands = ctx_commands
        else:
            commands = _get_registered_commands(self.application)
        try:
            from chatops.permissions import is_admin as _is_admin
            user_id = int(getattr(getattr(update, "effective_user", None), "id", 0) or 0)
            user_is_admin = bool(_is_admin(user_id))
        except Exception:
            user_is_admin = False
        response = _build_help_message(commands, is_admin=user_is_admin)
        for chunk in _split_long_message(response):
            await update.message.reply_text(chunk, parse_mode=ParseMode.HTML, disable_web_page_preview=True)
    
    async def save_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×¤×§×•×“×ª ×©××™×¨×ª ×§×•×“"""
        if reporter is not None:
            reporter.report_activity(update.effective_user.id)
        await log_user_activity(update, context)
        user_id = update.effective_user.id
        
        if not context.args:
            await update.message.reply_text(
                "â“ ×× × ×¦×™×™×Ÿ ×©× ×§×•×‘×¥:\n"
                "×“×•×’××”: `/save script.py`\n"
                "×¢× ×ª×’×™×•×ª: `/save script.py #python #api`",
                parse_mode=ParseMode.MARKDOWN
            )
            return
        
        # ×¤×¨×¡×•×¨ ×©× ×§×•×‘×¥ ×•×ª×’×™×•×ª
        args = " ".join(context.args)
        tags = []
        
        # ×—×™×œ×•×¥ ×ª×’×™×•×ª
        import re
        tag_matches = re.findall(r'#(\w+)', args)
        if tag_matches:
            tags = tag_matches
            # ×”×¡×¨×ª ×”×ª×’×™×•×ª ××©× ×”×§×•×‘×¥
            args = re.sub(r'#\w+', '', args).strip()
        
        file_name = args
        
        # ×©××™×¨×ª ××™×“×¢ ×‘×”×§×©×¨ ×œ××©×š ×”×©×™×—×”
        context.user_data['saving_file'] = {
            'file_name': file_name,
            'tags': tags,
            'user_id': user_id
        }
        
        safe_file_name = html_escape(file_name)
        safe_tags = ", ".join(html_escape(t) for t in tags) if tags else '×œ×œ×'
        
        # ×‘×§×©×ª ×§×•×“ ×•×œ××—×¨×™×• ×”×¢×¨×” ××•×¤×¦×™×•× ×œ×™×ª
        await update.message.reply_text(
            f"ğŸ“ ××•×›×Ÿ ×œ×©××•×¨ ××ª <code>{safe_file_name}</code>\n"
            f"ğŸ·ï¸ ×ª×’×™×•×ª: {safe_tags}\n\n"
            "×× × ×©×œ×— ××ª ×§×˜×¢ ×”×§×•×“:\n"
            "(××—×¨×™ ×©× ×§×‘×œ ××ª ×”×§×•×“, ××©××œ ×× ×ª×¨×¦×” ×œ×”×•×¡×™×£ ×”×¢×¨×”)",
            parse_mode=ParseMode.HTML
        )
    
    async def list_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×”×¦×’×ª ×¨×©×™××ª ×”×§×˜×¢×™× ×©×œ ×”××©×ª××©"""
        if reporter is not None:
            reporter.report_activity(update.effective_user.id)
        user_id = update.effective_user.id
        
        files = db.get_user_files(user_id, limit=20)
        
        if not files:
            await update.message.reply_text(
                "ğŸ“‚ ×¢×“×™×™×Ÿ ×œ× ×©××¨×ª ×§×˜×¢×™ ×§×•×“.\n"
                "×”×©×ª××© ×‘/save ×›×“×™ ×œ×”×ª×—×™×œ!"
            )
            return
        
        # ×‘× ×™×™×ª ×”×¨×©×™××”
        response = "ğŸ“‹ **×”×§×˜×¢×™× ×©×œ×š:**\n\n"
        
        for i, file_data in enumerate(files, 1):
            tags_str = ", ".join(file_data.get('tags', [])) if file_data.get('tags') else ""
            description = file_data.get('description', '')
            
            response += f"**{i}. {file_data['file_name']}**\n"
            response += f"ğŸ”¤ ×©×¤×”: {file_data['programming_language']}\n"
            
            if description:
                response += f"ğŸ“ ×ª×™××•×¨: {description}\n"
            
            if tags_str:
                response += f"ğŸ·ï¸ ×ª×’×™×•×ª: {tags_str}\n"
            
            response += f"ğŸ“… ×¢×•×“×›×Ÿ: {file_data['updated_at'].strftime('%d/%m/%Y %H:%M')}\n"
            response += f"ğŸ”¢ ×’×¨×¡×”: {file_data['version']}\n\n"
        
        if len(files) == 20:
            response += "\nğŸ“„ ××•×¦×’×™× 20 ×”×§×˜×¢×™× ×”××—×¨×•× ×™×. ×”×©×ª××© ×‘×—×™×¤×•×© ×œ×¢×•×“..."
        
        await update.message.reply_text(response, parse_mode=ParseMode.HTML)
    
    async def search_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×—×™×¤×•×© ×§×˜×¢×™ ×§×•×“"""
        if reporter is not None:
            reporter.report_activity(update.effective_user.id)
        await log_user_activity(update, context)
        user_id = update.effective_user.id
        
        if not context.args:
            await update.message.reply_text(
                "ğŸ” **××™×š ×œ×—×¤×©:**\n"
                "â€¢ `/search python` - ×œ×¤×™ ×©×¤×”\n"
                "â€¢ `/search api` - ×—×™×¤×•×© ×—×•×¤×©×™\n"
                "â€¢ `/search #automation` - ×œ×¤×™ ×ª×’×™×ª\n"
                "â€¢ `/search script` - ×‘×©× ×§×•×‘×¥",
                parse_mode=ParseMode.MARKDOWN
            )
            return
        
        query = " ".join(context.args)
        
        # ×–×™×”×•×™ ×× ×–×” ×—×™×¤×•×© ×œ×¤×™ ×ª×’×™×ª
        tags: list[str] = []
        # ×ª××™×›×” ×‘×’×¨×¡××•×ª ×™×©× ×•×ª ×©×œ ×”×§×•× ×¤×™×’ ×©×œ× ×›×•×œ×œ×•×ª SUPPORTED_LANGUAGES
        try:
            supported_languages = getattr(config, "SUPPORTED_LANGUAGES", []) or []
        except Exception:
            supported_languages = []
        normalized_languages = {lang.lower(): lang for lang in supported_languages if isinstance(lang, str)}

        language_filter: str | None = None
        search_term = query

        if query.startswith('#'):
            tags = [query[1:]]
            search_term = ""
        else:
            matched_language = normalized_languages.get(query.lower()) if normalized_languages else None
            if matched_language is not None:
                language_filter = matched_language
                search_term = ""

        if language_filter is not None:
            # ×—×™×¤×•×© ×œ×¤×™ ×©×¤×”
            with track_performance("search_by_language", labels={"operation": "search_by_language"}):
                results = db.search_code(user_id, "", programming_language=language_filter)
        else:
            # ×—×™×¤×•×© ×—×•×¤×©×™ ××• ×œ×¤×™ ×ª×’×™×ª
            with track_performance("search_free", labels={"operation": "search_free"}):
                results = db.search_code(user_id, search_term, tags=tags)
        
        if not results:
            await update.message.reply_text(
                f"ğŸ” ×œ× × ××¦××• ×ª×•×¦××•×ª ×¢×‘×•×¨: <code>{html_escape(' '.join(context.args))}</code>",
                parse_mode=ParseMode.HTML
            )
            return
        
        # Business metric: search performed (avoid logging raw query)
        try:
            track_search_performed(user_id=user_id, query=' '.join(context.args), results_count=len(results))
            emit_event(
                "search_performed",
                severity="info",
                user_id=user_id,
                query_length=len(' '.join(context.args)),
                results_count=len(results),
            )
        except Exception:
            pass

        # ×”×¦×’×ª ×ª×•×¦××•×ª
        safe_query = html_escape(' '.join(context.args))
        response = f"ğŸ” **×ª×•×¦××•×ª ×—×™×¤×•×© ×¢×‘×•×¨:** <code>{safe_query}</code>\n\n"
        
        for i, file_data in enumerate(results[:10], 1):
            response += f"{i}. <code>{html_escape(file_data['file_name'])}</code> â€” {file_data['programming_language']}\n"
        
        if len(results) > 10:
            response += f"\nğŸ“„ ××•×¦×’×•×ª 10 ××ª×•×š {len(results)} ×ª×•×¦××•×ª"
        
        await update.message.reply_text(response, parse_mode=ParseMode.HTML)
    
    async def check_commands(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×‘×“×™×§×ª ×¤×§×•×“×•×ª ×ª×¤×¨×™×˜/Runtime (×× ×”×œ×™× ×‘×œ×‘×“).

        ×©×™××•×©×™×:

        - ``/check``: ××¦×™×’ ××ª ×¤×§×•×“×•×ª ×”×ª×¤×¨×™×˜ (Telegram menu) ×¦×™×‘×•×¨×™ + scope ××™×©×™
        - ``/check commands``: ××¦×™×’ ××ª ×›×œ ×”-Slash commands ×©× ×¨×©××• ×‘-runtime ×“×¨×š Application.handlers,
          ×•××©×•×•×” ××•×œ ×”×ª×¤×¨×™×˜ ×›×“×™ ×œ×–×”×•×ª ××” "××•×¡×ª×¨".
        """
        from chatops.permissions import is_admin

        message_obj = getattr(update, "effective_message", None) or getattr(update, "message", None)
        try:
            user_id = int(getattr(getattr(update, "effective_user", None), "id", 0) or 0)
        except Exception:
            user_id = 0

        if not is_admin(user_id):
            if message_obj is not None:
                await message_obj.reply_text("âŒ ×¤×§×•×“×” ×–××™× ×” ×œ×× ×”×œ×™× ×‘×œ×‘×“")
            return

        args = []
        try:
            args = [str(a).strip().lower() for a in (getattr(context, "args", None) or []) if str(a).strip()]
        except Exception:
            args = []

        # /check commands â€“ ×“×™×‘×•×’ ×¤×§×•×“×•×ª runtime + diff ××•×œ ×ª×¤×¨×™×˜ ×˜×œ×’×¨×
        if args[:1] == ["commands"]:
            app = getattr(context, "application", None) or getattr(self, "application", None)
            registered = _get_registered_commands(app)

            public_cmds = None
            personal_cmds = None
            try:
                public_cmds = await context.bot.get_my_commands()
            except Exception:
                public_cmds = None
            try:
                from telegram import BotCommandScopeChat

                # ×‘×¦'××˜ ×¤×¨×˜×™ chat_id == user_id
                personal_cmds = await context.bot.get_my_commands(scope=BotCommandScopeChat(chat_id=user_id))
            except Exception:
                personal_cmds = None

            report = _build_debug_commands_report(
                registered_commands=registered,
                public_menu_commands=public_cmds,
                personal_menu_commands=personal_cmds,
            )
            if message_obj is not None:
                await message_obj.reply_text(report, parse_mode=ParseMode.HTML, disable_web_page_preview=True)
            return

        # /check â€“ ×ª×¤×¨×™×˜ ×¤×§×•×“×•×ª ×˜×œ×’×¨× (×¦×™×‘×•×¨×™ + ××™×©×™)
        from html import escape as html_escape

        warnings: list[str] = []

        public_cmds = []
        try:
            public_cmds = await context.bot.get_my_commands()
        except Exception:
            public_cmds = []
            warnings.append("âš ï¸ ×œ× ×”×¦×œ×—×ª×™ ×œ××©×•×š ×¤×§×•×“×•×ª ×¦×™×‘×•×¨×™×•×ª ××”-API ×©×œ ×˜×œ×’×¨×")

        # ×‘×¦'××˜ ×¤×¨×˜×™ chat_id == user_id. ×× ××™×Ÿ user_id (0), × × ×¡×” fallback ×œ-chat_id ×©×œ ×”×”×•×“×¢×”.
        chat_id_for_personal = None
        try:
            if user_id:
                chat_id_for_personal = user_id
            else:
                effective_chat = getattr(update, "effective_chat", None)
                cid = getattr(effective_chat, "id", None) if effective_chat is not None else None
                if isinstance(cid, int) and cid != 0:
                    chat_id_for_personal = cid
        except Exception:
            chat_id_for_personal = None

        personal_cmds = []
        if chat_id_for_personal is None:
            personal_cmds = []
            warnings.append("âš ï¸ ×“×™×œ×•×’ ×¢×œ ×¤×§×•×“×•×ª ××™×©×™×•×ª: ××™×Ÿ chat_id ×–××™×Ÿ")
        else:
            try:
                from telegram import BotCommandScopeChat

                personal_cmds = await context.bot.get_my_commands(
                    scope=BotCommandScopeChat(chat_id=chat_id_for_personal)
                )
            except Exception:
                personal_cmds = []
                warnings.append("âš ï¸ ×œ× ×”×¦×œ×—×ª×™ ×œ××©×•×š ×¤×§×•×“×•×ª ××™×©×™×•×ª (scope) ××”-API ×©×œ ×˜×œ×’×¨×")

        message = "ğŸ“‹ <b>×¡×˜×˜×•×¡ ×¤×§×•×“×•×ª (Telegram Menu)</b>\n\n"
        if warnings:
            message += "\n".join(warnings) + "\n\n"
        message += f"×¡×™×›×•×: ×¦×™×‘×•×¨×™×•×ª {len(public_cmds)} | ××™×©×™×•×ª {len(personal_cmds)}\n\n"
        if public_cmds:
            public_list = "\n".join(f"/{cmd.command}" for cmd in public_cmds)
            message += "<b>×¦×™×‘×•×¨×™×•×ª:</b>\n" + f"<pre>{html_escape(public_list)}</pre>\n"
        if personal_cmds:
            personal_list = "\n".join(f"/{cmd.command} â€” {cmd.description}" for cmd in personal_cmds)
            message += "<b>××™×©×™×•×ª:</b>\n" + f"<pre>{html_escape(personal_list)}</pre>"

        if message_obj is not None:
            await message_obj.reply_text(message, parse_mode=ParseMode.HTML, disable_web_page_preview=True)

    async def stats_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×”×¦×’×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ×”××©×ª××© ××• ×× ×”×œ"""
        if reporter is not None:
            reporter.report_activity(update.effective_user.id)
        await log_user_activity(update, context)  # ×”×•×¡×¤×ª ×¨×™×©×•× ××©×ª××© ×œ×¡×˜×˜×™×¡×˜×™×§×•×ª
        user_id = update.effective_user.id
        
        # ×¨×©×™××ª ×× ×”×œ×™×
        ADMIN_IDS = [6865105071]  # ×”×•×¡×£ ××ª ×”-ID ×©×œ×š ×›××Ÿ!
        
        # ×× ×”××©×ª××© ×”×•× ×× ×”×œ, ×”×¦×’ ×¡×˜×˜×™×¡×˜×™×§×•×ª ×× ×”×œ
        if user_id in ADMIN_IDS:
            # ×§×‘×œ ×¡×˜×˜×™×¡×˜×™×§×•×ª ×›×œ×œ×™×•×ª
            general_stats = user_stats.get_all_time_stats()
            weekly_users = user_stats.get_weekly_stats()
            
            # ×‘× ×” ×”×•×“×¢×” ×‘×˜×•×—×” ×œ-HTML
            message = "ğŸ“Š <b>×¡×˜×˜×™×¡×˜×™×§×•×ª ×× ×”×œ - ×©×‘×•×¢ ××—×¨×•×Ÿ:</b>\n\n"
            message += f"ğŸ‘¥ ×¡×”×´×› ××©×ª××©×™× ×¨×©×•××™×: {general_stats['total_users']}\n"
            message += f"ğŸŸ¢ ×¤×¢×™×œ×™× ×”×™×•×: {general_stats['active_today']}\n"
            message += f"ğŸ“… ×¤×¢×™×œ×™× ×”×©×‘×•×¢: {general_stats['active_week']}\n\n"
            
            if weekly_users:
                message += "ğŸ“‹ <b>×¨×©×™××ª ××©×ª××©×™× ×¤×¢×™×œ×™×:</b>\n"
                from html import escape as html_escape
                for i, user in enumerate(weekly_users[:15], 1):
                    username = user.get('username') or 'User'
                    # ×”×™××œ×˜×•×ª ×‘×˜×•×—×”
                    safe_username = html_escape(username)
                    if safe_username and safe_username != 'User' and not safe_username.startswith('User_'):
                        # ×”×•×¡×¤×ª @ ×× ×–×” ×©× ××©×ª××© ×˜×œ×’×¨×
                        display_name = f"@{safe_username}" if not safe_username.startswith('@') else safe_username
                    else:
                        display_name = safe_username
                    message += f"{i}. {display_name} - {user['days']} ×™××™× ({user['total_actions']} ×¤×¢×•×œ×•×ª)\n"
                
                if len(weekly_users) > 15:
                    message += f"\n... ×•×¢×•×“ {len(weekly_users) - 15} ××©×ª××©×™×"
            else:
                message += "××™×Ÿ ××©×ª××©×™× ×¤×¢×™×œ×™× ×‘×©×‘×•×¢ ×”××—×¨×•×Ÿ"
            
            await update.message.reply_text(message, parse_mode=ParseMode.HTML, reply_markup=ReplyKeyboardMarkup(MAIN_KEYBOARD, resize_keyboard=True))
        else:
            # ×¡×˜×˜×™×¡×˜×™×§×•×ª ×¨×’×™×œ×•×ª ×œ××©×ª××© ×¨×’×™×œ
            stats = db.get_user_stats(user_id)
            
            if not stats or stats.get('total_files', 0) == 0:
                await update.message.reply_text(
                    "ğŸ“Š ×¢×“×™×™×Ÿ ××™×Ÿ ×œ×š ×§×˜×¢×™ ×§×•×“ ×©××•×¨×™×.\n"
                    "×”×ª×—×œ ×¢× /save!",
                    reply_markup=ReplyKeyboardMarkup(MAIN_KEYBOARD, resize_keyboard=True)
                )
                return
            
            languages_str = ", ".join(stats.get('languages', []))
            last_activity = stats.get('latest_activity')
            last_activity_str = last_activity.strftime('%d/%m/%Y %H:%M') if last_activity else "×œ× ×™×“×•×¢"
            
            response = (
                "ğŸ“Š <b>×”×¡×˜×˜×™×¡×˜×™×§×•×ª ×©×œ×š:</b>\n\n"
                f"ğŸ“ ×¡×”\"×› ×§×‘×¦×™×: <b>{stats['total_files']}</b>\n"
                f"ğŸ”¢ ×¡×”\"×› ×’×¨×¡××•×ª: <b>{stats['total_versions']}</b>\n"
                f"ğŸ’¾ ××’×‘×œ×ª ×§×‘×¦×™×: {config.MAX_FILES_PER_USER}\n\n"
                "ğŸ”¤ <b>×©×¤×•×ª ×‘×©×™××•×©:</b>\n"
                f"{languages_str}\n\n"
                "ğŸ“… <b>×¤×¢×™×œ×•×ª ××—×¨×•× ×”:</b>\n"
                f"{last_activity_str}\n\n"
                "ğŸ’¡ <b>×˜×™×¤:</b> ×”×©×ª××© ×‘×ª×’×™×•×ª ×œ××¨×’×•×Ÿ ×˜×•×‘ ×™×•×ª×¨!"
            )
            
            await update.message.reply_text(response, parse_mode=ParseMode.HTML, reply_markup=ReplyKeyboardMarkup(MAIN_KEYBOARD, resize_keyboard=True))
    
    async def handle_document(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """××˜×¤×œ ×‘×§×‘×¦×™× ×‘×××¦×¢×•×ª DocumentHandler ×”×™×™×¢×•×“×™."""
        message = getattr(update, "effective_message", None)
        if message is None:
            message = getattr(update, "message", None)
        document = getattr(message, "document", None) if message else None

        if document:
            size_limit_bytes = 20 * 1024 * 1024

            if getattr(document, "file_size", None) is not None:
                if document.file_size > 20 * 1024 * 1024:
                    warning_text = (
                        "â—ï¸×”×§×•×‘×¥ ×’×“×•×œ ××“×™.\n"
                        "×”××’×‘×œ×” ×œ×”×¢×œ××ª ×§×‘×¦×™× ×”×™× 20MB. × ×¡×” ×œ×›×•×•×¥ ××• ×œ×—×œ×§ ××ª ×”×§×•×‘×¥."
                    )
                    if message and hasattr(message, "reply_text"):
                        await message.reply_text(warning_text)
                    else:
                        logger.warning("Document rejected: size exceeds 20MB limit")
                    return

            file_size = getattr(document, "file_size", None)

            if file_size is None:
                try:
                    telegram_file = await document.get_file()
                    file_size = getattr(telegram_file, "file_size", None)
                except Exception as exc:
                    logger.warning("Failed to resolve document size: %s", exc)

            if file_size is None:
                warning_text = (
                    "âš ï¸ ×œ× ×”×¦×œ×—×ª×™ ×œ×‘×“×•×§ ××ª ×’×•×“×œ ×”×§×•×‘×¥.\n"
                    "×”××’×‘×œ×” ×œ×”×¢×œ××ª ×§×‘×¦×™× ×”×™× 20MB. ×•×“× ×©×”×§×•×‘×¥ ×§×˜×Ÿ ××”××’×‘×œ×” ×•× ×¡×” ×©×•×‘."
                )
                if message and hasattr(message, "reply_text"):
                    await message.reply_text(warning_text)
                else:
                    logger.warning("Document rejected: unknown size, limit is 20MB")
                return

            if file_size > size_limit_bytes:
                warning_text = (
                    "â—ï¸×”×§×•×‘×¥ ×’×“×•×œ ××“×™.\n"
                    "×”××’×‘×œ×” ×œ×”×¢×œ××ª ×§×‘×¦×™× ×”×™× 20MB. × ×¡×” ×œ×›×•×•×¥ ××• ×œ×—×œ×§ ××ª ×”×§×•×‘×¥."
                )
                if message and hasattr(message, "reply_text"):
                    await message.reply_text(warning_text)
                else:
                    logger.warning("Document rejected: size exceeds 20MB limit")
                return

        await self.document_handler.handle_document(update, context)

    async def handle_text_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×˜×™×¤×•×œ ×‘×”×•×“×¢×•×ª ×˜×§×¡×˜ (×§×•×“ ×¤×•×˜× ×¦×™××œ×™)"""
        if reporter is not None:
            reporter.report_activity(update.effective_user.id)
        await log_user_activity(update, context)
        user_id = update.effective_user.id
        message = getattr(update, "message", None)
        if message is None:
            logger.debug("handle_text_message: update without message, ignoring")
            return
        message_text = getattr(message, "text", None)
        if message_text is None:
            logger.debug("handle_text_message: missing text payload, ignoring")
            return
        text = message_text

        # ××¦×‘ ×—×™×¤×•×© ××™× ×˜×¨××§×˜×™×‘×™ (××•×¤×¢×œ ××”×›×¤×ª×•×¨ "ğŸ” ×—×¤×© ×§×•×‘×¥")
        if context.user_data.get('awaiting_search_text'):
            query_text = (text or '').strip()
            context.user_data.pop('awaiting_search_text', None)

            # ×¤×™×¨×•×§ ×©××™×œ×ª×: ×ª×•××š name:..., lang:..., tag:repo:...
            name_substr = []
            lang_filter = None
            tag_filter = None
            try:
                tokens = [t for t in query_text.split() if t.strip()]
                for t in tokens:
                    lower = t.lower()
                    if lower.startswith('name:'):
                        name_substr.append(t.split(':', 1)[1])
                    elif lower.startswith('lang:'):
                        lang_filter = t.split(':', 1)[1].strip().lower() or None
                    elif lower.startswith('tag:'):
                        tag_filter = t.split(':', 1)[1].strip()
                    elif lower.startswith('repo:'):
                        tag_filter = t.strip()
                    else:
                        # ××•× ×—×™ ×—×™×¤×•×© ×—×•×¤×©×™×™× ×‘×©× ×”×§×•×‘×¥
                        name_substr.append(t)
                name_filter = ' '.join(name_substr).strip()
            except Exception:
                name_filter = query_text

            # ××—×–×•×¨ ×ª×•×¦××•×ª
            from database import db
            # × ×—×¤×© ×‘×‘×¡×™×¡ (×›×•×œ×œ $text), ×•××– × ×¡× ×Ÿ ×œ×¤×™ ×©× ×§×•×‘×¥ ×× ×”×•×’×“×¨ name_filter
            results = db.search_code(
                user_id,
                query=name_filter if name_filter else "",
                programming_language=(lang_filter or ""),
                tags=([tag_filter] if tag_filter else []),
                limit=10000,
            ) or []
            # ×¡×™× ×•×Ÿ ×œ×¤×™ ×©× ×§×•×‘×¥ ×× ×™×© name_filter
            if name_filter:
                try:
                    nf = name_filter.lower()
                    results = [r for r in results if nf in str(r.get('file_name', '')).lower()]
                except Exception:
                    pass

            total = len(results)
            if total == 0:
                await update.message.reply_text(
                    "ğŸ” ×œ× × ××¦××• ×ª×•×¦××•×ª.",
                    reply_to_message_id=update.message.message_id,
                )
                # ××¤×©×¨ ×œ××¤×©×¨ ×—×™×¤×•×© × ×•×¡×£ ××™×“
                context.user_data['awaiting_search_text'] = True
                return

            # ×©××™×¨×ª ×¤×™×œ×˜×¨×™× ×œ×”××©×š ×“×¤×“×•×£
            context.user_data['search_filters'] = {
                'name_filter': name_filter,
                'lang': lang_filter,
                'tag': tag_filter,
            }
            context.user_data['files_origin'] = { 'type': 'search' }

            # ×‘× ×™×™×ª ×¢××•×“ ×¨××©×•×Ÿ
            PAGE_SIZE = 10
            page = 1
            context.user_data['files_last_page'] = page
            start = (page - 1) * PAGE_SIZE
            end = min(start + PAGE_SIZE, total)

            # ×‘× ×™×™×ª ××§×œ×“×ª ×ª×•×¦××•×ª
            from telegram import InlineKeyboardMarkup, InlineKeyboardButton
            keyboard = []
            context.user_data['files_cache'] = {}
            for i in range(start, end):
                item = results[i]
                fname = item.get('file_name', '×§×•×‘×¥')
                lang = item.get('programming_language', 'text')
                button_text = f"ğŸ“„ {fname} ({lang})"
                keyboard.append([InlineKeyboardButton(button_text, callback_data=f"file_{i}")])
                context.user_data['files_cache'][str(i)] = item

            # ×¢×™××•×“
            total_pages = (total + PAGE_SIZE - 1) // PAGE_SIZE if total > 0 else 1
            row = []
            if page > 1:
                row.append(InlineKeyboardButton("â¬…ï¸ ×”×§×•×“×", callback_data=f"search_page_{page-1}"))
            if page < total_pages:
                row.append(InlineKeyboardButton("â¡ï¸ ×”×‘×", callback_data=f"search_page_{page+1}"))
            if row:
                keyboard.append(row)
            keyboard.append([InlineKeyboardButton("ğŸ”™ ×—×–×¨×”", callback_data="files")])

            await update.message.reply_text(
                f"ğŸ” ×ª×•×¦××•×ª ×—×™×¤×•×© â€” ×¡×”×´×›: {total}\n" +
                f"ğŸ“„ ×¢××•×“ {page} ××ª×•×š {total_pages}",
                reply_markup=InlineKeyboardMarkup(keyboard)
            )
            return

        # ×‘×™×˜×•×œ ×—×“-×¤×¢××™ ×©×œ ×”×•×“×¢×ª "× ×¨××” ×©×–×” ×§×˜×¢ ×§×•×“!" (×œ××©×œ ××—×¨×™ ×©××™×¨×ª ×”×¢×¨×” ×œ×’×™×‘×•×™)
        if context.user_data.pop('suppress_code_hint_once', False):
            return
        
        # ×‘×“×™×§×” ×× ×”××©×ª××© ×‘×ª×”×œ×™×š ×©××™×¨×”
        if 'saving_file' in context.user_data:
            await self._save_code_snippet(update, context, text)
            return
        
        # ×–×™×”×•×™ ×× ×–×” × ×¨××” ×›××• ×§×•×“, ×œ××¢×˜ ×‘×–××Ÿ ×–×¨×™××ª "×”×“×‘×§ ×§×•×“" ×©×œ GitHub
        if self._looks_like_code(text) and not (
            context.user_data.get('waiting_for_paste_content') or context.user_data.get('waiting_for_paste_filename')
        ):
            await update.message.reply_text(
                "ğŸ¤” × ×¨××” ×©×–×” ×§×˜×¢ ×§×•×“!\n"
                "×¨×•×¦×” ×œ×©××•×¨ ××•×ª×•? ×”×©×ª××© ×‘/save ××• ×©×œ×— ×©×•×‘ ×¢× ×©× ×§×•×‘×¥.",
                reply_to_message_id=update.message.message_id
            )
        # ×©×œ×‘ ×‘×™× ×™×™× ×œ×§×œ×™×˜×ª ×”×¢×¨×” ××—×¨×™ ×§×•×“
        elif 'saving_file' in context.user_data and context.user_data['saving_file'].get('note_asked') and 'pending_code_buffer' in context.user_data:
            note_text = (text or '').strip()
            if note_text.lower() in {"×“×œ×’", "skip", "×œ×œ×", ""}:
                context.user_data['saving_file']['note_value'] = ""
            else:
                # ×”×’×‘×œ×ª ××•×¨×š ×”×¢×¨×”
                context.user_data['saving_file']['note_value'] = note_text[:280]
            # ×§×¨× ×©×•×‘ ×œ×©××™×¨×” ×‘×¤×•×¢×œ (×ª×“×œ×’ ×¢×œ ×”×©××œ×” ×›×™ note_asked=true)
            await self._save_code_snippet(update, context, context.user_data.get('pending_code_buffer', ''))
    
    async def _save_code_snippet(self, update: Update, context: ContextTypes.DEFAULT_TYPE, code: str):
        """×©××™×¨×” ×‘×¤×•×¢×œ ×©×œ ×§×˜×¢ ×§×•×“"""
        if reporter is not None:
            reporter.report_activity(update.effective_user.id)
        saving_data = context.user_data.pop('saving_file')
        
        if len(code) > config.MAX_CODE_SIZE:
            await update.message.reply_text(
                f"âŒ ×”×§×•×“ ×’×“×•×œ ××“×™! ××§×¡×™××•× {config.MAX_CODE_SIZE} ×ª×•×•×™×."
            )
            return
        
        # ×–×™×”×•×™ ×©×¤×ª ×”×ª×›× ×•×ª ×‘×××¦×¢×•×ª CodeProcessor + ×ª×™×¢×•×“ ××“×•×“
        with track_performance("detect_language"):
            detected_language = code_processor.detect_language(code, saving_data['file_name'])
        logger.info(f"×–×•×”×ª×” ×©×¤×”: {detected_language} ×¢×‘×•×¨ ×”×§×•×‘×¥ {saving_data['file_name']}")
        try:
            emit_event(
                "file_save_detect_language",
                severity="info",
                language=detected_language,
                file_name=saving_data['file_name'],
                size_bytes=len(code.encode('utf-8', errors='replace')),
            )
        except Exception:
            pass
        
        # ×× ×˜×¨× × ×©××¨×” ×”×¢×¨×”, × ×©××œ ×›×¢×ª
        if not saving_data.get('note_asked'):
            saving_data['note_asked'] = True
            context.user_data['saving_file'] = saving_data
            context.user_data['pending_code_buffer'] = code
            await update.message.reply_text(
                "ğŸ“ ×¨×•×¦×” ×œ×”×•×¡×™×£ ×”×¢×¨×” ×§×¦×¨×” ×œ×§×•×‘×¥?\n"
                "×›×ª×•×‘/×›×ª×‘×™ ××•×ª×” ×¢×›×©×™×• ××• ×©×œ×—/×™ '×“×œ×’' ×›×“×™ ×œ×©××•×¨ ×‘×œ×™ ×”×¢×¨×”."
            )
            return

        # ×©×œ×‘ ×©× ×™: ×›×‘×¨ × ×©××œ×” ×”×¢×¨×”, ×‘×“×•×§ ×× ×”×ª×§×‘×œ×”
        note = saving_data.get('note_value') or ""
        if 'pending_code_buffer' in context.user_data:
            code = context.user_data.pop('pending_code_buffer')

        # ×™×¦×™×¨×ª ××•×‘×™×™×§×˜ ×§×˜×¢ ×§×•×“ ×›×•×œ×œ ×”×¢×¨×” (description)
        snippet = CodeSnippet(
            user_id=saving_data['user_id'],
            file_name=saving_data['file_name'],
            code=code,
            programming_language=detected_language,
            description=note,
            tags=saving_data['tags']
        )
        
        # ×©××™×¨×” ×‘××¡×“ ×”× ×ª×•× ×™×
        saved_ok = False
        with track_performance("db_save_code_snippet"):
            saved_ok = db.save_code_snippet(snippet)
        if saved_ok:
            try:
                # Business metric: file saved (size in BYTES, not chars)
                try:
                    size_bytes = len(code.encode("utf-8", errors="replace"))
                except Exception:
                    size_bytes = len(code)  # Fallback
                track_file_saved(user_id=saving_data['user_id'], language=detected_language, size_bytes=size_bytes)
                emit_event(
                    "file_saved",
                    severity="info",
                    user_id=saving_data['user_id'],
                    language=detected_language,
                    size_bytes=size_bytes,
                    file_name=saving_data['file_name'],
                )
            except Exception:
                pass
            await update.message.reply_text(
                f"âœ… × ×©××¨ ×‘×”×¦×œ×—×”!\n\n"
                f"ğŸ“ **{saving_data['file_name']}**\n"
                f"ğŸ”¤ ×©×¤×”: {detected_language}\n"
                f"ğŸ·ï¸ ×ª×’×™×•×ª: {', '.join(saving_data['tags']) if saving_data['tags'] else '×œ×œ×'}\n"
                f"ğŸ“ ×”×¢×¨×”: {note or 'â€”'}\n"
                f"ğŸ“Š ×’×•×“×œ: {len(code)} ×ª×•×•×™×",
                parse_mode=ParseMode.HTML
            )
        else:
            await update.message.reply_text(
                "âŒ ×©×’×™××” ×‘×©××™×¨×”. × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨."
            )
            try:
                if errors_total is not None:
                    errors_total.labels(code="E_SAVE_FAILED").inc()
                emit_event(
                    "file_save_failed",
                    severity="error",
                    user_id=saving_data['user_id'],
                    file_name=saving_data['file_name'],
                )
            except Exception:
                pass
    
    def _looks_like_code(self, text: str) -> bool:
        """×‘×“×™×§×” ×¤×©×•×˜×” ×× ×˜×§×¡×˜ × ×¨××” ×›××• ×§×•×“"""
        code_indicators = [
            'def ', 'function ', 'class ', 'import ', 'from ',
            '){', '};', '<?php', '<html', '<script', 'SELECT ', 'CREATE TABLE'
        ]
        
        return any(indicator in text for indicator in code_indicators) or \
               text.count('\n') > 3 or text.count('{') > 1
    
    def _detect_language(self, filename: str, code: str) -> str:
        """×–×™×”×•×™ ×‘×¡×™×¡×™ ×©×œ ×©×¤×ª ×ª×›× ×•×ª (×™×•×¨×—×‘ ×‘×¢×ª×™×“)"""
        # ×–×™×”×•×™ ×œ×¤×™ ×¡×™×•××ª ×§×•×‘×¥
        extension_map = {
            '.py': 'python',
            '.js': 'javascript',
            '.html': 'html',
            '.css': 'css',
            '.java': 'java',
            '.cpp': 'cpp',
            '.c': 'c',
            '.php': 'php',
            '.rb': 'ruby',
            '.go': 'go',
            '.rs': 'rust',
            '.ts': 'typescript',
            '.sql': 'sql',
            '.sh': 'bash',
            '.json': 'json',
            '.xml': 'xml',
            '.yml': 'yaml',
            '.yaml': 'yaml'
        }
        
        for ext, lang in extension_map.items():
            if filename.lower().endswith(ext):
                return lang
        
        # ×–×™×”×•×™ ×‘×¡×™×¡×™ ×œ×¤×™ ×ª×•×›×Ÿ
        if 'def ' in code or 'import ' in code:
            return 'python'
        elif 'function ' in code or 'var ' in code or 'let ' in code:
            return 'javascript'
        elif '<?php' in code:
            return 'php'
        elif '<html' in code or '<!DOCTYPE' in code:
            return 'html'
        elif 'SELECT ' in code.upper() or 'CREATE TABLE' in code.upper():
            return 'sql'
        
        return 'text'  # ×‘×¨×™×¨×ª ××—×“×œ
    
    async def error_handler(self, update: object, context: ContextTypes.DEFAULT_TYPE):
        """×˜×™×¤×•×œ ×‘×©×’×™××•×ª"""
        logger.error(f"×©×’×™××”: {context.error}", exc_info=context.error)

        # ×–×™×”×•×™ ×—×¨×™×’×ª ×–×™×›×¨×•×Ÿ (×’×œ×•×‘×œ×™)
        try:
            err = context.error
            err_text = str(err) if err else ""
            is_oom = isinstance(err, MemoryError) or (
                isinstance(err_text, str) and (
                    'Ran out of memory' in err_text or 'out of memory' in err_text.lower() or 'MemoryError' in err_text
                )
            )
            if is_oom:
                # × ×¡×” ×œ×¦×¨×£ ×¡×˜×˜×•×¡ ×–×™×›×¨×•×Ÿ
                mem_status = ""
                try:
                    from utils import get_memory_usage  # import ××§×•××™ ×œ×× ×™×¢×ª ×ª×œ×•×ª ×‘×–××Ÿ ×‘×“×™×§×•×ª
                    mu = get_memory_usage()
                    mem_status = f" (RSS={mu.get('rss_mb')}MB, VMS={mu.get('vms_mb')}MB, %={mu.get('percent')})"
                except Exception:
                    pass
                # Alert Pipeline Consolidation: ×©×œ×— ×”×ª×¨××” ×“×¨×š internal_alerts (×•×œ× DM ×™×©×™×¨ ×‘×‘×•×˜)
                try:
                    try:
                        from internal_alerts import emit_internal_alert  # type: ignore
                    except Exception:
                        emit_internal_alert = None  # type: ignore
                    if emit_internal_alert is not None:
                        emit_internal_alert(
                            "bot_oom",
                            severity="critical",
                            summary=f"ğŸš¨ OOM ×–×•×”×ª×” ×‘×‘×•×˜{mem_status}. ×—×¨×™×’×”: {err_text[:500]}",
                            source="main.error_handler",
                            error_message=err_text[:2000],
                            memory_status=mem_status,
                        )
                except Exception:
                    pass
        except Exception:
            pass

        if isinstance(update, Update) and update.effective_message:
            await update.effective_message.reply_text(
                "âŒ ××™×¨×¢×” ×©×’×™××”. ×× × × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨."
            )
    
    async def start(self):
        """×”×¤×¢×œ×ª ×”×‘×•×˜"""
        logger.info("××ª×—×™×œ ××ª ×”×‘×•×˜...")
        await self.application.initialize()
        await self.application.start()
        await self.application.updater.start_polling()
        
        logger.info("×”×‘×•×˜ ×¤×•×¢×œ! ×œ×—×¥ Ctrl+C ×œ×”×¤×¡×§×”.")
    
    async def stop(self):
        """×¢×¦×™×¨×ª ×”×‘×•×˜"""
        logger.info("×¢×•×¦×¨ ××ª ×”×‘×•×˜...")
        await self.application.updater.stop()
        await self.application.stop()
        await self.application.shutdown()
        
        # ×©×—×¨×•×¨ × ×¢×™×œ×” ×•×¡×’×™×¨×ª ×—×™×‘×•×¨ ×œ××¡×“ × ×ª×•× ×™× (××•×’×Ÿ ××›×¤×œ×•×ª)
        try:
            already_done = getattr(self, "_lock_cleanup_done", False)
        except Exception:
            already_done = False
        if not already_done:
            success = False
            try:
                success = bool(cleanup_mongo_lock())
            except Exception:
                success = False
            if success:
                try:
                    setattr(self, "_lock_cleanup_done", True)
                except Exception:
                    pass
        db.close()
        
        logger.info("×”×‘×•×˜ × ×¢×¦×¨.")

def signal_handler(signum, frame):
    """×˜×™×¤×•×œ ×‘×¡×™×’× ×œ×™ ×¢×¦×™×¨×”"""
    logger.info(f"×”×ª×§×‘×œ ×¡×™×’× ×œ {signum}, ×¢×•×¦×¨ ××ª ×”×‘×•×˜...")
    sys.exit(0)

# ---------------------------------------------------------------------------
# Helper to register the basic command handlers with the Application instance.
# ---------------------------------------------------------------------------


def setup_handlers(application: Application, db_manager):  # noqa: D401
    """Register basic command handlers required for the bot to operate."""

    async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):  # noqa: D401
        user_id = update.effective_user.id
        username = update.effective_user.username
        
        # ×©××•×¨ ××©×ª××© ×‘××¡×“ × ×ª×•× ×™× (INSERT OR IGNORE)
        db_manager.save_user(user_id, username)
        
        if reporter is not None:
            reporter.report_activity(user_id)
        await log_user_activity(update, context)  # ×”×•×¡×¤×ª ×¨×™×©×•× ××©×ª××© ×œ×¡×˜×˜×™×¡×˜×™×§×•×ª
        
        # ×‘×“×™×§×” ×× ×”××©×ª××© ×”×’×™×¢ ××”-Web App ××• ×¨×•×¦×” ×œ×”×•×¡×™×£ ×§×•×‘×¥
        if context.args and len(context.args) > 0:
            if context.args[0] == "add_file":
                # ×”××©×ª××© ×¨×•×¦×” ×œ×”×•×¡×™×£ ×§×•×‘×¥ ×—×“×©
                reply_markup = ReplyKeyboardMarkup(MAIN_KEYBOARD, resize_keyboard=True)
                await update.message.reply_text(
                    "ğŸ“ <b>×”×•×¡×¤×ª ×§×•×‘×¥ ×—×“×©</b>\n\n"
                    "×©×œ×— ×œ×™ ×§×•×‘×¥ ×§×•×“ ××• ×˜×§×¡×˜ ×›×“×™ ×œ×©××•×¨ ××•×ª×•.\n"
                    "××¤×©×¨ ×œ×©×œ×•×—:\n"
                    "â€¢ ×§×•×‘×¥ ×‘×•×“×“ ××• ××¡×¤×¨ ×§×‘×¦×™×\n"
                    "â€¢ ×§×•×‘×¥ ZIP ×¢× ××¡×¤×¨ ×§×‘×¦×™×\n"
                    "â€¢ ×”×•×“×¢×ª ×˜×§×¡×˜ ×¢× ×§×•×“\n\n"
                    "ğŸ’¡ ×˜×™×¤: ××¤×©×¨ ×œ×”×•×¡×™×£ ×ª×™××•×¨ ×œ×§×•×‘×¥ ×‘×›×™×ª×•×‘ (caption)",
                    reply_markup=reply_markup,
                    parse_mode=ParseMode.HTML
                )
                return
            elif context.args[0] == "webapp_login":
                # ×™×¦×™×¨×ª ×§×™×©×•×¨ ×”×ª×—×‘×¨×•×ª ××™×©×™
                webapp_url = os.getenv('WEBAPP_URL', 'https://code-keeper-webapp.onrender.com')
                
                # ×™×¦×™×¨×ª ×˜×•×§×Ÿ ×–×× ×™ ×œ××™××•×ª (××¤×©×¨ ×œ×”×©×ª××© ×‘-JWT ××• hash ×¤×©×•×˜)
                import hashlib
                import time
                timestamp = int(time.time())
                secret = os.getenv('SECRET_KEY', 'dev-secret-key')
                token_data = f"{user_id}:{timestamp}:{secret}"
                auth_token = hashlib.sha256(token_data.encode()).hexdigest()[:32]
                
                # ×©××™×¨×ª ×”×˜×•×§×Ÿ ×‘××¡×“ × ×ª×•× ×™× ×¢× ×ª×•×§×£ ×©×œ 5 ×“×§×•×ª
                db = db_manager.get_db()
                db.webapp_tokens.insert_one({
                    'token': auth_token,
                    'user_id': user_id,
                    'username': username,
                    'created_at': datetime.now(timezone.utc),
                    'expires_at': datetime.now(timezone.utc) + timedelta(minutes=5)
                })
                
                # ×™×¦×™×¨×ª ×§×™×©×•×¨ ×”×ª×—×‘×¨×•×ª
                login_url = f"{webapp_url}/auth/token?token={auth_token}&user_id={user_id}"
                
                keyboard = [
                    [InlineKeyboardButton("ğŸ” ×”×ª×—×‘×¨ ×œ-Web App", url=login_url)],
                    [InlineKeyboardButton("ğŸŒ ×¤×ª×— ××ª ×”-Web App", url=webapp_url)]
                ]
                reply_markup_inline = InlineKeyboardMarkup(keyboard)
                
                await update.message.reply_text(
                    "ğŸ” <b>×§×™×©×•×¨ ×”×ª×—×‘×¨×•×ª ××™×©×™ ×œ-Web App</b>\n\n"
                    "×œ×—×¥ ×¢×œ ×”×›×¤×ª×•×¨ ×œ××˜×” ×›×“×™ ×œ×”×ª×—×‘×¨:\n\n"
                    "âš ï¸ <i>×”×§×™×©×•×¨ ×ª×§×£ ×œ-5 ×“×§×•×ª ×‘×œ×‘×“ ××˜×¢××™ ××‘×˜×—×”</i>",
                    reply_markup=reply_markup_inline,
                    parse_mode=ParseMode.HTML
                )
                return
        
        reply_markup = ReplyKeyboardMarkup(MAIN_KEYBOARD, resize_keyboard=True)
        await update.message.reply_text(
            "ğŸ¤– ×©×œ×•× ×•×‘×¨×•×š ×”×‘× ×œ×‘×•×˜ ×©×•××¨ ×”×§×•×“ ×”××ª×§×“×!\n\n"
            "ğŸ”¹ ×©××•×¨ ×•× ×”×œ ×§×˜×¢×™ ×§×•×“ ×‘×—×›××”\n"
            "ğŸ”¹ ×¢×¨×™×›×” ××ª×§×“××ª ×¢× ×’×¨×¡××•×ª\n"
            "ğŸ”¹ ×—×™×¤×•×© ×•×”×¦×’×” ×—×›××”\n"
            "ğŸ”¹ ×”×•×¨×“×” ×•× ×™×”×•×œ ××œ×\n"
            "ğŸ”¹ ×”×¢×œ××ª ×§×‘×¦×™× ×œ-GitHub\n\n"
            "âœ¨ ×—×“×© ×‘×‘×•×˜: \n"
            "â€¢ ğŸŒ ××™× ×™-WebApp - ×›×¤×ª×•×¨ ×‘×¤×™× ×” ×”×©×××œ×™×ª ×œ××˜×”\n"
            "  ×”×›×™ × ×•×— ×œ×¦×¤×™×™×” ×•×”×¢×ª×§×” ×©×œ ×§×•×“ ××¨×•×š (×¢×“ ×¢×©×¨×•×ª ××œ×¤×™ ×©×•×¨×•×ª)\n\n"
            "â€¢ ğŸ—ƒ ××•×¡×£ ×”×§×”×™×œ×” - ×’×œ×• ×›×œ×™×, ×•×‘×•×˜×™× ×©×‘× ×• ××©×ª××©×™× ××—×¨×™×\n"
            "  ×•××ª× ××•×–×× ×™× ×œ×©×ª×£ ××ª ×”×¤×¨×•×™×§×˜×™× ×©×œ×›× ×•×œ×”×¦×˜×¨×£ ×œ××•×¡×£\n\n"
            "â€¢ ×œ×¨×©×™××ª ×¤×§×•×“×•×ª ×œ×œ× ×›×¤×ª×•×¨×™× - ×©×œ×—×• /help\n\n"
            "ğŸ”§ ×ª×§×œ×” ×‘×‘×•×˜? ×›×ª×‘×• ×œ-@moominAmir",
            reply_markup=reply_markup
        )

    async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):  # noqa: D401
        if reporter is not None:
            reporter.report_activity(update.effective_user.id)
        await log_user_activity(update, context)  # ×”×•×¡×¤×ª ×¨×™×©×•× ××©×ª××© ×œ×¡×˜×˜×™×¡×˜×™×§×•×ª
        ctx_app = getattr(context, "application", None)
        ctx_commands = _get_registered_commands(ctx_app) if ctx_app else set()
        if ctx_commands:
            commands = ctx_commands
        else:
            commands = _get_registered_commands(application)
        try:
            from chatops.permissions import is_admin as _is_admin
            user_id = int(getattr(getattr(update, "effective_user", None), "id", 0) or 0)
            user_is_admin = bool(_is_admin(user_id))
        except Exception:
            user_is_admin = False
        text = _build_help_message(commands, is_admin=user_is_admin)
        try:
            for chunk in _split_long_message(text):
                await update.message.reply_text(chunk, parse_mode=ParseMode.HTML, disable_web_page_preview=True)
        except Exception:
            plain_text = (
                text.replace("<b>", "")
                .replace("</b>", "")
                .replace("<code>", "")
                .replace("</code>", "")
                .replace("&lt;", "<")
                .replace("&gt;", ">")
            )
            for chunk in _split_long_message(plain_text, max_len=3900):
                await update.message.reply_text(chunk, disable_web_page_preview=True)

    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("help", help_command))


# ---------------------------------------------------------------------------
# New lock-free main
# ---------------------------------------------------------------------------
def main() -> None:
    """
    Initializes and runs the bot after acquiring a lock.
    """
    try:
        # Initialize database first
        global db
        # ×”×©×ª××© ×‘-DatabaseManager ×”×’×œ×•×‘×œ×™ (database.db) ×›×“×™ ×œ× ×œ×™×¦×•×¨ instance ×—×“×©
        from database import db as _db  # type: ignore
        db = _db
        
        # MongoDB connection and lock management
        if not manage_mongo_lock():
            logger.warning("Another bot instance is already running. Exiting gracefully.")
            # ×™×¦×™××” × ×§×™×™×” ×œ×œ× ×©×’×™××”
            sys.exit(0)

        # --- ×”××©×š ×”×§×•×“ ×”×§×™×™× ×©×œ×š ---
        logger.info("Lock acquired. Initializing CodeKeeperBot...")
        
        # × ×©×ª××© ×‘××™× ×¡×˜× ×¡ ×§×™×™× ×× ×›×‘×¨ × ×•×¦×¨ (×œ××©×œ ×¢"×™ ×˜×¡×˜), ××—×¨×ª × ×™×¦×•×¨ ×—×“×©
        bot = CURRENT_BOT or CodeKeeperBot()
        
        logger.info("Bot is starting to poll...")
        # Cache warming: ×”×¤×¢×œ×ª ×¢×‘×•×“×” ×¨×§×¢ ×§×¦×¨×” ×œ××ª×—×•×œ ×§××© ×¢×‘×•×¨ ××©×ª××©×™×/×ª×¤×¨×™×˜×™× × ×¤×•×¦×™×
        try:
            async def _warm_cache(_ctx):
                try:
                    from database import db as _db
                    users: list[int] = []
                    try:
                        # ×§×¨× ××–×”×™ ××©×ª××©×™× ×¤×¢×™×œ×™× ××—×¨×•× ×™× (best-effort)
                        coll = getattr(_db, 'db', None)
                        coll = getattr(coll, 'users', None)
                        rows_obj = None
                        if coll is not None and hasattr(coll, 'find'):
                            try:
                                rows_obj = coll.find({}, {"user_id": 1})
                                # ×× ×™×© limit ×¢×œ ×”××•×‘×™×™×§×˜ (Cursor), ×”×©×ª××© ×‘×•, ××—×¨×ª × ××™×¨ ×œ×¨×©×™××” ×•× ×—×ª×•×š
                                if hasattr(rows_obj, 'limit'):
                                    rows_obj = rows_obj.limit(10)
                            except Exception:
                                rows_obj = []
                        if rows_obj is None:
                            rows_obj = []
                        rows_list = list(rows_obj)
                        for r in rows_list[:10]:
                            uid = r.get('user_id') if isinstance(r, dict) else None
                            if isinstance(uid, int):
                                users.append(uid)
                    except Exception:
                        users = []
                    # ×—×× ×¨×©×™××•×ª ×§×‘×¦×™× ×•×©××•×ª ×œ×§×•××‘×•×¡/××•×˜×•×§×•××¤×œ×™×˜
                    for uid in users[:10]:
                        try:
                            _ = _db.get_user_files(uid, limit=50)
                        except Exception:
                            pass
                        try:
                            _ = _db.get_user_file_names(uid, limit=200)
                        except Exception:
                            pass
                        try:
                            _ = _db.get_repo_tags_with_counts(uid, max_tags=50)
                        except Exception:
                            pass
                except Exception:
                    return
            # ×”×¨×¦×” ×œ××—×¨ ×¢×œ×™×™×” ×›×“×™ ×œ× ×œ×¢×›×‘ startup
            try:
                bot.application.job_queue.run_once(_warm_cache, when=2)
            except Exception:
                pass
        except Exception:
            pass
        # Start polling. In tests, run_polling may exist either on the
        # application or directly on the bot stub. Support both to avoid
        # AttributeError in minimal fakes.
        _app = getattr(bot, "application", None)
        _run_poll_app = getattr(_app, "run_polling", None)
        if callable(_run_poll_app):
            # ×¨×™×›×•×š ×”×ª×•×¤×¢×” ×©×œ 409 Conflict ×‘×’×œ×œ "×’×™×”×•×§×™×" ×‘×¨×©×ª:
            # - ××¢×œ×™× read/write/connect/pool timeouts (×‘-builder) + ××’×“×™×œ×™× ×’× ××ª long-poll timeout ×›××Ÿ.
            # - ××¤×¢×™×œ×™× ×¨×§ ×¤×¨××˜×¨×™× ×©×§×™×™××™× ×‘×¤×•×¢×œ ×‘×’×¨×¡×ª PTB (×‘×××¦×¢×•×ª inspect.signature).
            def _env_float(name: str, default: float) -> float:
                try:
                    v = os.getenv(name)
                    if v is None:
                        return float(default)
                    v = str(v).strip()
                    if not v:
                        return float(default)
                    return float(v)
                except Exception:
                    return float(default)

            def _env_int(name: str, default: int) -> int:
                try:
                    v = os.getenv(name)
                    if v is None:
                        return int(default)
                    v = str(v).strip()
                    if not v:
                        return int(default)
                    return int(float(v))
                except Exception:
                    return int(default)

            connect_timeout = _env_float("TELEGRAM_CONNECT_TIMEOUT_SECS", 10.0)
            pool_timeout = _env_float("TELEGRAM_POOL_TIMEOUT_SECS", 10.0)
            write_timeout = _env_float("TELEGRAM_WRITE_TIMEOUT_SECS", 30.0)
            read_timeout = _env_float("TELEGRAM_READ_TIMEOUT_SECS", 30.0)
            poll_interval = _env_float("TELEGRAM_POLL_INTERVAL_SECS", 0.0)
            long_poll_timeout = _env_int("TELEGRAM_LONG_POLL_TIMEOUT_SECS", 20)
            conflict_backoff = _env_int("TELEGRAM_CONFLICT_BACKOFF_SECS", 30)
            conflict_max_retries = _env_int("TELEGRAM_CONFLICT_MAX_RETRIES", 5)
            conflict_max_seconds = _env_int("TELEGRAM_CONFLICT_MAX_SECONDS", 300)

            # Ensure read_timeout is safely above the long poll timeout
            try:
                if float(read_timeout) <= float(long_poll_timeout) + 2.0:
                    read_timeout = float(long_poll_timeout) + 5.0
            except Exception:
                pass

            poll_kwargs = {
                "drop_pending_updates": True,
                "poll_interval": float(poll_interval),
                "timeout": int(long_poll_timeout),
                "read_timeout": float(read_timeout),
                "write_timeout": float(write_timeout),
                "connect_timeout": float(connect_timeout),
                "pool_timeout": float(pool_timeout),
            }

            def _call_with_supported_kwargs(fn, kwargs: dict[str, Any]):
                """
                Call fn(**kwargs) but only pass supported keyword args.

                ×—×©×•×‘: ×œ× "×œ×‘×œ×•×¢" ×—×¨×™×’×•×ª ×©×œ fn (×œ××©×œ Conflict). ×œ×›×Ÿ ×× ×—× ×• ×ª×•×¤×¡×™× ×—×¨×™×’×•×ª
                *×¨×§* ××”××™× ×˜×•×¨×¡×¤×§×¦×™×” ×©×œ inspect.signature, ×•×œ× ××”×§×¨×™××” ×¢×¦××”.
                """
                supported = kwargs
                try:
                    sig = inspect.signature(fn)
                    # ×× ×”×¤×•× ×§×¦×™×” ××§×‘×œ×ª **kwargs, ×ª×¢×‘×™×¨ ×”×›×œ (×–×” ×”××§×¨×” ×‘×”×¨×‘×” stubs/tests)
                    if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in sig.parameters.values()):
                        supported = kwargs
                    else:
                        supported = {k: v for k, v in kwargs.items() if k in sig.parameters}
                except (TypeError, ValueError):
                    # signature ×œ× ×–××™×Ÿ (builtins/partials/monkeypatch) â€“ × × ×¡×” ×œ×”×¢×‘×™×¨ ×”×›×œ
                    supported = kwargs
                return fn(**supported)

            # Best-effort swallow & backoff on Conflict (×× ×–×” × ×–×¨×§ ×”×—×•×¦×”)
            try:
                from telegram.error import Conflict as _TgConflict  # type: ignore
            except Exception:  # pragma: no cover
                _TgConflict = None  # type: ignore

            conflict_tries = 0
            conflict_started_at: float | None = None
            while True:
                try:
                    _call_with_supported_kwargs(_run_poll_app, poll_kwargs)
                    break
                except Exception as _e:
                    is_conflict = False
                    try:
                        if _TgConflict is not None and isinstance(_e, _TgConflict):
                            is_conflict = True
                        elif "terminated by other getupdates request" in str(_e).lower():
                            is_conflict = True
                    except Exception:
                        is_conflict = False
                    if not is_conflict:
                        raise
                    # Persistent conflicts likely mean another long-lived poller (or webhook) is active.
                    # Don't retry forever: release lock via finally and let the orchestrator recover.
                    try:
                        conflict_tries += 1
                        if conflict_started_at is None:
                            conflict_started_at = time.time()
                        elapsed = float(time.time() - conflict_started_at)
                    except Exception:
                        elapsed = 0.0

                    # conflict_tries × ×¡×¤×¨ ×›"×›××” ×¤×¢××™× ×›×‘×¨ ×§×™×‘×œ× ×• Conflict" (×›×•×œ×œ ×”×¤×¢× ×”×¨××©×•× ×”).
                    # ×›×“×™ ×©-CONFLICT_MAX_RETRIES ×™×ª× ×”×’ ×›"××¡×¤×¨ retries ××—×¨×™ ×”-Conflict ×”×¨××©×•×Ÿ",
                    # ×× ×—× ×• ×™×•×¦××™× ×¨×§ ×›×©×¢×‘×¨× ×• ××ª ×”×ª×§×¨×” (>) ×•×œ× ×›×©×©×•×•×™× ×œ×”.
                    hit_retry_cap = bool(conflict_max_retries > 0 and conflict_tries > conflict_max_retries)
                    hit_time_cap = bool(conflict_max_seconds > 0 and elapsed >= float(conflict_max_seconds))
                    if hit_retry_cap or hit_time_cap:
                        logger.error(
                            "Persistent Telegram getUpdates Conflict; exiting to release lock and allow recovery. "
                            f"tries={conflict_tries} elapsed={elapsed:.1f}s max_retries={conflict_max_retries} "
                            f"max_seconds={conflict_max_seconds} last_err={_e}"
                        )
                        try:
                            emit_event(
                                "telegram_polling_conflict_persistent",
                                severity="error",
                                tries=int(conflict_tries),
                                elapsed_seconds=float(elapsed),
                                max_retries=int(conflict_max_retries),
                                max_seconds=int(conflict_max_seconds),
                                error=str(_e)[:500],
                            )
                        except Exception:
                            pass
                        raise SystemExit(1)
                    logger.warning(
                        f"Telegram getUpdates Conflict detected; backing off for {conflict_backoff}s and retrying. err={_e}"
                    )
                    try:
                        emit_event(
                            "telegram_polling_conflict_backoff",
                            severity="warn",
                            backoff_seconds=int(conflict_backoff),
                            error=str(_e)[:500],
                        )
                    except Exception:
                        pass
                    time.sleep(max(5, int(conflict_backoff)))
        else:
            _run_poll_bot = getattr(bot, "run_polling", None)
            if callable(_run_poll_bot):
                _run_poll_bot(drop_pending_updates=True)
            else:
                logger.warning("run_polling not available on application or bot; skipping.")
        
    except Exception as e:
        logger.error(f"×©×’×™××”: {e}")
        raise
    finally:
        logger.info("Bot polling stopped. Releasing lock and closing database connection.")
        try:
            cleanup_mongo_lock()
        except Exception:
            pass
        if 'db' in globals():
            db.close_connection()
        # Scheduler/Webapp thread-safety: close the scheduler-dedicated Mongo clients (best-effort)
        try:
            app_obj = bot if "bot" in locals() else None
            # CodeKeeperBot ×©×•××¨ ××ª PTB Application ×ª×—×ª bot.application
            app = getattr(app_obj, "application", None) or app_obj
            bot_data = getattr(app, "bot_data", None)
            if isinstance(bot_data, dict):
                motor_client = bot_data.get("_scheduler_motor_client")
                if motor_client is not None and hasattr(motor_client, "close"):
                    motor_client.close()
                pymongo_client = bot_data.get("_scheduler_pymongo_client")
                if pymongo_client is not None and hasattr(pymongo_client, "close"):
                    pymongo_client.close()
                # × ×™×§×•×™ best-effort ×›×“×™ ×œ×× ×•×¢ ×©×™××•×© ×—×•×–×¨ ×‘××•×‘×™×™×§×˜×™× ×¡×’×•×¨×™×
                try:
                    bot_data.pop("_scheduler_motor_client", None)
                    bot_data.pop("_scheduler_motor_db", None)
                    bot_data.pop("_scheduler_pymongo_client", None)
                    bot_data.pop("_scheduler_motor_lock", None)
                except Exception:
                    pass
        except Exception:
            pass


# A minimal post_init stub to comply with the PTB builder chain
async def setup_bot_data(application: Application) -> None:  # noqa: D401
    """A post_init function to setup application-wide data."""
    # ××—×™×§×ª ×›×œ ×”×¤×§×•×“×•×ª ×”×¦×™×‘×•×¨×™×•×ª (××™×Ÿ ×œ×”×’×“×™×¨ /share /share_help â€” ×©×™×ª×•×£ ×“×¨×š ×”×›×¤×ª×•×¨×™×)
    await application.bot.delete_my_commands()
    logger.info("âœ… Public commands cleared (no /share, /share_help)")

    # ×¨×™×©×•× ×›×œ ×”-Background Jobs ×‘××¢×¨×›×ª (Jobs Monitor)
    try:
        from services.register_jobs import register_all_jobs

        register_all_jobs()
    except Exception:
        # Fail-open: ××œ ×ª×›×©×™×œ startup ×× ××•×“×•×œ ×”× ×™×˜×•×¨ ×œ× ×–××™×Ÿ
        pass

    # Scheduler: "×¦×™× ×•×¨" MongoDB × ×¤×¨×“ ×œ-thread ×©×œ ×”-bot/scheduler, ×›×“×™ ×œ× ×œ×—×œ×•×§ Pool ×¢× ×”-Webapp.
    def _scheduler_db_disabled() -> bool:
        try:
            return str(os.getenv("DISABLE_DB", "") or "").strip().lower() in {"1", "true", "yes", "on"}
        except Exception:
            return False

    async def _get_scheduler_motor_db(app: Application):
        """Motor DB ×¤×¨×˜×™ ×œ-scheduler (best-effort)."""
        if _scheduler_db_disabled():
            return None
        mongo_url = (os.getenv("MONGODB_URL") or "").strip()
        if not mongo_url:
            return None
        db_name = (os.getenv("DATABASE_NAME") or "code_keeper_bot").strip() or "code_keeper_bot"

        try:
            from motor.motor_asyncio import AsyncIOMotorClient  # type: ignore
        except Exception:
            return None

        bot_data = getattr(app, "bot_data", None)
        if not isinstance(bot_data, dict):
            return None

        existing_db = bot_data.get("_scheduler_motor_db")
        if existing_db is not None:
            return existing_db

        # ×”×’× ×” ××¤× ×™ race: ×©×ª×™ coroutines ×™×›×•×œ×•×ª ×œ×”×’×™×¢ ×œ×›××Ÿ ×‘××§×‘×™×œ ×•×œ×”×“×œ×™×£ client "×™×ª×•×"
        lock = bot_data.get("_scheduler_motor_lock")
        if lock is None or not isinstance(lock, asyncio.Lock):
            lock = asyncio.Lock()
            bot_data["_scheduler_motor_lock"] = lock

        async with lock:
            # Double-check ××—×¨×™ ×”× ×¢×™×œ×”
            existing_db = bot_data.get("_scheduler_motor_db")
            if existing_db is not None:
                return existing_db

            try:
                client = AsyncIOMotorClient(mongo_url)
                db_obj = client[db_name]

                # ×©××™×¨×” ×œ×¤× ×™ await ×›×“×™ ×œ×× ×•×¢ "×™×ª×•×" ×‘××§×¨×” ×©×œ interleave
                bot_data["_scheduler_motor_client"] = client
                bot_data["_scheduler_motor_db"] = db_obj

                # Best-effort ping: ×œ× ×—×™×™×‘, ×¨×§ sanity check ×§×¦×¨
                try:
                    await asyncio.wait_for(client.admin.command("ping"), timeout=2.0)
                except Exception:
                    pass

                return db_obj
            except Exception:
                # ×× ××©×”×• × ×›×©×œ ××—×¨×™ ×™×¦×™×¨×” ×—×œ×§×™×ª, × × ×§×” best-effort
                try:
                    maybe_client = bot_data.pop("_scheduler_motor_client", None)
                    bot_data.pop("_scheduler_motor_db", None)
                    if maybe_client is not None and hasattr(maybe_client, "close"):
                        maybe_client.close()
                except Exception:
                    pass
                return None

    def _get_scheduler_pymongo_client(app: Application):
        """PyMongo client ×¤×¨×˜×™ ×œ-APScheduler jobstore (best-effort)."""
        if _scheduler_db_disabled():
            return None
        mongo_url = (os.getenv("MONGODB_URL") or "").strip()
        if not mongo_url:
            return None
        try:
            from pymongo import MongoClient  # type: ignore
        except Exception:
            return None

        bot_data = getattr(app, "bot_data", None)
        if not isinstance(bot_data, dict):
            return None

        existing = bot_data.get("_scheduler_pymongo_client")
        if existing is not None:
            return existing

        try:
            client = MongoClient(mongo_url, serverSelectionTimeoutMS=3000)
            bot_data["_scheduler_pymongo_client"] = client
            return client
        except Exception:
            return None

    # Jobs Monitor: ×–×™×”×•×™ ×”×¨×¦×•×ª "×ª×§×•×¢×•×ª" (job_stuck)
    try:
        from datetime import timedelta as _td
        from observability import emit_event as _emit  # type: ignore

        async def _jobs_stuck_monitor(_context: ContextTypes.DEFAULT_TYPE):  # noqa: ARG001
            try:
                db_obj = await _get_scheduler_motor_db(_context.application)
                if db_obj is None:
                    return

                try:
                    threshold_min = int(os.getenv("JOBS_STUCK_THRESHOLD_MINUTES", "20") or 20)
                except Exception:
                    threshold_min = 20
                threshold_min = max(1, threshold_min)

                now = datetime.now(timezone.utc)
                cutoff = now - _td(minutes=threshold_min)

                coll = getattr(db_obj, "job_runs", None)
                if coll is None or not hasattr(coll, "find"):
                    return

                # emit only once per run (stuck_reported_at gate)
                cursor = coll.find(
                    {
                        "status": "running",
                        "started_at": {"$lt": cutoff},
                        "stuck_reported_at": {"$exists": False},
                    },
                    {"run_id": 1, "job_id": 1, "started_at": 1},
                ).sort("started_at", 1).limit(50)

                try:
                    docs = await cursor.to_list(length=50)
                except Exception:
                    docs = []

                for doc in list(docs or []):
                    run_id = str(doc.get("run_id") or "").strip()
                    job_id = str(doc.get("job_id") or "").strip()
                    started_at = doc.get("started_at")
                    minutes = None
                    try:
                        if started_at:
                            minutes = int(max(1, (now - started_at).total_seconds() // 60))
                    except Exception:
                        minutes = None

                    if not run_id or not job_id:
                        continue

                    # mark + append log (keep last 50)
                    try:
                        await coll.update_one(
                            {"run_id": run_id, "stuck_reported_at": {"$exists": False}},
                            {
                                "$set": {"stuck_reported_at": now},
                                "$push": {
                                    "logs": {
                                        "$each": [
                                            {
                                                "timestamp": now,
                                                "level": "error",
                                                "message": "Job stuck detected",
                                                "details": {"minutes": minutes} if minutes is not None else None,
                                            }
                                        ],
                                        "$slice": -50,
                                    }
                                },
                            },
                            upsert=False,
                        )
                    except Exception:
                        pass

                    _emit(
                        "job_stuck",
                        severity="error",
                        job_id=job_id,
                        run_id=run_id,
                        minutes=int(minutes or threshold_min),
                    )
            except Exception:
                return

        try:
            interval = int(os.getenv("JOBS_STUCK_MONITOR_INTERVAL_SECS", "60") or 60)
        except Exception:
            interval = 60
        interval = max(30, interval)
        application.job_queue.run_repeating(
            _jobs_stuck_monitor,
            interval=interval,
            first=30,
            name="jobs_stuck_monitor",
        )
    except Exception:
        # Fail-open
        pass

    # Job Triggers Processor: ×¢×™×‘×•×“ ×‘×§×©×•×ª trigger ××”-Webapp
    try:
        async def _process_pending_job_triggers(context: ContextTypes.DEFAULT_TYPE):
            """××¢×‘×“ ×‘×§×©×•×ª trigger ×©× ×•×¦×¨×• ×“×¨×š ×”-Webapp ×•××¤×¢×™×œ ××ª ×”×’'×•×‘×™×."""
            try:
                db_obj = await _get_scheduler_motor_db(context.application)
                if db_obj is None:
                    logger.debug("pending_job_triggers: DB not available or noop")
                    return

                coll = getattr(db_obj, "job_trigger_requests", None)
                if coll is None or not hasattr(coll, "find"):
                    logger.debug("pending_job_triggers: collection not available")
                    return

                now = datetime.now(timezone.utc)
                # ××—×¤×© ×›×œ ×‘×§×©×•×ª pending - ×œ×œ× cutoff ×›×“×™ ×œ× ×œ××‘×“ ×‘×§×©×•×ª ×× ×”×‘×•×˜ ×”×™×” ×œ××˜×”
                # ×‘×§×©×•×ª ×™×©× ×•×ª ×××•×“ (××¢×œ ×©×¢×”) ×™×¡×•×× ×• ×›-expired ×‘××§×•× ×œ×”×ª×¢×œ× ××”×Ÿ
                from datetime import timedelta as _td_trigger
                expire_cutoff = now - _td_trigger(hours=1)

                # ×¡×™××•×Ÿ ×‘×§×©×•×ª ×™×©× ×•×ª ××“×™ ×›-expired
                try:
                    expired_result = await coll.update_many(
                        {"status": "pending", "created_at": {"$lt": expire_cutoff}},
                        {"$set": {"status": "expired", "error": "Request expired (bot was unavailable for >1h)"}},
                    )
                    if expired_result.modified_count > 0:
                        logger.info("pending_job_triggers: expired %d old requests", expired_result.modified_count)
                except Exception as exp_err:
                    logger.debug("pending_job_triggers: expire update failed: %s", exp_err)

                cursor = coll.find({"status": "pending"}).sort("created_at", 1).limit(10)
                try:
                    pending_list = await cursor.to_list(length=10)
                except Exception:
                    pending_list = []
                if pending_list:
                    logger.info("pending_job_triggers: found %d pending requests", len(pending_list))

                for doc in pending_list:
                    trigger_id = doc.get("trigger_id")
                    job_id = doc.get("job_id")
                    if not trigger_id or not job_id:
                        logger.warning("pending_job_triggers: skipping doc with missing trigger_id/job_id")
                        continue

                    logger.info("pending_job_triggers: processing trigger_id=%s job_id=%s", trigger_id, job_id)

                    # ×¡×™××•×Ÿ ×›-processing ×›×“×™ ×œ×× ×•×¢ ×¢×™×‘×•×“ ×›×¤×•×œ
                    result = await coll.update_one(
                        {"trigger_id": trigger_id, "status": "pending"},
                        {"$set": {"status": "processing", "processed_at": now}},
                    )
                    if result.modified_count == 0:
                        logger.debug("pending_job_triggers: trigger %s already processed", trigger_id)
                        continue  # ×›×‘×¨ ×¢×•×‘×“/×¢×‘×¨ ×¢×™×‘×•×“

                    try:
                        # ×—×™×¤×•×© ×”×’'×•×‘ ×‘-JobQueue ×•×”×¤×¢×œ×ª×•
                        jq = context.application.job_queue
                        if jq is None:
                            raise RuntimeError("job_queue_unavailable")

                        jobs = jq.get_jobs_by_name(job_id)
                        logger.debug("pending_job_triggers: get_jobs_by_name(%s) returned %d jobs", job_id, len(jobs) if jobs else 0)

                        if not jobs:
                            # × ×™×¡×™×•×Ÿ ×œ××¦×•× callback ×™×©×™×¨×•×ª ××”-JobRegistry
                            all_job_names = [getattr(j, "name", "?") for j in (jq.jobs() if hasattr(jq, "jobs") else [])]
                            logger.warning(
                                "pending_job_triggers: job_not_found job_id=%s available_jobs=%s",
                                job_id,
                                all_job_names[:20]
                            )
                            raise RuntimeError(f"job_not_found: {job_id}")

                        job_obj = jobs[0]
                        callback = getattr(job_obj, "callback", None)
                        if not callable(callback):
                            raise RuntimeError(f"callback_not_callable: {job_id}")

                        # ×”×¤×¢×œ×ª ×”×’'×•×‘ ××™×™×“×™×ª
                        suffix = str(int(time.time()))
                        data = getattr(job_obj, "data", None)
                        chat_id = getattr(job_obj, "chat_id", None)
                        user_id = getattr(job_obj, "user_id", None)
                        kwargs = {"when": 0, "name": f"{job_id}_webapp_trigger_{suffix}"}
                        if data is not None:
                            kwargs["data"] = data
                        if chat_id is not None:
                            kwargs["chat_id"] = chat_id
                        if user_id is not None:
                            kwargs["user_id"] = user_id

                        logger.info("pending_job_triggers: running job %s via run_once", job_id)
                        jq.run_once(callback, **kwargs)

                        # ×¢×“×›×•×Ÿ ×¡×˜×˜×•×¡ ×œ×”×¦×œ×—×”
                        await coll.update_one(
                            {"trigger_id": trigger_id},
                            {"$set": {"status": "completed", "result": "triggered"}},
                        )
                        logger.info("pending_job_triggers: SUCCESS trigger_id=%s job_id=%s", trigger_id, job_id)

                    except Exception as e:
                        # ×¢×“×›×•×Ÿ ×¡×˜×˜×•×¡ ×œ×›×™×©×œ×•×Ÿ
                        await coll.update_one(
                            {"trigger_id": trigger_id},
                            {"$set": {"status": "failed", "error": str(e)}},
                        )
                        logger.warning("pending_job_triggers: FAILED trigger_id=%s job_id=%s error=%s", trigger_id, job_id, e)

            except Exception as outer_err:
                logger.error("pending_job_triggers: outer exception: %s", outer_err)
                return

        # ×©×™×›×•×š ×›××‘×™×: polling ××™×˜×™ ×™×•×ª×¨ ×›×“×™ ×œ×”×¤×—×™×ª ×¢×•××¡ ×¢×œ Mongo ×‘×¨×©×ª ××™×˜×™×ª/latency ×’×‘×•×”×”
        # ×‘×¨×™×¨×ª ××—×“×œ: 60 ×©× ×™×•×ª (× ×™×ª×Ÿ ×œ×©×™× ×•×™ ×“×¨×š ENV)
        try:
            interval = int(os.getenv("JOB_TRIGGERS_POLL_INTERVAL_SECS", "60") or 60)
        except Exception:
            interval = 60
        interval = max(60, interval)
        application.job_queue.run_repeating(
            _process_pending_job_triggers,
            interval=interval,
            first=10,
            name="pending_job_triggers",
        )
        logger.info("âœ… Pending job triggers processor registered (every %ds)", interval)
    except Exception:
        # Fail-open
        pass

    # ×”×’×“×¨×ª JobStore ××ª××™×“ ×œ-APScheduler (MongoDB) ×× ××¤×©×¨×™
    try:
        jq = getattr(application, "job_queue", None)
        scheduler = getattr(jq, "scheduler", None)
        if scheduler is not None:
            client = _get_scheduler_pymongo_client(application)
            db_name = (os.getenv("DATABASE_NAME") or "code_keeper_bot").strip() or "code_keeper_bot"
            # ××œ ×ª×’×“×™×¨ ×›×©××™×Ÿ ×—×™×‘×•×¨
            if client is not None and db_name:
                try:
                    # ×”×•×¡×£ JobStore ×‘×©× 'persistent' ×œ×©×™××•×© ×¢"×™ ××©×™××•×ª ×”×’×™×‘×•×™
                    scheduler.add_jobstore(
                        'mongodb',
                        alias='persistent',
                        client=client,
                        database=db_name,
                        collection=os.getenv('APSCHEDULER_COLLECTION', 'scheduler_jobs'),
                    )
                    logger.info("âœ… APScheduler persistent jobstore registered (MongoDB)")
                except Exception as e:  # pragma: no cover â€” failâ€‘open ×‘×¡×‘×™×‘×•×ª ×˜×¡×˜/×œ×œ× DB
                    logger.warning(f"APS persistent jobstore not available: {e}")
    except Exception:
        # Fail-open: ××™×Ÿ ×œ×”×¤×™×œ ××ª ×”-setup ×× ×©×›×‘×ª APScheduler ××™× ×” ×–××™× ×”
        pass
    
    # ×”×’×“×¨×ª ×¤×§×•×“×ª stats ×¨×§ ×œ×× ×”×œ (×××™×¨ ×‘×™×¨×•×Ÿ)
    AMIR_ID = 6865105071  # ×”-ID ×©×œ ×××™×¨ ×‘×™×¨×•×Ÿ
    
    try:
        # ×”×’×“×¨ ×¨×§ ××ª ×¤×§×•×“×ª stats ×œ×××™×¨
        await application.bot.set_my_commands(
            commands=[
                BotCommand("stats", "ğŸ“Š ×¡×˜×˜×™×¡×˜×™×§×•×ª ×©×™××•×©"),
            ],
            scope=BotCommandScopeChat(chat_id=AMIR_ID)
        )
        logger.info(f"âœ… Commands set for Amir (ID: {AMIR_ID}): stats only")
    except Exception as e:
        logger.error(f"âš ï¸ Error setting admin commands: {e}")

    # ×¤×œ×™×˜×ª ××™×¨×•×¢ ××•×§×“××ª: × ×™×§×•×™ ×’×™×‘×•×™×™× â€” ×ª××™×›×” ×‘××¦×‘×™ ×˜×¡×˜
    # × ×©×ª××© ×‘×™×™×‘×•× ×“×™× ××™ ×›×“×™ ×œ×©×ª×£ ×¤×¢×•×œ×” ×¢× monkeypatch ×‘×˜×¡×˜×™×
    try:
        enabled_env = str(os.getenv("BACKUPS_CLEANUP_ENABLED", "false")).lower()
        enabled = enabled_env in {"1", "true", "yes", "on"}
        if not enabled:
            try:
                from observability import emit_event as _emit
            except Exception:  # pragma: no cover
                _emit = None
            if _emit is not None:
                _emit("backups_cleanup_disabled", severity="info")
            else:
                try:
                    emit_event("backups_cleanup_disabled", severity="info")
                except Exception:
                    pass
        else:
            # ×›××©×¨ ××•×¤×¢×œ (enabled) ×•×‘×¡×‘×™×‘×ª ×˜×¡×˜×™×, × ×¤×¢×™×œ ×¤×¢× ××—×ª ××™×“×™×ª ×›×“×™ ×œ×”×‘×˜×™×— ×¤×œ×™×˜×ª ××™×¨×•×¢
            try:
                if os.getenv("PYTEST_CURRENT_TEST"):
                    try:
                        from file_manager import backup_manager as _bm
                    except Exception:  # pragma: no cover
                        _bm = None
                    if _bm is not None:
                        try:
                            summary = _bm.cleanup_expired_backups()
                            try:
                                from observability import emit_event as _emit
                            except Exception:  # pragma: no cover
                                _emit = (lambda *a, **k: None)
                            _emit(
                                "backups_cleanup_done",
                                severity="info",
                                fs_scanned=int((summary or {}).get("fs_scanned", 0) or 0),
                                fs_deleted=int((summary or {}).get("fs_deleted", 0) or 0),
                                gridfs_scanned=int((summary or {}).get("gridfs_scanned", 0) or 0),
                                gridfs_deleted=int((summary or {}).get("gridfs_deleted", 0) or 0),
                            )
                        except Exception:
                            try:
                                from observability import emit_event as _emit
                            except Exception:  # pragma: no cover
                                _emit = (lambda *a, **k: None)
                            _emit("backups_cleanup_error", severity="anomaly")
            except Exception:
                pass
    except Exception:
        # Fail-open: ××™×Ÿ ×œ×”×¤×™×œ ××ª ×”-setup ×× ×©×›×‘×ª observability ×œ× ×–××™× ×”
        pass
    
    # ×”×¤×¢×œ×ª ×©×¨×ª ×§×˜×Ÿ ×œ-/health ×•-/share/<id> â€” ×›×‘×•×™ ×›×‘×¨×™×¨×ª ××—×“×œ
    enable_internal_web = str(os.getenv('ENABLE_INTERNAL_SHARE_WEB', 'false')).lower() == 'true'
    if enable_internal_web and config.PUBLIC_BASE_URL:
        try:
            from services.webserver import create_app
            aiohttp_app = create_app()
            async def _start_web_job(context: ContextTypes.DEFAULT_TYPE):
                # Jobs Monitor trigger support: ×©××•×¨ reference ×œ-Application ×‘×ª×•×š aiohttp app
                try:
                    aiohttp_app["telegram_application"] = context.application
                except Exception:
                    pass
                runner = web.AppRunner(aiohttp_app)
                await runner.setup()
                port = int(os.getenv("PORT", "10000"))
                site = web.TCPSite(runner, host="0.0.0.0", port=port)
                await site.start()
                logger.info(f"ğŸŒ Internal web server started on :{port}")
                try:
                    try:
                        from observability import emit_event as _emit
                    except Exception:  # pragma: no cover
                        _emit = lambda *a, **k: None
                    _emit("internal_web_started", severity="info", port=int(port))
                except Exception:
                    pass
            # ×œ×”×¨×™×¥ ××—×¨×™ ×©×”××¤×œ×™×§×¦×™×” ×”×ª×—×™×œ×”, ×›×“×™ ×œ×”×™×× ×¢ ×-PTBUserWarning
            result = application.job_queue.run_once(_start_web_job, when=0)
            # ×‘×¡×‘×™×‘×ª ×˜×¡×˜×™×, ×”-run_once ×¢×©×•×™ ×œ×”×—×–×™×¨ create_task; × ××ª×™×Ÿ ×œ×• ×›×“×™ ×œ×”×‘×˜×™×— ×©×”××™×¨×•×¢ ×™×•×¤×§
            try:
                import asyncio as _asyncio
                if _asyncio.isfuture(result) or _asyncio.iscoroutine(result):
                    await result
                    # Double-emit defensively for tests that expect the event synchronously
                    try:
                        try:
                            from observability import emit_event as _emit
                        except Exception:  # pragma: no cover
                            _emit = lambda *a, **k: None
                        _emit("internal_web_started", severity="info", port=int(os.getenv("PORT", "10000")))
                    except Exception:
                        pass
                else:
                    # ×× ××™×Ÿ Future ×œ×—×›×•×ª ×œ×•, ×”×¤×§ ××™×¨×•×¢ "start" ×‘××•×¤×Ÿ ××™×˜×‘×™ ×›×“×™ ×œ× ×œ×¤×¡×¤×¡ ×‘×˜×¡×˜×™×
                    try:
                        port_guess = int(os.getenv("PORT", "10000"))
                        emit_event("internal_web_started", severity="info", port=port_guess)
                    except Exception:
                        pass
            except Exception:
                pass
        except Exception as e:
            logger.error(f"âš ï¸ Failed to start internal web server: {e}")
            try:
                emit_event("internal_web_start_failed", severity="error", error=str(e))
            except Exception:
                pass
    else:
        logger.info("â„¹ï¸ Skipping internal web server (disabled or missing PUBLIC_BASE_URL)")

    # Register reminders feature (handlers + scheduler)
    try:
        from reminders.handlers import setup_reminder_handlers  # type: ignore
        from reminders.scheduler import setup_reminder_scheduler  # type: ignore
        # ×©××•×¨ db_manager ×‘-bot_data ×›×“×™ ×©-reminders ×™×©×ª××© ×‘××•×ª×• ×—×™×‘×•×¨ DB
        try:
            if 'db' in globals():
                application.bot_data['db_manager'] = db  # type: ignore[name-defined]
        except Exception:
            pass
        setup_reminder_handlers(application)
        setup_reminder_scheduler(application)
        logger.info("âœ… Reminders registered")
    except Exception as e:
        logger.warning(f"Reminders init skipped: {e}")

    # Reschedule Google Drive backup jobs for all users with an active schedule
    try:
        async def _reschedule_drive_jobs(context: ContextTypes.DEFAULT_TYPE):
            from services.job_tracker import get_job_tracker, JobAlreadyRunningError

            tracker = get_job_tracker()
            stats = {"total": 0, "recreated": 0, "scanned": 0, "skipped": 0}

            try:
                trigger = (
                    str(((getattr(getattr(context, "job", None), "data", None) or {}) or {}).get("trigger") or "scheduled")
                    .strip()
                    .lower()
                )
            except Exception:
                trigger = "scheduled"

            # × ×©×ª××© ×‘-track ×›×“×™ ×œ×©××¨ fail/skip × ×›×•×Ÿ
            try:
                with tracker.track("drive_reschedule", trigger=trigger) as run:
                    drive_handler, handler_restored = get_drive_handler_from_application(context.application)
                    if not drive_handler:
                        logger.warning("drive_reschedule_jobs_skip reason=no_drive_handler")
                        tracker.skip_run(run.run_id, "no_drive_handler")
                        return
                    if handler_restored:
                        try:
                            logger.warning("drive_reschedule_handler_restored source=application_attr")
                        except Exception:
                            pass
                        try:
                            emit_event("drive_reschedule_handler_restored", severity="info", source="application_attr")
                        except Exception:
                            pass
                    # ××ª×¨ ××ª ×× ×”×œ ×”-DB: ×¢×“×™×¤×•×ª ×œ×× ×”×œ ×©× ×©××¨ ×‘-bot_data, ××—×¨ ×›×š ×™×™×‘×•× ×™×©×™×¨
                    db_manager = context.application.bot_data.get('db_manager')
                    if not db_manager:
                        try:
                            from database import db as module_db  # type: ignore
                            db_manager = module_db
                        except Exception:
                            pass
                    if not db_manager:
                        # fallback: ×”××•×¤×¢ ×”××§×•××™ ×©× ×•×¦×¨ ×‘-main (×× ×–××™×Ÿ ×‘×¡×§×•×¤)
                        try:
                            db_manager = db
                        except Exception:
                            pass
                    if not db_manager:
                        logger.warning("drive_reschedule_jobs_skip reason=no_db_manager")
                        tracker.skip_run(run.run_id, "no_db_manager")
                        return
                    # Use the new Repository method to get users with active schedules
                    sched_keys = {"daily", "every3", "weekly", "biweekly", "monthly"}
                    users_docs = []
                    try:
                        get_users_fn = getattr(db_manager, 'get_users_with_active_drive_schedule', None)
                        if callable(get_users_fn):
                            users_docs = get_users_fn()
                            logger.info(
                                "drive_reschedule_via_repo users_found=%s",
                                len(users_docs),
                            )
                        else:
                            # Fallback to direct collection access if method not available
                            logger.warning("drive_reschedule_fallback_to_direct reason=method_missing")
                            cand_db = getattr(db_manager, 'db', None)
                            users_coll = getattr(cand_db, 'users', None) if cand_db else None
                            if users_coll and hasattr(users_coll, 'find'):
                                wide_query = {"drive_prefs": {"$exists": True, "$ne": None}}
                                users_docs = list(users_coll.find(wide_query, {"user_id": 1, "drive_prefs": 1}))
                                logger.info(
                                    "drive_reschedule_direct_query users_found=%s",
                                    len(users_docs),
                                )
                            else:
                                logger.warning("drive_reschedule_jobs_skip reason=no_users_collection")
                                tracker.skip_run(run.run_id, "no_users_collection")
                                return
                    except Exception as exc:
                        logger.warning("drive_reschedule_jobs_query_failed error=%s", exc)
                        users_docs = []
                    for doc in users_docs:
                        try:
                            uid = int(doc.get("user_id") or 0)
                            if not uid:
                                stats["skipped"] += 1
                                continue
                            stats["scanned"] += 1
                            prefs = doc.get("drive_prefs") or {}
                            key = drive_extract_schedule_key(prefs)
                            if not key:
                                stats["skipped"] += 1
                                continue
                            key = str(key).strip().lower()
                            if key not in sched_keys:
                                stats["skipped"] += 1
                                continue
                            stats["total"] += 1
                            recreated = False
                            ensure_fn = getattr(drive_handler, "ensure_schedule_job_if_missing", None)
                            if callable(ensure_fn):
                                recreated = bool(await ensure_fn(context, uid, key))
                            else:
                                await drive_handler._ensure_schedule_job(context, uid, key)
                                recreated = True
                            if recreated:
                                stats["recreated"] += 1
                        except Exception:
                            stats["skipped"] += 1
                            continue
                    # âœ… ×©×™××•×© × ×›×•×Ÿ ×‘-run.run_id
                    try:
                        tracker.add_log(
                            run.run_id,
                            "info",
                            f"drive_reschedule_jobs_run total={stats['total']} recreated={stats['recreated']} scanned={stats['scanned']} skipped={stats['skipped']}",
                        )
                    except Exception:
                        pass
                    try:
                        tracker.complete_run(run.run_id, result=dict(stats))
                    except Exception:
                        pass
            except JobAlreadyRunningError:
                try:
                    tracker.record_skipped(job_id="drive_reschedule", trigger=trigger, reason="already_running")
                except Exception:
                    pass
                return

            # ×œ×•×’×™× ×•××™×¨×•×¢×™× ×›×œ×œ×™×™× â€“ × ×©××¨×™× ××—×•×¥ ×œ-track ×›×“×™ ×œ× ×œ×”×¡×ª×‘×š ×¢× skip_run ×©××¡×™×¨ ××”-active
            try:
                logger.info(
                    "drive_reschedule_jobs_run total=%s recreated=%s scanned=%s skipped=%s",
                    stats["total"],
                    stats["recreated"],
                    stats["scanned"],
                    stats["skipped"],
                )
            except Exception:
                pass
            try:
                emit_event(
                    "drive_reschedule_jobs_run",
                    severity="info",
                    total=int(stats["total"]),
                    recreated=int(stats["recreated"]),
                    scanned=int(stats["scanned"]),
                    skipped=int(stats["skipped"]),
                )
            except Exception:
                pass

        def _safe_run_once(callback, *, when: int, name: str, grace: int) -> None:
            try:
                application.job_queue.run_once(
                    callback,
                    when=when,
                    name=name,
                    job_kwargs={"misfire_grace_time": grace},
                )
            except TypeError:
                application.job_queue.run_once(callback, when=when, name=name)
            except Exception as exc:
                logger.warning("Failed to schedule %s: %s", name, exc)

        def _safe_run_repeating(callback, *, interval: int, first: int, name: str, grace: int) -> None:
            try:
                application.job_queue.run_repeating(
                    callback,
                    interval=interval,
                    first=first,
                    name=name,
                    job_kwargs={"misfire_grace_time": grace},
                )
            except TypeError:
                application.job_queue.run_repeating(callback, interval=interval, first=first, name=name)
            except Exception as exc:
                logger.warning("Failed to schedule %s: %s", name, exc)

        bootstrap_delay = int(os.getenv("DRIVE_RESCHEDULE_BOOTSTRAP_DELAY", "5") or 5)
        keepalive_interval = int(os.getenv("DRIVE_RESCHEDULE_INTERVAL", "900") or 900)
        keepalive_first = int(os.getenv("DRIVE_RESCHEDULE_FIRST_DELAY", "60") or 60)

        _safe_run_once(
            _reschedule_drive_jobs,
            when=bootstrap_delay,
            name="drive_reschedule_bootstrap",
            grace=30,
        )
        _safe_run_repeating(
            _reschedule_drive_jobs,
            interval=max(keepalive_interval, 300),
            first=max(keepalive_first, 30),
            name="drive_reschedule",
            grace=60,
        )
    except Exception:
        logger.warning("Failed to schedule Drive jobs rescan keepalive")

    # Weekly admin report (usage summary) â€” scheduled with JobQueue
    try:
        async def _weekly_admin_report(context: ContextTypes.DEFAULT_TYPE):
            from services.job_tracker import get_job_tracker, JobAlreadyRunningError

            tracker = get_job_tracker()
            try:
                trigger = (
                    str(((getattr(getattr(context, "job", None), "data", None) or {}) or {}).get("trigger") or "scheduled")
                    .strip()
                    .lower()
                )
            except Exception:
                trigger = "scheduled"

            try:
                with tracker.track("weekly_admin_report", trigger=trigger) as run:
                    # ××¤×©×¨ ×œ×›×‘×•×ª ×‘×“×•×—×•×ª ×©×‘×•×¢×™×™× ×œ×—×œ×•×˜×™×Ÿ ×“×¨×š ENV
                    if str(os.getenv("DISABLE_WEEKLY_REPORTS", "")).lower() in {"1", "true", "yes"}:
                        tracker.skip_run(run.run_id, "disabled_by_env")
                        return

                    # ×× ×’× ×•×Ÿ ×”×©×ª×§×” ×©×‘×•×¢×™ (idempotent): ×©×œ×— ×¤×¢× ××—×ª ×œ×›×œ ×©×‘×•×¢ ×§×œ× ×“×¨×™
                    should_send = True
                    try:
                        from datetime import datetime, timezone as _tz
                        from database import db as _dbm
                        db_obj = getattr(_dbm, 'db', None)
                        is_noop_db = (getattr(db_obj, 'name', '') == 'noop_db') if db_obj is not None else True
                        if not is_noop_db and db_obj is not None:
                            admin_reports = getattr(db_obj, 'admin_reports', None)
                            if admin_reports is not None:
                                now = datetime.now(_tz.utc)
                                iso = now.isocalendar()
                                week_key = f"{iso[0]}-{iso[1]:02d}"
                                res = admin_reports.update_one(
                                    {"_id": "weekly_admin_report", "week_key": {"$ne": week_key}},
                                    {"$set": {"week_key": week_key, "last_sent_at": now}},
                                    upsert=True,
                                )
                                modified = int(getattr(res, 'modified_count', 0) or 0)
                                upserted = getattr(res, 'upserted_id', None)
                                should_send = bool(modified or upserted)
                    except Exception:
                        # ×‘××§×¨×” ×©×œ ×›×©×œ ×‘×’×™×™×˜×™× ×’, × ××©×™×š ×œ×©×œ×•×— (×¢×“×™×£ ×“×™×•×•×— ×¢×œ ×›×¤×™×œ×•×ª ×××©×¨ ××™×‘×•×“ ×“×™×•×•×—)
                        should_send = True
                    if not should_send:
                        tracker.skip_run(run.run_id, "already_sent_this_week")
                        return

                    total_users = 0
                    active_week = 0
                    try:
                        general = user_stats.get_all_time_stats()
                        weekly = user_stats.get_weekly_stats() or []
                        active_week = int(len(weekly))
                        if isinstance(general, dict):
                            total_users = int(general.get("total_users", 0) or 0)
                    except Exception:
                        pass
                    text = (
                        "ğŸ“Š ×“×•""×— ×©×‘×•×¢×™ â€” CodeBot\n\n"
                        f"ğŸ‘¥ ××©×ª××©×™× ×¨×©×•××™×: {total_users}\n"
                        f"ğŸ—“ï¸ ×¤×¢×™×œ×™× ×‘×©×‘×•×¢ ×”××—×¨×•×Ÿ: {active_week}\n"
                    )
                    await notify_admins(context, text)
                    tracker.add_log(run.run_id, "info", f"Weekly report sent total_users={total_users} active_week={active_week}")
                    # Emit via a dynamic import to cooperate with test monkeypatching
                    try:
                        try:
                            from observability import emit_event as _emit
                        except Exception:  # pragma: no cover
                            _emit = lambda *a, **k: None
                        _emit("weekly_report_sent", severity="info", total_users=total_users, active_week=active_week)
                    except Exception:
                        pass
            except JobAlreadyRunningError:
                try:
                    tracker.record_skipped(job_id="weekly_admin_report", trigger=trigger, reason="already_running")
                except Exception:
                    pass
                return
            # ×—×¨×™×’×•×ª ×× ×•×”×œ×•×ª ×¢"×™ ×”-context manager

        # Run weekly; first run after a short delay to avoid startup contention
        when_seconds = int(os.getenv("WEEKLY_REPORT_DELAY_SECS", "3600") or 3600)
        try:
            application.job_queue.run_repeating(
                _weekly_admin_report,
                interval=7 * 24 * 3600,
                first=when_seconds,
                name="weekly_admin_report",
            )
        except Exception:
            # In restricted test environments, schedule may fail due to event loop state.
            # Fallback: run once immediately with a minimal context stub to avoid attribute errors.
            class _Ctx:
                bot = None  # notify_admins will no-op safely if bot is missing
            await _weekly_admin_report(_Ctx())
    except Exception:
        pass

    # Background cleanup jobs (Phase 2): cache maintenance and backups retention
    try:
        async def _cache_maintenance_job(context: ContextTypes.DEFAULT_TYPE):
            from services.job_tracker import get_job_tracker, JobAlreadyRunningError

            tracker = get_job_tracker()
            # Trigger resolution (scheduled/manual/api)
            try:
                trigger = (
                    str(((getattr(getattr(context, "job", None), "data", None) or {}) or {}).get("trigger") or "scheduled")
                    .strip()
                    .lower()
                )
            except Exception:
                trigger = "scheduled"
            try:
                with tracker.track("cache_maintenance", trigger=trigger) as run:
                    try:
                        # ×›×™×‘×•×™ ×’×œ×•×‘×œ×™ ×“×¨×š ENV
                        if str(os.getenv("DISABLE_BACKGROUND_CLEANUP", "")).lower() in {"1", "true", "yes"}:
                            tracker.skip_run(run.run_id, "disabled_by_env")
                            return
                        # × ×™×§×•×™ ×¢×“×™×Ÿ ×©×œ ×§××© (respect SAFE_MODE/DISABLE_CACHE_MAINTENANCE internally)
                        from cache_manager import cache  # lazy import
                        # × ×™×ª×Ÿ ×œ×©×œ×•×˜ ×‘×¤×¨××˜×¨×™× ×“×¨×š ENV
                        max_scan = int(os.getenv("CACHE_MAINT_MAX_SCAN", "1000") or 1000)
                        ttl_thr = int(os.getenv("CACHE_MAINT_TTL_THRESHOLD", "60") or 60)
                        deleted = int(cache.clear_stale(max_scan=max_scan, ttl_seconds_threshold=ttl_thr) or 0)
                        tracker.add_log(run.run_id, "info", f"Cache maintenance deleted={deleted}")
                        if deleted > 0:
                            try:
                                from observability import emit_event as _emit
                            except Exception:  # pragma: no cover
                                _emit = lambda *a, **k: None
                            _emit("cache_maintenance_done", severity="info", deleted=int(deleted))
                    except Exception as e:
                        try:
                            from observability import emit_event as _emit
                        except Exception:  # pragma: no cover
                            _emit = lambda *a, **k: None
                        _emit("cache_maintenance_error", severity="anomaly", error=str(e))
                        raise
            except JobAlreadyRunningError:
                try:
                    tracker.record_skipped(job_id="cache_maintenance", trigger=trigger, reason="already_running")
                except Exception:
                    pass
                return

        # ×ª×–××•×Ÿ ×ª×—×–×•×§×ª ×§××© â€“ ×›×œ 10 ×“×§×•×ª, ×”×ª×—×œ×” ××—×¨×™ 30 ×©× ×™×•×ª
        try:
            interval_secs = int(os.getenv("CACHE_MAINT_INTERVAL_SECS", "600") or 600)
            first_secs = int(os.getenv("CACHE_MAINT_FIRST_SECS", "30") or 30)
            application.job_queue.run_repeating(
                _cache_maintenance_job,
                interval=max(60, interval_secs),
                first=max(0, first_secs),
                name="cache_maintenance",
            )
        except Exception:
            # ×‘×¡×‘×™×‘×•×ª ××•×’×‘×œ×•×ª (×›××• ×˜×¡×˜×™×) ×”×ª×–××•×Ÿ ×¢×©×•×™ ×œ×”×›×©×œ â€” × ×¨×™×¥ ×¤×¢× ××—×ª ××™×“×™×ª
            class _CtxMaint:
                def __init__(self, app):
                    self.application = app
            try:
                await _cache_maintenance_job(_CtxMaint(application))
            except Exception:
                pass
        # ×”×¢×¨×”: ×œ× × ×¤×¢×™×œ ×”×¨×¦×” ×›×¤×•×œ×” ×›××©×¨ ×”×ª×–××•×Ÿ ××¦×œ×™×—
        # ×›×“×™ ×œ×× ×•×¢ ×¤×œ×™×§×•×ª ×‘×˜×¡×˜×™×/×¡×™×™×“-××¤×§×˜×™× ×›×¤×•×œ×™×. ×”×¨×¦×” ×—×“-×¤×¢××™×ª
        # ××ª×‘×¦×¢×ª ×¨×§ ×‘-fallback ×›××©×¨ ×”×ª×–××•×Ÿ × ×›×©×œ.

        async def _backups_cleanup_job(context: ContextTypes.DEFAULT_TYPE):
            from services.job_tracker import get_job_tracker, JobAlreadyRunningError

            tracker = get_job_tracker()
            try:
                trigger = (
                    str(((getattr(getattr(context, "job", None), "data", None) or {}) or {}).get("trigger") or "scheduled")
                    .strip()
                    .lower()
                )
            except Exception:
                trigger = "scheduled"

            # ğŸ”’ Singleton Jobs: ×× ×›×‘×¨ ×¨×¥, ×“×œ×’ (SKIPPED) ×‘××§×•× ×œ×”×™×—×©×‘ ×›-failure
            try:
                with tracker.track("backups_cleanup", trigger=trigger) as run:
                    try:
                        # ×›×™×‘×•×™ ×’×œ×•×‘×œ×™ ×“×¨×š ENV
                        if str(os.getenv("DISABLE_BACKGROUND_CLEANUP", "")).lower() in {"1", "true", "yes"}:
                            tracker.skip_run(run.run_id, "disabled_by_env")
                            return
                        from file_manager import backup_manager  # lazy import
                        summary = backup_manager.cleanup_expired_backups()
                        tracker.add_log(
                            run.run_id,
                            "info",
                            f"Cleaned {summary.get('fs_deleted', 0)} files, scanned {summary.get('fs_scanned', 0)}",
                        )
                        try:
                            from observability import emit_event as _emit
                        except Exception:  # pragma: no cover
                            _emit = lambda *a, **k: None
                        _emit(
                            "backups_cleanup_done",
                            severity="info",
                            fs_scanned=int(summary.get("fs_scanned", 0) or 0),
                            fs_deleted=int(summary.get("fs_deleted", 0) or 0),
                            gridfs_scanned=int(summary.get("gridfs_scanned", 0) or 0),
                            gridfs_deleted=int(summary.get("gridfs_deleted", 0) or 0),
                        )
                    except Exception as e:
                        try:
                            from observability import emit_event as _emit
                        except Exception:  # pragma: no cover
                            _emit = lambda *a, **k: None
                        _emit("backups_cleanup_error", severity="anomaly", error=str(e))
                        raise
            except JobAlreadyRunningError:
                try:
                    tracker.record_skipped(job_id="backups_cleanup", trigger=trigger, reason="already_running")
                except Exception:
                    pass
                return

        # ×ª×–××•×Ÿ × ×™×§×•×™ ×’×™×‘×•×™×™× â€“ ×›×‘×•×™ ×›×‘×¨×™×¨×ª ××—×“×œ; ×™×•×¤×¢×œ ×¨×§ ×× BACKUPS_CLEANUP_ENABLED=true
        try:
            enabled = str(os.getenv("BACKUPS_CLEANUP_ENABLED", "false")).lower() in {"1", "true", "yes", "on"}
            if enabled:
                # ×‘×¡×‘×™×‘×ª ×˜×¡×˜×™×: ×”×¤×¢×œ × ×™×§×•×™ ×¤×¢× ××—×ª ××™×“×™×ª ×›×“×™ ×œ×”×‘×˜×™×— ×¤×œ×™×˜×ª ××™×¨×•×¢,
                # ×œ×œ× ×ª×œ×•×ª ×‘××•×–×¨×•×™×•×ª ×©×œ ×œ×•×œ××•×ª asyncio ×‘×¡×™××•×œ×¦×™×” ×©×œ ×”-JobQueue
                try:
                    if os.getenv("PYTEST_CURRENT_TEST"):
                        try:
                            from file_manager import backup_manager as _bm
                        except Exception:  # pragma: no cover
                            _bm = None
                        if _bm is not None:
                            try:
                                summary = _bm.cleanup_expired_backups()
                                try:
                                    from observability import emit_event as _emit
                                except Exception:  # pragma: no cover
                                    _emit = (lambda *a, **k: None)
                                _emit(
                                    "backups_cleanup_done",
                                    severity="info",
                                    fs_scanned=int((summary or {}).get("fs_scanned", 0) or 0),
                                    fs_deleted=int((summary or {}).get("fs_deleted", 0) or 0),
                                    gridfs_scanned=int((summary or {}).get("gridfs_scanned", 0) or 0),
                                    gridfs_deleted=int((summary or {}).get("gridfs_deleted", 0) or 0),
                                )
                            except Exception:
                                try:
                                    from observability import emit_event as _emit
                                except Exception:  # pragma: no cover
                                    _emit = (lambda *a, **k: None)
                                _emit("backups_cleanup_error", severity="anomaly")
                except Exception:
                    # ×œ× × ×™×ª×Ÿ/×œ× × ×“×¨×© ×‘×¡×‘×™×‘×” ×–×• â€” × ××©×™×š ×œ×ª×–××•×Ÿ ×”×¨×’×™×œ
                    pass
                interval_secs = int(os.getenv("BACKUPS_CLEANUP_INTERVAL_SECS", "86400") or 86400)
                first_secs = int(os.getenv("BACKUPS_CLEANUP_FIRST_SECS", "180") or 180)
                try:
                    application.job_queue.run_repeating(
                        _backups_cleanup_job,
                        interval=max(3600, interval_secs),
                        first=max(0, first_secs),
                        name="backups_cleanup",
                    )
                except Exception:
                    # ×‘×¡×‘×™×‘×•×ª ××•×’×‘×œ×•×ª (×›××• ×˜×¡×˜×™×) ×”×ª×–××•×Ÿ ×¢×©×•×™ ×œ×”×›×©×œ â€” × ×¨×™×¥ ×¤×¢× ××—×ª ××™×“×™×ª
                    class _CtxBkp:
                        def __init__(self, app):
                            self.application = app
                    try:
                        await _backups_cleanup_job(_CtxBkp(application))
                    except Exception:
                        pass
                else:
                    # ×‘×¡×‘×™×‘×•×ª ×˜×¡×˜×™×, ×”×‘×˜×—×ª ×××™×ª×•×ª: ×”×¤×¢×œ ×”×¨×¦×” ×—×“-×¤×¢××™×ª ×›×“×™ ×œ×¤×œ×•×˜ ××™×¨×•×¢
                    try:
                        if os.getenv("PYTEST_CURRENT_TEST"):
                            class _Ctx2:
                                def __init__(self, app):
                                    self.application = app
                            await _backups_cleanup_job(_Ctx2(application))
                    except Exception:
                        pass
            else:
                # Emit the disabled event reliably and in a test-friendly way:
                # 1) Prefer a late dynamic import (cooperates with tests that patch sys.modules at runtime)
                # 2) Fallback to the already-imported emit_event when dynamic import is unavailable
                try:
                    try:
                        from observability import emit_event as _emit
                    except Exception:  # pragma: no cover
                        _emit = None
                    if _emit is not None:
                        _emit("backups_cleanup_disabled", severity="info")
                    else:
                        try:
                            emit_event("backups_cleanup_disabled", severity="info")
                        except Exception:
                            pass
                except Exception:
                    # Fail-open: do not raise if observability layer is unavailable
                    pass
        except Exception:
            # Fail-open: ××œ ×ª×›×©×™×œ ××ª ×¢×œ×™×™×ª ×”×‘×•×˜
            pass
    except Exception:
        # Fail-open: ××œ ×ª×›×©×™×œ ××ª ×¢×œ×™×™×ª ×”×‘×•×˜ ×× ×”×ª×–××•×Ÿ × ×›×©×œ
        pass

    # Predictive Health sampler: scrape webapp /metrics and feed predictive engine
    try:
        async def _predictive_sampler_job(context: ContextTypes.DEFAULT_TYPE):  # noqa: ARG001
            from services.job_tracker import get_job_tracker, JobAlreadyRunningError

            tracker = get_job_tracker()
            try:
                trigger = (
                    str(((getattr(getattr(context, "job", None), "data", None) or {}) or {}).get("trigger") or "scheduled")
                    .strip()
                    .lower()
                )
            except Exception:
                trigger = "scheduled"

            import sys as _sys

            _cm = tracker.track("predictive_sampler", trigger=trigger)
            try:
                run = _cm.__enter__()
            except JobAlreadyRunningError:
                try:
                    tracker.record_skipped(job_id="predictive_sampler", trigger=trigger, reason="already_running")
                except Exception:
                    pass
                return

            _exc_info = (None, None, None)
            try:
                if os.getenv("PYTEST_CURRENT_TEST"):
                    allow_in_tests = str(os.getenv("PREDICTIVE_SAMPLER_RUN_IN_TESTS", "false")).lower()
                    if allow_in_tests not in {"1", "true", "yes", "on"}:
                        tracker.skip_run(run.run_id, "disabled_in_tests")
                        return
                # Feature flag: allow disabling explicitly
                if str(os.getenv("PREDICTIVE_SAMPLER_ENABLED", "true")).lower() not in {"1", "true", "yes", "on"}:
                    tracker.skip_run(run.run_id, "disabled_by_env")
                    return
                base = (os.getenv("PREDICTIVE_SAMPLER_METRICS_URL")
                        or os.getenv("WEBAPP_URL")
                        or os.getenv("PUBLIC_BASE_URL")
                        or "").strip()
                if not base:
                    tracker.skip_run(run.run_id, "missing_metrics_base_url")
                    return
                # Normalize URL and build metrics path
                url = base.rstrip("/") + "/metrics"
                text: str | None = None
                try:
                    from http_async import request as async_request  # type: ignore
                    async with async_request("GET", url, service="webapp", endpoint="/metrics") as resp:
                        if getattr(resp, "status", 0) == 200:
                            # aiohttp response supports .text() coroutine
                            try:
                                text = await resp.text()  # type: ignore[attr-defined]
                            except Exception:
                                try:
                                    text = (await resp.read()).decode("utf-8", "ignore")  # type: ignore[attr-defined]
                                except Exception:
                                    text = None
                except Exception:
                    text = None

                cur_lat = cur_err = thr_lat = thr_err = None
                if text:
                    try:
                        for line in text.splitlines():
                            s = line.strip()
                            if not s or s.startswith("#"):
                                continue
                            # Very simple Prometheus exposition parsing: "name value"
                            if s.startswith("adaptive_current_latency_avg_seconds "):
                                try:
                                    cur_lat = float(s.split()[-1])
                                except Exception:
                                    pass
                            elif s.startswith("adaptive_current_error_rate_percent "):
                                try:
                                    cur_err = float(s.split()[-1])
                                except Exception:
                                    pass
                            elif s.startswith("adaptive_latency_threshold_seconds "):
                                try:
                                    thr_lat = float(s.split()[-1])
                                except Exception:
                                    pass
                            elif s.startswith("adaptive_error_rate_threshold_percent "):
                                try:
                                    thr_err = float(s.split()[-1])
                                except Exception:
                                    pass
                    except Exception:
                        cur_lat = cur_err = thr_lat = thr_err = None

                # Feed predictive engine with the best available snapshot
                try:
                    from predictive_engine import note_observation, maybe_recompute_and_preempt  # type: ignore
                    kwargs = {}
                    if cur_err is not None:
                        kwargs["error_rate_percent"] = float(cur_err)
                    if cur_lat is not None:
                        kwargs["latency_seconds"] = float(cur_lat)
                    # memory is handled inside note_observation when omitted
                    note_observation(**kwargs)  # type: ignore[arg-type]
                    maybe_recompute_and_preempt()
                except Exception:
                    # Soft-fail, but report once per run
                    try:
                        from observability import emit_event as _emit  # type: ignore
                        _emit("predictive_sampler_error", severity="anomaly", handled=True)
                    except Exception:
                        pass
                tracker.add_log(run.run_id, "info", "Predictive sampler tick completed")
            except Exception:
                _exc_info = _sys.exc_info()
                raise
            finally:
                _cm.__exit__(*_exc_info)
            # ×—×¨×™×’×•×ª ×× ×•×”×œ×•×ª ×¢"×™ ×”-context manager

        try:
            interval_secs = int(os.getenv("PREDICTIVE_SAMPLER_INTERVAL_SECS", "60") or 60)
            first_secs = int(os.getenv("PREDICTIVE_SAMPLER_FIRST_SECS", "10") or 10)
            application.job_queue.run_repeating(
                _predictive_sampler_job,
                interval=max(15, interval_secs),
                first=max(0, first_secs),
                name="predictive_sampler",
            )
        except Exception:
            # ×‘×¡×‘×™×‘×•×ª ×©×‘×”×Ÿ ×”-JobQueue ×œ× ×–××™×Ÿ (×œ××©×œ ×—×œ×§ ××”×˜×¡×˜×™×), ×”×¨×¥ ×¤×¢× ××—×ª ××™×“×™×ª
            class _Ctx:
                def __init__(self, app):
                    self.application = app
            try:
                await _predictive_sampler_job(_Ctx(application))
            except Exception:
                pass
    except Exception:
        pass

    # --- Background job: Sentry polling (fallback when webhooks are unavailable) ---
    try:
        from services.sentry_polling import SentryPoller, SentryPollerConfig  # type: ignore

        poller_cfg = SentryPoller.from_env()
        poller = SentryPoller(poller_cfg)

        async def _sentry_poll_job(_context: ContextTypes.DEFAULT_TYPE):  # noqa: ARG001
            from services.job_tracker import get_job_tracker, JobAlreadyRunningError

            tracker = get_job_tracker()
            import sys as _sys

            _cm = tracker.track("sentry_poll", trigger="scheduled")
            try:
                run = _cm.__enter__()
            except JobAlreadyRunningError:
                try:
                    tracker.record_skipped(job_id="sentry_poll", trigger="scheduled", reason="already_running")
                except Exception:
                    pass
                return

            _exc_info = (None, None, None)
            try:
                try:
                    res = await poller.tick()
                    try:
                        from observability import emit_event as _emit  # type: ignore
                    except Exception:  # pragma: no cover
                        _emit = lambda *a, **k: None
                    if isinstance(res, dict) and res.get("enabled"):
                        tracker.add_log(
                            run.run_id,
                            "info",
                            f"sentry_poll_tick polled={int(res.get('polled', 0) or 0)} emitted={int(res.get('emitted', 0) or 0)}",
                        )
                        _emit(
                            "sentry_poll_tick",
                            severity="info",
                            polled=int(res.get("polled", 0) or 0),
                            emitted=int(res.get("emitted", 0) or 0),
                            configured=bool(res.get("configured", True)),
                        )
                except Exception as e:
                    try:
                        from observability import emit_event as _emit  # type: ignore
                    except Exception:  # pragma: no cover
                        _emit = lambda *a, **k: None
                    _emit("sentry_poll_error", severity="anomaly", handled=True, error=str(e))
                    raise
            except Exception:
                _exc_info = _sys.exc_info()
                raise
            finally:
                _cm.__exit__(*_exc_info)

        try:
            if bool(getattr(poller_cfg, "enabled", False)):
                interval_secs = int(getattr(poller_cfg, "interval_seconds", 300) or 300)
                first_secs = int(os.getenv("SENTRY_POLL_FIRST_SECS", "20") or 20)
                application.job_queue.run_repeating(
                    _sentry_poll_job,
                    interval=max(30, interval_secs),
                    first=max(0, first_secs),
                    name="sentry_poll",
                )
        except Exception:
            # Fail-open: ×œ× × ×©×‘×•×¨ startup ×× JobQueue ×œ× ×–××™×Ÿ/××•×’×‘×œ
            pass
    except Exception:
        pass

# --- Background job: Cache warming based on recent usage (lightweight) ---
    try:
        async def _cache_warming_job(context: ContextTypes.DEFAULT_TYPE):  # noqa: ARG001
            from services.job_tracker import get_job_tracker, JobAlreadyRunningError

            tracker = get_job_tracker()
            try:
                trigger = (
                    str(((getattr(getattr(context, "job", None), "data", None) or {}) or {}).get("trigger") or "scheduled")
                    .strip()
                    .lower()
                )
            except Exception:
                trigger = "scheduled"
            import sys as _sys

            _cm = tracker.track("cache_warming", trigger=trigger)
            try:
                run = _cm.__enter__()
            except JobAlreadyRunningError:
                try:
                    tracker.record_skipped(job_id="cache_warming", trigger=trigger, reason="already_running")
                except Exception:
                    pass
                return

            _exc_info = (None, None, None)
            try:
                try:
                    # Feature flag
                    enabled = str(os.getenv("CACHE_WARMING_ENABLED", "true")).lower() in {"1", "true", "yes", "on"}
                    if not enabled:
                        tracker.skip_run(run.run_id, "disabled_by_env")
                        return

                    # Time budget to avoid load
                    import time as _t

                    # ×‘×¨×™×¨×ª ××—×“×œ ×”×•×’×“×œ×” ×›×™ ×× ×—× ×• ××—×××™× ×’× Pages ××¨×›×–×™×™× (Files/Collections)
                    budget = float(os.getenv("CACHE_WARMING_BUDGET_SECONDS", "5.0") or 5.0)
                    t0 = _t.time()

                    # Lazy imports to avoid hard deps
                    try:
                        from cache_manager import cache as _cache
                    except Exception:  # pragma: no cover
                        _cache = None
                    try:
                        from cache_manager import build_cache_key as _build_cache_key
                    except Exception:  # pragma: no cover
                        _build_cache_key = None
                    try:
                        from webapp.app import get_db as _get_db
                    except Exception:  # pragma: no cover
                        _get_db = None
                    try:
                        from webapp.app import search_engine as _search_engine
                    except Exception:  # pragma: no cover
                        _search_engine = None

                    if _cache is None or not getattr(_cache, "is_enabled", False) or _get_db is None:
                        tracker.skip_run(run.run_id, "cache_disabled_or_db_unavailable")
                        return

                    warmed_keys: set[str] = set()
                    warmed_counts: dict[str, int] = {
                        "api_stats": 0,
                        "api_search_suggest": 0,
                        "web_files": 0,
                        "collections_list": 0,
                        "collections_detail": 0,
                        "collections_items": 0,
                    }

                    def _mark_warmed(key: str, kind: str) -> None:
                        try:
                            k = str(key or "").strip()
                        except Exception:
                            return
                        if not k:
                            return
                        if k in warmed_keys:
                            return
                        warmed_keys.add(k)
                        try:
                            warmed_counts[kind] = int(warmed_counts.get(kind, 0) or 0) + 1
                        except Exception:
                            pass

                    db = _get_db()
                    now = __import__("datetime").datetime.now(__import__("datetime").timezone.utc)
                    week_ago = now - __import__("datetime").timedelta(days=7)

                    # Top active users in last 7 days (at most 3)
                    top_users = []
                    try:
                        pipeline = [
                            {"$match": {"updated_at": {"$gte": week_ago}}},
                            {"$group": {"_id": "$user_id", "cnt": {"$sum": 1}}},
                            {"$sort": {"cnt": -1}},
                            {"$limit": 3},
                        ]
                        agg = list(db.code_snippets.aggregate(pipeline))
                        top_users = [int(d.get("_id")) for d in agg if d.get("_id") is not None]
                    except Exception:
                        pass

                    # Seeds: common keywords + top tags (last 7d)
                    seeds = ["def", "class", "import", "fix", "refactor", "todo"]
                    try:
                        tag_pipe = [
                            {"$match": {"updated_at": {"$gte": week_ago}, "tags": {"$exists": True, "$ne": []}}},
                            {"$unwind": "$tags"},
                            {"$group": {"_id": "$tags", "cnt": {"$sum": 1}}},
                            {"$sort": {"cnt": -1}},
                            {"$limit": 5},
                        ]
                        tag_rows = list(db.code_snippets.aggregate(tag_pipe))
                        seeds += [str(r.get("_id")) for r in tag_rows if r.get("_id")]
                    except Exception:
                        pass
                    # Dedup and sanitize seeds
                    uniq_seeds = []
                    for s in seeds:
                        s2 = str(s or "").strip()
                        if s2 and s2 not in uniq_seeds:
                            uniq_seeds.append(s2)

                    import hashlib, json

                    # Warm per user: stats and suggestions
                    for uid in top_users:
                        if (_t.time() - t0) > budget:
                            break
                        # Stats (like /api/stats)
                        try:
                            active_q = {"user_id": uid, "is_active": True}
                            stats = {
                                "total_files": db.code_snippets.count_documents(active_q),
                                "languages": list(db.code_snippets.distinct("programming_language", active_q)),
                                "recent_activity": [],
                            }
                            recent = (
                                db.code_snippets.find(active_q, {"file_name": 1, "created_at": 1})
                                .sort("created_at", -1)
                                .limit(5)
                            )
                            for item in recent:
                                stats["recent_activity"].append(
                                    {
                                        "file_name": item.get("file_name", ""),
                                        "created_at": (item.get("created_at") or now).isoformat(),
                                    }
                                )
                            raw = json.dumps({}, sort_keys=True, ensure_ascii=False)
                            h = hashlib.sha256(raw.encode("utf-8")).hexdigest()[:16]
                            key = f"api:stats:user:{uid}:{h}"
                            try:
                                _cache.set_dynamic(
                                    key,
                                    stats,
                                    "user_stats",
                                    {"user_id": uid, "endpoint": "api_stats", "access_frequency": "high"},
                                )
                                _mark_warmed(key, "api_stats")
                            except Exception:
                                pass
                        except Exception:
                            pass

                        # Suggestions (if engine available)
                        if _search_engine is not None:
                            for q in uniq_seeds:
                                if (_t.time() - t0) > budget:
                                    break
                                try:
                                    if len(q) < 2:
                                        continue
                                    sugg = _search_engine.suggest_completions(uid, q, limit=10)
                                    payload = json.dumps({"q": q}, sort_keys=True, ensure_ascii=False)
                                    h = hashlib.sha256(payload.encode("utf-8")).hexdigest()[:16]
                                    key = f"api:search_suggest:{uid}:{h}"
                                    _cache.set_dynamic(
                                        key,
                                        {"suggestions": sugg},
                                        "search_results",
                                        {"user_id": uid, "endpoint": "api_search_suggestions"},
                                    )
                                    _mark_warmed(key, "api_search_suggest")
                                except Exception:
                                    continue

                        # --- Warm core page: All Files (/files) HTML cache ---
                        if (_t.time() - t0) <= budget:
                            try:
                                from webapp.app import app as _web_app  # Flask app
                                from webapp.app import files as _files_page
                                from flask import session as _flask_session

                                # ××¤×ª×— ×§××© ×–×”×” ×œ×–×” ×©×‘-webapp/app.py
                                try:
                                    _params = {
                                        "q": "",
                                        "lang": "",
                                        "category": "",
                                        "sort": "created_at",
                                        "repo": "",
                                        "page": 1,
                                        "cursor": "",
                                    }
                                    _raw = json.dumps(_params, sort_keys=True, ensure_ascii=False)
                                    _hash = hashlib.sha256(_raw.encode("utf-8")).hexdigest()[:24]
                                    files_cache_key = f"web:files:user:{uid}:{_hash}"
                                except Exception:
                                    files_cache_key = f"web:files:user:{uid}:fallback"

                                # ×‘× ×™×™×ª user_data ××™× ×™××œ×™ ×©×ª×•×× ×œ-session ×©×œ ×”-webapp
                                user_doc = {}
                                try:
                                    user_doc = db.users.find_one({"user_id": int(uid)}) or {}
                                except Exception:
                                    user_doc = {}
                                user_data = {
                                    "id": int(uid),
                                    "first_name": user_doc.get("first_name", "") if isinstance(user_doc, dict) else "",
                                    "last_name": user_doc.get("last_name", "") if isinstance(user_doc, dict) else "",
                                    "username": user_doc.get("username", "") if isinstance(user_doc, dict) else "",
                                    "photo_url": user_doc.get("photo_url", "") if isinstance(user_doc, dict) else "",
                                    "has_seen_welcome_modal": bool((user_doc or {}).get("has_seen_welcome_modal", False)) if isinstance(user_doc, dict) else False,
                                }

                                # ×¨×™× ×“×•×¨ ×‘×ª×•×š request context ×›×“×™ ×©×”-endpoint ×™×¤×¢×œ ×›××• ×‘×™×™×¦×•×¨
                                with _web_app.test_request_context("/files"):
                                    _flask_session["user_id"] = int(uid)
                                    _flask_session["user_data"] = user_data
                                    _flask_session.permanent = True
                                    html = _files_page()
                                # cache.set_dynamic ×‘×¤× ×™× ×›×‘×¨ ×¢×•×©×” ×©××™×¨×”; ×‘×›×œ ×–××ª × ×•×•×“× ×©×”××¤×ª×— ×§×™×™× (best-effort)
                                try:
                                    cached_html = _cache.get(files_cache_key)
                                    if isinstance(cached_html, str) and cached_html:
                                        _mark_warmed(files_cache_key, "web_files")
                                    else:
                                        if isinstance(html, str) and html:
                                            try:
                                                _cache.set_dynamic(
                                                    files_cache_key,
                                                    html,
                                                    "file_list",
                                                    {
                                                        "user_id": int(uid),
                                                        "user_tier": "regular",
                                                        "access_frequency": "high",
                                                        "endpoint": "files",
                                                    },
                                                )
                                                _mark_warmed(files_cache_key, "web_files")
                                            except Exception:
                                                pass
                                except Exception:
                                    pass
                            except Exception:
                                # Fail-open: ×× Flask/webapp ×œ× ×–××™×Ÿ ×‘×¡×‘×™×‘×” ×”×–×•, × ×“×œ×’
                                pass

                        # --- Warm core API: Collections list + Desktop items ---
                        if (_t.time() - t0) <= budget and _build_cache_key is not None:
                            try:
                                from webapp.app import app as _web_app
                                from webapp.collections_api import list_collections as _api_list_collections
                                from webapp.collections_api import get_items as _api_get_items
                                from webapp.collections_api import get_collection as _api_get_collection
                                from flask import session as _flask_session

                                # user_data (×›××• ×œ××¢×œ×”) â€” × ×‘× ×” ×©×•×‘ ×‘×¦×•×¨×” ×—×¡×™× ×” (×‘×œ×™ ×ª×œ×•×ª ×‘×‘×œ×•×§ ×”×§×•×“×)
                                user_doc = {}
                                try:
                                    user_doc = db.users.find_one({"user_id": int(uid)}) or {}
                                except Exception:
                                    user_doc = {}
                                user_data = {
                                    "id": int(uid),
                                    "first_name": user_doc.get("first_name", "") if isinstance(user_doc, dict) else "",
                                    "last_name": user_doc.get("last_name", "") if isinstance(user_doc, dict) else "",
                                    "username": user_doc.get("username", "") if isinstance(user_doc, dict) else "",
                                    "photo_url": user_doc.get("photo_url", "") if isinstance(user_doc, dict) else "",
                                    "has_seen_welcome_modal": bool((user_doc or {}).get("has_seen_welcome_modal", False)) if isinstance(user_doc, dict) else False,
                                }

                                # 1) /api/collections?limit=100&skip=0 (××©××© ×‘-base.html ×œ× ×™×•×•×˜ ×œ×©×•×œ×—×Ÿ ×¢×‘×•×“×”)
                                qs100 = "limit=100&skip=0"
                                with _web_app.test_request_context(f"/api/collections?{qs100}"):
                                    _flask_session["user_id"] = int(uid)
                                    _flask_session["user_data"] = user_data
                                    _flask_session.permanent = True
                                    res = _api_list_collections()
                                key_collections_100 = _build_cache_key("collections_list:v2", str(uid), "/api/collections", qs100)
                                try:
                                    if _cache.get(key_collections_100) is not None:
                                        _mark_warmed(key_collections_100, "collections_list")
                                except Exception:
                                    pass

                                # 2) /api/collections (××©××© ×‘××•×“××œ Add to Collection)
                                with _web_app.test_request_context("/api/collections"):
                                    _flask_session["user_id"] = int(uid)
                                    _flask_session["user_data"] = user_data
                                    _flask_session.permanent = True
                                    res2 = _api_list_collections()
                                key_collections_default = _build_cache_key("collections_list:v2", str(uid), "/api/collections", "")
                                try:
                                    if _cache.get(key_collections_default) is not None:
                                        _mark_warmed(key_collections_default, "collections_list")
                                except Exception:
                                    pass

                                # parse JSON to find Desktop/×©×•×œ×—×Ÿ ×¢×‘×•×“×” id
                                def _extract_payload(obj: object) -> dict | None:
                                    # Cache miss: ×”-endpoint ××—×–×™×¨ dict ×™×©×™×¨×•×ª
                                    if isinstance(obj, dict):
                                        return obj
                                    # Cache hit (dynamic_cache): ×”-endpoint ××—×–×™×¨ Flask Response
                                    try:
                                        getter = getattr(obj, "get_json", None)
                                        if callable(getter):
                                            out = getter(silent=True)
                                            return out if isinstance(out, dict) else None
                                    except Exception:
                                        return None
                                    return None

                                payload = _extract_payload(res) or _extract_payload(res2)
                                collections = (payload or {}).get("collections") if payload else None
                                workspace_id = None
                                if isinstance(collections, list):
                                    for c in collections:
                                        if not isinstance(c, dict):
                                            continue
                                        name = str(c.get("name") or "").strip().lower()
                                        if name in {"×©×•×œ×—×Ÿ ×¢×‘×•×“×”", "desktop"}:
                                            wid = c.get("id")
                                            if wid is not None:
                                                workspace_id = str(wid)
                                                break

                                if workspace_id and (_t.time() - t0) <= budget:
                                    # warm /api/collections/<id> (detail)
                                    with _web_app.test_request_context(f"/api/collections/{workspace_id}"):
                                        _flask_session["user_id"] = int(uid)
                                        _flask_session["user_data"] = user_data
                                        _flask_session.permanent = True
                                        _api_get_collection(workspace_id)
                                    key_detail = _build_cache_key("collections_detail", str(uid), f"/api/collections/{workspace_id}", "")
                                    try:
                                        if _cache.get(key_detail) is not None:
                                            _mark_warmed(key_detail, "collections_detail")
                                    except Exception:
                                        pass

                                    # warm /api/collections/<id>/items?page=1&per_page=20&include_computed=true
                                    items_qs = "page=1&per_page=20&include_computed=true"
                                    with _web_app.test_request_context(f"/api/collections/{workspace_id}/items?{items_qs}"):
                                        _flask_session["user_id"] = int(uid)
                                        _flask_session["user_data"] = user_data
                                        _flask_session.permanent = True
                                        _api_get_items(workspace_id)
                                    key_items = _build_cache_key(
                                        "collections_items",
                                        str(uid),
                                        f"/api/collections/{workspace_id}/items",
                                        items_qs,
                                    )
                                    try:
                                        if _cache.get(key_items) is not None:
                                            _mark_warmed(key_items, "collections_items")
                                    except Exception:
                                        pass
                            except Exception:
                                pass

                    # Emit
                    try:
                        try:
                            from observability import emit_event as _emit
                        except Exception:  # pragma: no cover
                            _emit = (lambda *a, **k: None)
                        _emit(
                            "cache_warming_done",
                            severity="info",
                            warmed_keys_count=int(len(warmed_keys)),
                            warmed_counts=dict(warmed_counts),
                        )
                    except Exception:
                        pass
                    tracker.add_log(
                        run.run_id,
                        "info",
                        f"Cache warming done warmed_keys={int(len(warmed_keys))} breakdown={warmed_counts}",
                    )
                except Exception as e:
                    try:
                        from observability import emit_event as _emit
                    except Exception:
                        _emit = (lambda *a, **k: None)
                    _emit("cache_warming_error", severity="anomaly", error=str(e))
                    raise
            except Exception:
                _exc_info = _sys.exc_info()
                raise
            finally:
                _cm.__exit__(*_exc_info)

        try:
            interval_secs = int(os.getenv("CACHE_WARMING_INTERVAL_SECS", "900") or 900)
            first_secs = int(os.getenv("CACHE_WARMING_FIRST_SECS", "45") or 45)
            application.job_queue.run_repeating(
                _cache_warming_job,
                interval=max(120, interval_secs),
                first=max(0, first_secs),
                name="cache_warming",
            )
        except Exception:
            # ×‘×¡×‘×™×‘×•×ª ××•×’×‘×œ×•×ª (×›××• ×˜×¡×˜×™×) ×”×ª×–××•×Ÿ ×¢×©×•×™ ×œ×”×›×©×œ â€” × ×¨×™×¥ ×¤×¢× ××—×ª ××™×“×™×ª
            class _CtxWarm:
                def __init__(self, app):
                    self.application = app
            try:
                await _cache_warming_job(_CtxWarm(application))
            except Exception:
                pass
    except Exception:
        pass

if __name__ == "__main__":
    main()
